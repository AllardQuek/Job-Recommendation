{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JobRecommendation-0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1SpiekC3jPMJjrzBcOqBSukpylpCelNsN",
      "authorship_tag": "ABX9TyNs6o11c3N/y35evZ0UCZke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllardQuek/Job-Recommendation/blob/main/JobRecommendation_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiU3aHS7Gcjl"
      },
      "source": [
        "# Job Recommendation for Undergraduates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "514JVNiBDTdH"
      },
      "source": [
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S179dVvhDKf6"
      },
      "source": [
        "#@title\n",
        "\n",
        "# Some of the model training logs can cover the full\n",
        "# screen if not compressed to a smaller viewport.\n",
        "# This magic allows setting a max height for a cell.\n",
        "@register_line_magic\n",
        "def set_cell_height(size):\n",
        "  display(\n",
        "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
        "                 str(size) + \"})\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "UscF7xhB3HVr",
        "outputId": "8c8ff878-32c0-4667-be61-d7c54f0cfa84"
      },
      "source": [
        "%set_cell_height 300\n",
        "!pip3 install tensorflow_decision_forests --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow_decision_forests in /usr/local/lib/python3.7/dist-packages (0.1.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow~=2.5->tensorflow_decision_forests) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPK_QX0AFBnO"
      },
      "source": [
        "Install [Wurlitzer](https://pypi.org/project/wurlitzer/). It can be used to show\n",
        "the detailed training logs. This is only needed in colabs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpoOVWzCFKyY",
        "outputId": "acb4493b-b359-43b1-f092-e2aa94c2b419"
      },
      "source": [
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wurlitzer\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ac/b7082c3d228e600af37ec5cf99697d400328b13350b4d7577c213fa4faca/wurlitzer-2.1.0-py2.py3-none-any.whl\n",
            "Installing collected packages: wurlitzer\n",
            "Successfully installed wurlitzer-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZoyTgq5FWxL"
      },
      "source": [
        "Now let's import all the packages we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8HQ54CtDudY"
      },
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC5SVvaRGpJ7",
        "outputId": "4b52e7e2-8e32-42b9-87ec-135d1a28f25e"
      },
      "source": [
        "# Check the version of TensorFlow Decision Forests\n",
        "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TensorFlow Decision Forests v0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5uWxYnrFsnI"
      },
      "source": [
        "## Kaggle Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1mj67-aV8Xp"
      },
      "source": [
        "Let's see all the files we have from [Kaggle](https://www.kaggle.com/c/job-recommendation/data).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynYftoSuVvFc",
        "outputId": "1d9b33c2-c1ca-4948-fc0a-3b4ab7017d8e"
      },
      "source": [
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Jobs Internships/Matchin Internship/AI ML/Datasets/Kaggle'):\n",
        "    for filename in filenames:\n",
        "        print(filename)\n",
        "        # print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user_history.tsv\n",
            "users.tsv\n",
            "apps.tsv\n",
            "window_dates.tsv\n",
            "test_users.tsv\n",
            "popular_jobs.csv\n",
            "jobs1.tsv\n",
            "jobs2.tsv\n",
            "jobs3.tsv\n",
            "jobs4.tsv\n",
            "jobs5.tsv\n",
            "jobs6.tsv\n",
            "jobs7.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "4RY5071Mj_Jl",
        "outputId": "bffa6a52-9e46-4ac5-ed45-41c31adeae1c"
      },
      "source": [
        "df_users = pd.read_csv(\"/content/drive/MyDrive/Jobs Internships/Matchin Internship/AI ML/Datasets/Kaggle/users.tsv\", sep=\"\\t\")\n",
        "df_users.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>WindowID</th>\n",
              "      <th>Split</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Country</th>\n",
              "      <th>ZipCode</th>\n",
              "      <th>DegreeType</th>\n",
              "      <th>Major</th>\n",
              "      <th>GraduationDate</th>\n",
              "      <th>WorkHistoryCount</th>\n",
              "      <th>TotalYearsExperience</th>\n",
              "      <th>CurrentlyEmployed</th>\n",
              "      <th>ManagedOthers</th>\n",
              "      <th>ManagedHowMany</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>Paramount</td>\n",
              "      <td>CA</td>\n",
              "      <td>US</td>\n",
              "      <td>90723</td>\n",
              "      <td>High School</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1999-06-01 00:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>La Mesa</td>\n",
              "      <td>CA</td>\n",
              "      <td>US</td>\n",
              "      <td>91941</td>\n",
              "      <td>Master's</td>\n",
              "      <td>Anthropology</td>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>10</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>Williamstown</td>\n",
              "      <td>NJ</td>\n",
              "      <td>US</td>\n",
              "      <td>08094</td>\n",
              "      <td>High School</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>1985-06-01 00:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>Astoria</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "      <td>11105</td>\n",
              "      <td>Master's</td>\n",
              "      <td>Journalism</td>\n",
              "      <td>2007-05-01 00:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>Baton Rouge</td>\n",
              "      <td>LA</td>\n",
              "      <td>US</td>\n",
              "      <td>70808</td>\n",
              "      <td>Bachelor's</td>\n",
              "      <td>Agricultural Business</td>\n",
              "      <td>2011-05-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserID  WindowID  Split  ... CurrentlyEmployed ManagedOthers ManagedHowMany\n",
              "0      47         1  Train  ...               Yes            No              0\n",
              "1      72         1  Train  ...               Yes            No              0\n",
              "2      80         1  Train  ...               Yes           Yes              5\n",
              "3      98         1  Train  ...               Yes            No              0\n",
              "4     123         1  Train  ...               Yes            No              0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DfH1MqRvFfo9",
        "outputId": "4e1a9c53-30d0-4d6a-962b-973090c9e0db"
      },
      "source": [
        "df_user_history = pd.read_csv(\"/content/drive/MyDrive/Jobs Internships/Matchin Internship/AI ML/Datasets/Kaggle/user_history.tsv\", sep=\"\\t\")\n",
        "df_user_history.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>WindowID</th>\n",
              "      <th>Split</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>JobTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>1</td>\n",
              "      <td>National Space Communication Programs-Special ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>2</td>\n",
              "      <td>Detention Officer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>3</td>\n",
              "      <td>Passenger Screener, TSA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>1</td>\n",
              "      <td>Lecturer, Department of Anthropology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>Train</td>\n",
              "      <td>2</td>\n",
              "      <td>Student Assistant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserID  ...                                           JobTitle\n",
              "0      47  ...  National Space Communication Programs-Special ...\n",
              "1      47  ...                                  Detention Officer\n",
              "2      47  ...                            Passenger Screener, TSA\n",
              "3      72  ...               Lecturer, Department of Anthropology\n",
              "4      72  ...                                  Student Assistant\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea4MbE4tFw9a"
      },
      "source": [
        "## Matchin Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "t4-5MlOQ4s1R",
        "outputId": "25d84210-5f4c-469c-dd7e-038c5ffca41b"
      },
      "source": [
        "dataset_df = pd.read_excel(\"/content/drive/MyDrive/Jobs Internships/Matchin Internship/AI ML/Datasets/100datapoints-1.xlsx\")\n",
        "dataset_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.</th>\n",
              "      <th>Name</th>\n",
              "      <th>Current Job Title with Company</th>\n",
              "      <th>Current Job Description</th>\n",
              "      <th>Past Job/Internship Experience 1</th>\n",
              "      <th>Description</th>\n",
              "      <th>Past Internship Experience 2</th>\n",
              "      <th>Description.1</th>\n",
              "      <th>Past Internship Experience 3</th>\n",
              "      <th>Description.2</th>\n",
              "      <th>Skills</th>\n",
              "      <th>School</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Eda Tan</td>\n",
              "      <td>Software Analyst at JPMorgan Chase &amp; Co</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Software Developer at LiveMore</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Amanda Lee</td>\n",
              "      <td>Systems Engineer at HP</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Intern at Embraer</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Byron Elton Tan</td>\n",
              "      <td>Engineer (Vehicle Systems) at HTX (Home Team S...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Engineer Vehicle Systems at MHA</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Kavya Nair</td>\n",
              "      <td>Graduate Design Engineer at Dyson</td>\n",
              "      <td>Design Engineer</td>\n",
              "      <td>Executive Engineer at SMRT</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Seung Kyu Kim</td>\n",
              "      <td>Siri Annotation Analyst AI/ML at Apple</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Freelance Translator at MMD Singapore</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   No.             Name  ... School Unnamed: 12\n",
              "0    1          Eda Tan  ...    NIL         NaN\n",
              "1    2       Amanda Lee  ...    NIL         NaN\n",
              "2    3  Byron Elton Tan  ...    NIL         NaN\n",
              "3    4       Kavya Nair  ...    NIL         NaN\n",
              "4    5    Seung Kyu Kim  ...    NIL         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hYiX6cLve8e"
      },
      "source": [
        "### Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xLbCM4IvYZh",
        "outputId": "4f42cb7a-21a6-46cc-a5ab-ac8d87b01726"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No.                                 float64\n",
              "Name                                 object\n",
              "Current Job Title with Company       object\n",
              "Current Job Description              object\n",
              "Past Job/Internship Experience 1     object\n",
              "Description                          object\n",
              "Past Internship Experience 2         object\n",
              "Description.1                        object\n",
              "Past Internship Experience 3         object\n",
              "Description.2                        object\n",
              "Skills                               object\n",
              "School                               object\n",
              "Unnamed: 12                          object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovp2LJS5vbvg"
      },
      "source": [
        "dataset_df[\"Current Job Title with Company\"].apply(lambda x: print(x, type(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayCMx2koKlHI",
        "outputId": "1377c0f1-ac5a-477a-80e3-2eb113cfc017"
      },
      "source": [
        "# Testing partitions\n",
        "title = \"Software Analyst at JPMorgan Chase & Co\t\"\n",
        "words = title.partition(\" at \")\n",
        "print(words[0])\n",
        "\n",
        "title_no_at = \"Software Analyst JPMorgan Chase & Co\t\"\n",
        "words_no_at = title_no_at.partition(\" at \")\n",
        "print(words_no_at[0].strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Software Analyst\n",
            "Software Analyst JPMorgan Chase & Co\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu6DaYLAviqb"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBcsZNJHKZBH"
      },
      "source": [
        "def split_it(title):\n",
        "    # Let's get only the title without the company for now\n",
        "    return title.partition(\" at \")[0].strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "EPLw8WgwJq9q",
        "outputId": "203bf35f-d1d5-443c-a657-f306698d48e1"
      },
      "source": [
        "dataset_df[\"Current Job Title\"] = dataset_df[\"Current Job Title with Company\"].apply(split_it)\n",
        "dataset_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.</th>\n",
              "      <th>Name</th>\n",
              "      <th>Current Job Title with Company</th>\n",
              "      <th>Current Job Description</th>\n",
              "      <th>Past Job/Internship Experience 1</th>\n",
              "      <th>Description</th>\n",
              "      <th>Past Internship Experience 2</th>\n",
              "      <th>Description.1</th>\n",
              "      <th>Past Internship Experience 3</th>\n",
              "      <th>Description.2</th>\n",
              "      <th>Skills</th>\n",
              "      <th>School</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Current Job Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Eda Tan</td>\n",
              "      <td>Software Analyst at JPMorgan Chase &amp; Co</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Software Developer at LiveMore</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software Analyst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Amanda Lee</td>\n",
              "      <td>Systems Engineer at HP</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Intern at Embraer</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Systems Engineer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Byron Elton Tan</td>\n",
              "      <td>Engineer (Vehicle Systems) at HTX (Home Team S...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Engineer Vehicle Systems at MHA</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Engineer (Vehicle Systems)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Kavya Nair</td>\n",
              "      <td>Graduate Design Engineer at Dyson</td>\n",
              "      <td>Design Engineer</td>\n",
              "      <td>Executive Engineer at SMRT</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Graduate Design Engineer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Seung Kyu Kim</td>\n",
              "      <td>Siri Annotation Analyst AI/ML at Apple</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Freelance Translator at MMD Singapore</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Siri Annotation Analyst AI/ML</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   No.             Name  ... Unnamed: 12              Current Job Title\n",
              "0    1          Eda Tan  ...         NaN               Software Analyst\n",
              "1    2       Amanda Lee  ...         NaN               Systems Engineer\n",
              "2    3  Byron Elton Tan  ...         NaN     Engineer (Vehicle Systems)\n",
              "3    4       Kavya Nair  ...         NaN       Graduate Design Engineer\n",
              "4    5    Seung Kyu Kim  ...         NaN  Siri Annotation Analyst AI/ML\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "3lExWIN-OaT3",
        "outputId": "9c9292bf-85b1-421b-ef0f-4d07640a21c6"
      },
      "source": [
        "# Rename the columns to single words\n",
        "dataset_df.rename(columns = {'Current Job Title':'currentJobTitle', \n",
        "                             'Past Job/Internship Experience 1':'Past1',\n",
        "                             'Past Internship Experience 2':'Past2',\n",
        "                             'Past Internship Experience 3':'Past3',\n",
        "                             }, inplace=True)\n",
        "\n",
        "# Pick only the columns we need for training/prediction\n",
        "dataset_df = dataset_df[[\"currentJobTitle\", \"Past1\", \"Past2\", \"Past3\"]]\n",
        "dataset_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>currentJobTitle</th>\n",
              "      <th>Past1</th>\n",
              "      <th>Past2</th>\n",
              "      <th>Past3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Software Engineer at nucon.io</td>\n",
              "      <td>Coding Course Instructor at First Code Academy</td>\n",
              "      <td>SAP Leonardo Machine Learning - Business Devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Tech Consultant</td>\n",
              "      <td>Assistant Manager (Business Improvement &amp; Auto...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>User Experience Architect</td>\n",
              "      <td>UX/UI Intern at Dentsu Aegis NEtwork</td>\n",
              "      <td>Software Quality Assurance Engineer at Ascenz ...</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Artificial Intelligence Engineer</td>\n",
              "      <td>Data Science Intern at Amaris.AI Pte Ltd</td>\n",
              "      <td>Temporary Officer at IRAS</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>UI/UX Developer Trainee</td>\n",
              "      <td>Digital Marketing &amp; Public Relations Intern at...</td>\n",
              "      <td>Dairy and Beverage Intern at Tate &amp; Lyle</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Research And Development Intern</td>\n",
              "      <td>Undergraduate Student Researcher at NTU</td>\n",
              "      <td>Research Assistant at NUS</td>\n",
              "      <td>Artificial Intellience Engineer Intern at AiCh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>Web Developer Intern at Jewel Paymentech</td>\n",
              "      <td>Teaching Assistant at SUTD</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>Software Engineer and Quantitative Researcher ...</td>\n",
              "      <td>Intern at nuTonomy</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Regional Supply &amp; Inventory Planner - Energy G...</td>\n",
              "      <td>Computational Engineering Intern at Rolls Royce</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Data Analyst Intern</td>\n",
              "      <td>Business Development Intern at Enterprise Sing...</td>\n",
              "      <td>Self-employed Fullstack Engineer</td>\n",
              "      <td>Software Engineer at Orbittech Investment Tech...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      currentJobTitle  ...                                              Past3\n",
              "36                                     Data Scientist  ...  SAP Leonardo Machine Learning - Business Devel...\n",
              "62                                    Tech Consultant  ...                                                NIL\n",
              "47                          User Experience Architect  ...                                                NIL\n",
              "75                   Artificial Intelligence Engineer  ...                                                NIL\n",
              "86                            UI/UX Developer Trainee  ...                                                NIL\n",
              "82                    Research And Development Intern  ...  Artificial Intellience Engineer Intern at AiCh...\n",
              "44                                  Software Engineer  ...                                                NIL\n",
              "12                                  Software Engineer  ...                                                NIL\n",
              "21  Regional Supply & Inventory Planner - Energy G...  ...                                                NIL\n",
              "57                                Data Analyst Intern  ...  Software Engineer at Orbittech Investment Tech...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUAc4zTAHKvC"
      },
      "source": [
        "TF-DF supports numerical, categorical amd missing feature types natively (differently than NN based models), therefore there is no need for preprocessing in the form of one-hot encoding, normalization or extra `is_present` feature.\n",
        "\n",
        "Labels are a bit different: Keras metrics expect integers. The label (`Current Job Title with Company`) is stored as a string, so let's convert it into an integer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcfEVRWlHMf0",
        "outputId": "db69a51d-1632-4102-c951-fb5089bcf321"
      },
      "source": [
        "# label = \"Current Job Title with Company\"\n",
        "label = \"currentJobTitle\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label classes: ['Software Analyst', 'Systems Engineer', 'Engineer (Vehicle Systems)', 'Graduate Design Engineer', 'Siri Annotation Analyst AI/ML', 'User Experience Designer', 'Associate Product Manager', 'Software Engineer', 'R&D Engineer', 'Consulting Analyst', 'Engineer', 'Lead Engineer', 'Program Manager', 'Software Development Engineer', 'Banker', 'Product Analyst - South Asia', 'Regional Supply & Inventory Planner - Energy Generation Program Associate', 'Financial Consultant / Career Advisor', 'Business Integration Analyst', 'Advisory Associate - Technology Risk', 'Emerging Technology Engineer', 'Sales Engineer', 'Associate Consultant', 'Market Risk Analyst', 'Associate Data Scientist', 'Associate Solution Engineer', 'Business Analyst', 'Senior Associate, Airport Development', 'Growth and Marketing Associate', 'Senior Engineer', 'Data Scientist', 'Product Development Engineer', 'CEO & C0-Founder Everything Analytics', 'Marketing Executive', 'Business Analyst - Ministry Of Communications and Information', 'Pega Developer', 'Cloud Solutions Architect | Management Associate', 'Ernst & Young - Associate', 'User Experience Architect', 'DZH International - Software Specialist', 'Regional Data Analyst', 'Data Analyst', 'Global Data Analyst', 'Data Analyst Intern', 'Technology Consultant', 'Business Technology Consultant', 'Tech Consultant', 'Co-Founder & CEO', 'Product Manager', 'Product Manager, IoT', 'Product Engineer', 'AI Product Engineer', 'Artificial Intelligence Engineer', 'Technology Associate', 'Artificial Intelligence Apprentice', 'Research And Development Intern', 'Research and Development Executive', 'Research Technologist', 'UI Developer', 'UI/UX Developer', 'UI/UX Developer Trainee', 'Market Data Analyst', 'Customer Insights Manager', 'AI Apprentice', 'Strategy & Consulting', 'Senior Marketing Lead', 'Data & Analytics', 'Mechanical Engineer', 'Executive Civil Engineer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfTW1D6xQb7T",
        "outputId": "889eefbd-6503-4f4a-e9f9-6a58e5cdfc5f"
      },
      "source": [
        "dataset_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['currentJobTitle', 'Past1', 'Past2', 'Past3'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4pFu86ZG0lH"
      },
      "source": [
        "Split the dataset into training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2HDtlh_G02N",
        "outputId": "f53e4c2a-3db2-4b58-a6b9-e876c47f9f5d"
      },
      "source": [
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74 examples in training, 25 examples for testing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cGUjoeJOpFy"
      },
      "source": [
        "Convert the pandas dataframe (`pd.Dataframe`) into tensorflow datasets (`tf.data.Dataset`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaQ_uL9YOixR"
      },
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe5RpVtxOwrV"
      },
      "source": [
        "**Notes:** `pd_dataframe_to_tf_dataset` could have converted the label to integer for you.\n",
        "\n",
        "And, if you wanted to create the `tf.data.Dataset` yourself, there is a couple of things to remember:\n",
        "\n",
        "- The learning algorithms work with a one-epoch dataset and without shuffling.\n",
        "- The batch size does not impact the training algorithm, but a small value might slow down reading the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYAoyfYtqHG4"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xete-FbuqJCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f23c0009-af6f-48f7-bfd3-827c43b857e8"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "# Specify the model.\n",
        "model_1 = tfdf.keras.RandomForestModel()\n",
        "\n",
        "# Optionally, add evaluation metrics.\n",
        "model_1.compile(\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model.\n",
        "# \"sys_pipes\" is optional. It enables the display of the training logs.\n",
        "with sys_pipes():\n",
        "  model_1.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-19 10:10:02.203441: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-06-19 10:10:02.207405: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 4s 8ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 2\n",
            "[INFO kernel.cc:393] Number of examples: 74\n",
            "[INFO data_spec_inference.cc:289] 72 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Past1 (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 56 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Past2 (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Past3 (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 74\n",
            "Number of columns: 4\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 4 (100%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 4 (100%)\n",
            "\t0: \"Past1\" CATEGORICAL has-dict vocab-size:1 num-oods:72 (97.2973%)\n",
            "\t1: \"Past2\" CATEGORICAL has-dict vocab-size:2 num-oods:56 (75.6757%) most-frequent:\"<OOD>\" 56 (75.6757%)\n",
            "\t2: \"Past3\" CATEGORICAL has-dict vocab-size:2 num-oods:38 (51.3514%) most-frequent:\"<OOD>\" 38 (51.3514%)\n",
            "\t3: \"__LABEL\" CATEGORICAL integerized vocab-size:54 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Past1\"\n",
            "features: \"Past2\"\n",
            "features: \"Past3\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 74 example(s) and 3 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:0) done accuracy:0.130435 logloss:31.3423\n",
            "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:12) done accuracy:0.0945946 logloss:31.7676\n",
            "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:23) done accuracy:0.121622 logloss:30.3699\n",
            "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:30) done accuracy:0.135135 logloss:29.8907\n",
            "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:42) done accuracy:0.135135 logloss:29.4135\n",
            "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:53) done accuracy:0.121622 logloss:28.5297\n",
            "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:64) done accuracy:0.135135 logloss:28.5299\n",
            "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:71) done accuracy:0.148649 logloss:28.5288\n",
            "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:82) done accuracy:0.162162 logloss:28.5319\n",
            "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:91) done accuracy:0.162162 logloss:28.0877\n",
            "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:84) done accuracy:0.162162 logloss:28.0916\n",
            "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:114) done accuracy:0.162162 logloss:28.1039\n",
            "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:124) done accuracy:0.162162 logloss:28.1003\n",
            "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:134) done accuracy:0.162162 logloss:28.1056\n",
            "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:145) done accuracy:0.162162 logloss:28.1101\n",
            "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:150) done accuracy:0.162162 logloss:28.1138\n",
            "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:161) done accuracy:0.162162 logloss:28.1182\n",
            "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:173) done accuracy:0.162162 logloss:28.121\n",
            "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:184) done accuracy:0.162162 logloss:28.1274\n",
            "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:193) done accuracy:0.162162 logloss:28.1202\n",
            "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:200) done accuracy:0.162162 logloss:28.1237\n",
            "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:214) done accuracy:0.162162 logloss:28.1273\n",
            "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:224) done accuracy:0.162162 logloss:27.6998\n",
            "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:234) done accuracy:0.162162 logloss:27.6997\n",
            "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:244) done accuracy:0.162162 logloss:27.7032\n",
            "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:255) done accuracy:0.162162 logloss:27.706\n",
            "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:264) done accuracy:0.162162 logloss:27.709\n",
            "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:274) done accuracy:0.162162 logloss:27.7107\n",
            "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:283) done accuracy:0.162162 logloss:27.7139\n",
            "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:291) done accuracy:0.162162 logloss:27.7162\n",
            "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:299) done accuracy:0.162162 logloss:27.712\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.162162 logloss:27.712\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpmz8y6eic\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:929] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 1500 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:876] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:797] Use fast generic engine\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLxldl0tyEIK"
      },
      "source": [
        "### Remarks\n",
        "\n",
        "-   No input features are specified. Therefore, **all** the columns will be used as\n",
        "    input features except for the label. \n",
        "- The feature used by the model are shown in the training logs and in the `model.summary()`.\n",
        "-   DFs consume natively numerical, categorical, categorical-set features and\n",
        "    missing-values. Numerical features do not need to be normalized. Categorical\n",
        "    string values do not need to be encoded in a dictionary.\n",
        "-   No training hyper-parameters are specified. Therefore the default\n",
        "    hyper-parameters will be used. Default hyper-parameters provide\n",
        "    reasonable results in most situations.\n",
        "-   Calling `compile` on the model before the `fit` is **optional**. Compile can be used to provide **extra evaluation metrics**.\n",
        "-   Training algorithms **do not** need validation datasets. If a validation dataset is provided, it will only be used to **show metrics**.\n",
        "\n",
        "**Note:** A *Categorical-Set* feature is composed of a set of categorical values (while a *Categorical* is only one value)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSdtNJUArBpl"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udtu_uS1paSu"
      },
      "source": [
        "Let's evaluate our model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUy4ULEMtDXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce57770c-0c96-480e-f6eb-e8966d1120ee"
      },
      "source": [
        "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 256ms/step - loss: 0.0000e+00 - accuracy: 0.0400\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 0.0400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHBFtUeElRYz"
      },
      "source": [
        "## Prepare this model for TensorFlow Serving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbC4lmgfr5Sm"
      },
      "source": [
        "Export the model to the SavedModel format for later re-use e.g.\n",
        "[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08YWGr9U2fza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cf0b93-142d-4a70-aec7-3799cae762af"
      },
      "source": [
        "model_1.save(\"/tmp/my_saved_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Past1, Past2, Past3 with unsupported characters which will be renamed to past1, past2, past3 in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/my_saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/my_saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-8R02_SXpbq"
      },
      "source": [
        "## Plot the model\n",
        "\n",
        "Plotting a decision tree and following the first branches helps learning about decision forests. In some cases, plotting a model can even be used for debugging.\n",
        "\n",
        "Because of the difference in the way they are trained, some models are more interresting to plan than others. Because of the noise injected during training and the depth of the trees, plotting Random Forest is less informative than plotting a CART or the first tree of a Gradient Boosted Tree.\n",
        "\n",
        "Never the less, let's plot the first tree of our Random Forest model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUIxf8N6Yjl0"
      },
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPcL_hDnY7Zy"
      },
      "source": [
        "The root node on the left contains the first condition (`bill_depth_mm >= 16.55`), number of examples (240) and label distribution (the red-blue-green bar).\n",
        "\n",
        "Examples that evaluates true to `bill_depth_mm >= 16.55` are branched to the green path. The other ones are branched to the red path.\n",
        "\n",
        "The deeper the node, the more `pure` they become i.e. the label distribution is biased toward a subset of classes. \n",
        "\n",
        "**Note:** Over the mouse on top of the plot for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ob3ovQ2seVY"
      },
      "source": [
        "## Model tructure and feature importance\n",
        "\n",
        "The overall structure of the model is show with `.summary()`. You will see:\n",
        "\n",
        "-   **Type**: The learning algorithm used to train the model (`Random Forest` in\n",
        "    our case).\n",
        "-   **Task**: The problem solved by the model (`Classification` in our case).\n",
        "-   **Input Features**: The input features of the model.\n",
        "-   **Variable Importance**: Different measures of the importance of each\n",
        "    feature for the model.\n",
        "-   **Out-of-bag evaluation**: The out-of-bag evaluation of the model. This is a\n",
        "    cheap and efficient alternative to cross-validation.\n",
        "-   **Number of {trees, nodes} and other metrics**: Statistics about the\n",
        "    structure of the decisions forests.\n",
        "\n",
        "**Remark:** The summary's content depends on the learning algorithm (e.g.\n",
        "Out-of-bag is only available for Random Forest) and the hyper-parameters (e.g.\n",
        "the *mean-decrease-in-accuracy* variable importance can be disabled in the\n",
        "hyper-parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzXME28Lq7Il"
      },
      "source": [
        "%set_cell_height 300\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ApRpUm02zU"
      },
      "source": [
        "The information in ``summary`` are all available programatically using the model inspector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3xuB3jN1Cww"
      },
      "source": [
        "# The input features\n",
        "model_1.make_inspector().features()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2RBbU51L6s"
      },
      "source": [
        "# The feature importances\n",
        "model_1.make_inspector().variable_importances()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvyRJVk1aEk"
      },
      "source": [
        "The content of the summary and the inspector depends on the learning algorithm (`tfdf.keras.RandomForestModel` in this case) and its hyper-parameters (e.g. `compute_oob_variable_importances=True` will trigger the computation of Out-of-bag variable importances for the Random Forest learner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFVmrHtWXYKY"
      },
      "source": [
        "## Model Self Evaluation\n",
        "\n",
        "During training TFDF models can self evaluate even if no validation dataset is provided to the `fit()` method. The exact logic depends on the model. For example, Random Forest will use Out-of-bag evaluation while Gradient Boosted Trees will use internal train-validation.\n",
        "\n",
        "**Note:** While this evaluation is  computed during training, it is NOT computed on the training dataset and can be used as a low quality evaluation.\n",
        "\n",
        "The model self evaluation is available with the inspector's `evaluation()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZPzyIMmYmsI"
      },
      "source": [
        "model_1.make_inspector().evaluation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSz-jE0Qss_"
      },
      "source": [
        "## Plotting the training logs\n",
        "\n",
        "The training logs show the quality of the model (e.g. accuracy evaluated on the out-of-bag or validation dataset) according to the number of trees in the model. These logs are helpful to study the balance between model size and model quality.\n",
        "\n",
        "The logs are available in multiple ways:\n",
        "\n",
        "1. Displayed in during training if `fit()` is wrapped in `with sys_pipes():` (see example above).\n",
        "1. At the end of the model summary i.e. `model.summary()` (see example above).\n",
        "1. Programmatically, using the model inspector i.e. `model.make_inspector().training_logs()`.\n",
        "1. Using [TensorBoard](https://www.tensorflow.org/tensorboard)\n",
        "\n",
        "Let's try the options 2 and 3:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbRk7xvpTKQG"
      },
      "source": [
        "%set_cell_height 150\n",
        "model_1.make_inspector().training_logs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WynFJCEbhuF_"
      },
      "source": [
        "Let's plot it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzPH7Gggh0g1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = model_1.make_inspector().training_logs()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Logloss (out-of-bag)\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1xzugBRhwuN"
      },
      "source": [
        "This dataset is small. You can see the model converging almost immediately.\n",
        "\n",
        "Let's use TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R_m-JmvU9tu"
      },
      "source": [
        "# This cell start TensorBoard that can be slow.\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Google internal version\n",
        "# %load_ext google3.learning.brain.tensorboard.notebook.extension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6mp7K6HWwqQ"
      },
      "source": [
        "# Clear existing results (if any)\n",
        "!rm -fr \"/tmp/tensorboard_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16NbLILYo124"
      },
      "source": [
        "# Export the meta-data to tensorboard.\n",
        "model_1.make_inspector().export_to_tensorboard(\"/tmp/tensorboard_logs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSsN6aTXW0LJ"
      },
      "source": [
        "# docs_infra: no_execute\n",
        "# Start a tensorboard instance.\n",
        "%tensorboard --logdir \"/tmp/tensorboard_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_tlSccjZ8kE"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/beginner_tensorboard.png\"/> -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phTUr6F1t-_E"
      },
      "source": [
        "## Re-train the model with a different learning algorithm\n",
        "\n",
        "The learning algorithm is defined by the model class. For\n",
        "example, `tfdf.keras.RandomForestModel()` trains a Random Forest, while\n",
        "`tfdf.keras.GradientBoostedTreesModel()` trains a Gradient Boosted Decision\n",
        "Trees.\n",
        "\n",
        "The learning algorithms are listed by calling `tfdf.keras.get_all_models()` or in the\n",
        "[learner list](https://github.com/google/yggdrasil-decision-forests/manual/learners)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwEAAzUZq2m8"
      },
      "source": [
        "tfdf.keras.get_all_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmzvuI78voD4"
      },
      "source": [
        "The description of the learning algorithms and their hyper-parameters are also available in the [API reference](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf) and builtin help:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hONToBav4DE"
      },
      "source": [
        "# help works anywhere.\n",
        "help(tfdf.keras.RandomForestModel)\n",
        "\n",
        "# ? only works in ipython or notebooks, it usually opens on a separate panel.\n",
        "tfdf.keras.RandomForestModel?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuWEYvXaiwhk"
      },
      "source": [
        "## Using a subset of features\n",
        "\n",
        "The previous example did not specify the features, so all the columns were used\n",
        "as input feature (except for the label). The following example shows how to\n",
        "specify input features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgn_LnRz3M7z"
      },
      "source": [
        "feature_1 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
        "feature_2 = tfdf.keras.FeatureUsage(name=\"island\")\n",
        "\n",
        "all_features = [feature_1, feature_2]\n",
        "\n",
        "# Note: This model is only trained with two features. It will not be as good as\n",
        "# the one trained on all features.\n",
        "\n",
        "model_2 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    features=all_features, exclude_non_specified_features=True)\n",
        "\n",
        "model_2.compile(metrics=[\"accuracy\"])\n",
        "model_2.fit(x=train_ds, validation_data=test_ds)\n",
        "\n",
        "print(model_2.evaluate(test_ds, return_dict=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvM84cgCmbUR"
      },
      "source": [
        "**Note:** As expected, the accuracy is lower than previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFmqpivc7x7p"
      },
      "source": [
        "**TF-DF** attaches a **semantics** to each feature. This semantics controls how\n",
        "the feature is used by the model. The following semantics are currently supported:\n",
        "\n",
        "-   **Numerical**: Generally for quantities or counts with full ordering. For\n",
        "    example, the age of a person, or the number of items in a bag. Can be a\n",
        "    float or an integer. Missing values are represented with float(Nan) or with\n",
        "    an empty sparse tensor.\n",
        "-   **Categorical**: Generally for a type/class in finite set of possible values\n",
        "    without ordering. For example, the color RED in the set {RED, BLUE, GREEN}.\n",
        "    Can be a string or an integer. Missing values are represented as \"\" (empty\n",
        "    sting), value -2 or with an empty sparse tensor.\n",
        "-   **Categorical-Set**: A set of categorical values. Great to represent\n",
        "    tokenized text. Can be a string or an integer in a sparse tensor or a\n",
        "    ragged tensor (recommended). The order/index of each item doesn't matter.\n",
        "\n",
        "If not specified, the semantics is inferred from the representation type and shown in the training logs:\n",
        "\n",
        "- int, float (dense or sparse)  Numerical semantics.\n",
        "- str (dense or sparse)  Categorical semantics\n",
        "- int, str (ragged)  Categorical-Set semantics\n",
        "\n",
        "In some cases, the inferred semantics is incorrect. For example: An Enum stored as an integer is semantically categorical, but it will be detected as numerical. In this case, you should specify the semantic argument in the input. The `education_num` field of the Adult dataset is classical example.\n",
        "\n",
        "This dataset doesn't contain such a feature. However, for the demonstration, we will make the model treat the `year` as a categorical feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNRIwLYC8zrp"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "feature_1 = tfdf.keras.FeatureUsage(name=\"year\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL)\n",
        "feature_2 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
        "feature_3 = tfdf.keras.FeatureUsage(name=\"sex\")\n",
        "all_features = [feature_1, feature_2, feature_3]\n",
        "\n",
        "model_3 = tfdf.keras.GradientBoostedTreesModel(features=all_features, exclude_non_specified_features=True)\n",
        "model_3.compile( metrics=[\"accuracy\"])\n",
        "\n",
        "with sys_pipes():\n",
        "  model_3.fit(x=train_ds, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AQaNwihcpP7"
      },
      "source": [
        "Note that `year` is in the list of CATEGORICAL features (unlike the first run)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYrw7nKN40Vm"
      },
      "source": [
        "## Hyper-parameters\n",
        "\n",
        "**Hyper-parameters** are parameters of the training algorithm that impact\n",
        "the quality of the final model. They are specified in the model class\n",
        "constructor. The list of hyper-parameters is visible with the *question mark* colab command (e.g. `?tfdf.keras.GradientBoostedTreesModel`).\n",
        "\n",
        "Alternatively, you can find them on the [TensorFlow Decision Forest Github](https://github.com/tensorflow/decision-forests/keras/wrappers_pre_generated.py) or the [Yggdrasil Decision Forest documentation](https://github.com/google/yggdrasil_decision_forests/documentation/learners).\n",
        "\n",
        "The default hyper-parameters of each algorithm matches approximatively the initial publication paper. To ensure consistancy, new features and their matching hyper-parameters are always disable by default. That's why it is a good idea to tune your hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHgPr4Pt43hv"
      },
      "source": [
        "# A classical but slighly more complex model.\n",
        "model_6 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500, growing_strategy=\"BEST_FIRST_GLOBAL\", max_depth=8)\n",
        "model_6.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uECgPGDc2P4p"
      },
      "source": [
        "# A more complex, but possibly, more accurate model.\n",
        "model_7 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500,\n",
        "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
        "    max_depth=8,\n",
        "    split_axis=\"SPARSE_OBLIQUE\",\n",
        "    categorical_algorithm=\"RANDOM\",\n",
        "    )\n",
        "model_7.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk7wEmUZu3V0"
      },
      "source": [
        "As new training methods are published and implemented, combinaisons of hyper-parameters can emerge as good or almost-always-better than the default parameters. To avoid changing the default hyper-parameter values these good combinaisons are indexed and available as hyper-parameter templates.\n",
        "\n",
        "For example, the `benchmark_rank1` template is the best combinaison on our internal benchmarks. Those templates are versioned to allow training configuration stability e.g. `benchmark_rank1@v1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtrRhMhj3hSu"
      },
      "source": [
        "# A good template of hyper-parameters.\n",
        "model_8 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n",
        "model_8.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSDXcKXB3u6M"
      },
      "source": [
        "The available tempaltes are available with `predefined_hyperparameters`. Note that different learning algorithms have different templates, even if the name is similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQrWI2iv37Bo"
      },
      "source": [
        "# The hyper-parameter templates of the Gradient Boosted Tree model.\n",
        "print(tfdf.keras.GradientBoostedTreesModel.predefined_hyperparameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcX4tov1_lwp"
      },
      "source": [
        "## Feature Preprocessing\n",
        "\n",
        "Pre-processing features is sometimes necessary to consume signals with complex\n",
        "structures, to regularize the model or to apply transfer learning.\n",
        "Pre-processing can be done in one of three ways:\n",
        "\n",
        "1.  Preprocessing on the Pandas dataframe. This solution is easy to implement\n",
        "    and generally suitable for experimentation. However, the\n",
        "    pre-processing logic will not be exported in the model by `model.save()`.\n",
        "\n",
        "2.  [Keras Preprocessing](https://keras.io/guides/preprocessing_layers/): While\n",
        "    more complex than the previous solution, Keras Preprocessing is packaged in\n",
        "    the model.\n",
        "\n",
        "3.  [TensorFlow Feature Columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns):\n",
        "    This API is part of the TF Estimator library (!= Keras) and planned for\n",
        "    deprecation. This solution is interesting when using existing preprocessing\n",
        "    code.\n",
        "\n",
        "Note: Using [TensorFlow Hub](https://www.tensorflow.org/hub)\n",
        "pre-trained embedding is often, a great way to consume text and image with\n",
        "TF-DF. For example, `hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")`. See the [Intermediate tutorial](intermediate_colab.ipynb) for more details.\n",
        "\n",
        "In the next example, pre-process the `body_mass_g` feature into `body_mass_kg = body_mass_g / 1000`. The `bill_length_mm` is consumed without pre-processing. Note that such\n",
        "monotonic transformations have generally no impact on decision forest models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGcIvTeKAApp"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "body_mass_g = tf.keras.layers.Input(shape=(1,), name=\"body_mass_g\")\n",
        "body_mass_kg = body_mass_g / 1000.0\n",
        "\n",
        "bill_length_mm = tf.keras.layers.Input(shape=(1,), name=\"bill_length_mm\")\n",
        "\n",
        "raw_inputs = {\"body_mass_g\": body_mass_g, \"bill_length_mm\": bill_length_mm}\n",
        "processed_inputs = {\"body_mass_kg\": body_mass_kg, \"bill_length_mm\": bill_length_mm}\n",
        "\n",
        "# \"preprocessor\" contains the preprocessing logic.\n",
        "preprocessor = tf.keras.Model(inputs=raw_inputs, outputs=processed_inputs)\n",
        "\n",
        "# \"model_4\" contains both the pre-processing logic and the decision forest.\n",
        "model_4 = tfdf.keras.RandomForestModel(preprocessing=preprocessor)\n",
        "model_4.fit(x=train_ds)\n",
        "\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Bx3Feyjb2o"
      },
      "source": [
        "The following example re-implements the same logic using TensorFlow Feature\n",
        "Columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnwe3sBt-yJk"
      },
      "source": [
        "def g_to_kg(x):\n",
        "  return x / 1000\n",
        "\n",
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(\"body_mass_g\", normalizer_fn=g_to_kg),\n",
        "    tf.feature_column.numeric_column(\"bill_length_mm\"),\n",
        "]\n",
        "\n",
        "preprocessing = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "model_5 = tfdf.keras.RandomForestModel(preprocessing=preprocessing)\n",
        "model_5.compile(metrics=[\"accuracy\"])\n",
        "model_5.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vif6gsAjfzv"
      },
      "source": [
        "## Training a regression model\n",
        "\n",
        "The previous example trains a classification model (TF-DF does not differentiate\n",
        "between binary classification and multi-class classification). In the next\n",
        "example, train a regression model on the\n",
        "[Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone). The\n",
        "objective of this dataset is to predict the number of shell's rings of an\n",
        "abalone.\n",
        "\n",
        "**Note:** The csv file is assembled by appending UCI's header and data files. No preprocessing was applied.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/LivingAbalone.JPG/800px-LivingAbalone.JPG\" width=\"200\"/></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uKI_Uy7RyWN"
      },
      "source": [
        "# Download the dataset.\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/abalone_raw.csv -O /tmp/abalone.csv\n",
        "\n",
        "dataset_df = pd.read_csv(\"/tmp/abalone.csv\")\n",
        "print(dataset_df.head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gjrquQySU7Q"
      },
      "source": [
        "# Split the dataset into a training and testing dataset.\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Name of the label column.\n",
        "label = \"Rings\"\n",
        "\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8fUhQKISqYT"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "# Configure the model.\n",
        "model_7 = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "# Optional.\n",
        "model_7.compile(metrics=[\"mse\"])\n",
        "\n",
        "# Train the model.\n",
        "with sys_pipes():\n",
        "  model_7.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSriIAaMSzwA"
      },
      "source": [
        "# Evaluate the model on the test dataset.\n",
        "evaluation = model_7.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "print(evaluation)\n",
        "print()\n",
        "print(f\"MSE: {evaluation['mse']}\")\n",
        "print(f\"RMSE: {math.sqrt(evaluation['mse'])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S54mR6i9jkhp"
      },
      "source": [
        "## Training a ranking model\n",
        "\n",
        "Finaly, after having trained a classification and a regression models, train a [ranking](https://en.wikipedia.org/wiki/Learning_to_rank) model.\n",
        "\n",
        "The goal of a ranking is to **order** items by importance. The \"value\" of\n",
        "relevance does not matter directly. Ranking a set of *documents* with regard to\n",
        "a user *query* is an example of ranking problem: It is only important to get the right order, where the top documents matter more.\n",
        "\n",
        "TF-DF expects for ranking datasets to be presented in a \"flat\" format. A\n",
        "document+query dataset might look like that:\n",
        "\n",
        "query | document_id | feature_1 | feature_2 | relevance/label\n",
        "----- | ----------- | --------- | --------- | ---------------\n",
        "cat   | 1           | 0.1       | blue      | 4\n",
        "cat   | 2           | 0.5       | green     | 1\n",
        "cat   | 3           | 0.2       | red       | 2\n",
        "dog   | 4           | NA        | red       | 0\n",
        "dog   | 5           | 0.2       | red       | 1\n",
        "dog   | 6           | 0.6       | green     | 1\n",
        "\n",
        "The *relevance/label* is a floating point numerical value between 0 and 5\n",
        "(generally between 0 and 4) where 0 means \"completely unrelated\", 4 means \"very\n",
        "relevant\" and 5 means \"the same as the query\".\n",
        "\n",
        "Interestingly, decision forests are often good rankers, and many\n",
        "state-of-the-art ranking models are decision forests.\n",
        "\n",
        "In this example, use a sample of the\n",
        "[LETOR3](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/#!letor-3-0)\n",
        "dataset. More precisely, we want to download the `OHSUMED.zip` from [the LETOR3 repo](https://onedrive.live.com/?authkey=%21ACnoZZSZVfHPJd0&id=8FEADC23D838BDA8%21107&cid=8FEADC23D838BDA8). This dataset is stored in the\n",
        "libsvm format, so we will need to convert it to csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axD6x1ZivHCS"
      },
      "source": [
        "%set_cell_height 200\n",
        "\n",
        "archive_path = tf.keras.utils.get_file(\"letor.zip\",\n",
        "  \"https://download.microsoft.com/download/E/7/E/E7EABEF1-4C7B-4E31-ACE5-73927950ED5E/Letor.zip\",\n",
        "  extract=True)\n",
        "\n",
        "# Path to the train and test dataset using libsvm format.\n",
        "raw_dataset_path = os.path.join(os.path.dirname(archive_path),\"OHSUMED/Data/All/OHSUMED.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcManr98ZGID"
      },
      "source": [
        "The dataset is stored as a .txt file in a specific format, so first convert it into a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkiM9HJox-e8"
      },
      "source": [
        "def convert_libsvm_to_csv(src_path, dst_path):\n",
        "  \"\"\"Converts a libsvm ranking dataset into a flat csv file.\n",
        "  \n",
        "  Note: This code is specific to the LETOR3 dataset.\n",
        "  \"\"\"\n",
        "  dst_handle = open(dst_path, \"w\")\n",
        "  first_line = True\n",
        "  for src_line in open(src_path,\"r\"):\n",
        "    # Note: The last 3 items are comments.\n",
        "    items = src_line.split(\" \")[:-3]\n",
        "    relevance = items[0]\n",
        "    group = items[1].split(\":\")[1]\n",
        "    features = [ item.split(\":\") for item in items[2:]]\n",
        "\n",
        "    if first_line:\n",
        "      # Csv header\n",
        "      dst_handle.write(\"relevance,group,\" + \",\".join([\"f_\" + feature[0] for feature in features]) + \"\\n\")\n",
        "      first_line = False\n",
        "    dst_handle.write(relevance + \",g_\" + group + \",\" + (\",\".join([feature[1] for feature in features])) + \"\\n\")\n",
        "  dst_handle.close()\n",
        "\n",
        "# Convert the dataset.\n",
        "csv_dataset_path=\"/tmp/ohsumed.csv\"\n",
        "convert_libsvm_to_csv(raw_dataset_path, csv_dataset_path)\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(csv_dataset_path)\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB7bWAja1G-o"
      },
      "source": [
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Display the first 3 examples of the training dataset.\n",
        "train_ds_pd.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQKqN9zN4L00"
      },
      "source": [
        "In this dataset, the `relevance` defines the ground-truth rank among rows of the same `group`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QMbBkCEXxu_"
      },
      "source": [
        "# Name of the relevance and grouping columns.\n",
        "relevance = \"relevance\"\n",
        "\n",
        "ranking_train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)\n",
        "ranking_test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba1gb75SX1rr"
      },
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    task=tfdf.keras.Task.RANKING,\n",
        "    ranking_group=\"group\",\n",
        "    num_trees=50)\n",
        "\n",
        "with sys_pipes():\n",
        "  model_8.fit(x=ranking_train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spZCfxfR3VK0"
      },
      "source": [
        "At this point, keras does not propose any ranking metrics. Instead, the training and validation (a GBDT uses a validation dataset) are shown in the training\n",
        "logs. In this case the loss is `LAMBDA_MART_NDCG5`, and the final (i.e. at\n",
        "the end of the training) NDCG (normalized discounted cumulative gain) is `0.510136` (see line `Final model valid-loss: -0.510136`).\n",
        "\n",
        "Note that the NDCG is a value between 0 and 1. The larget the NDCG, the better\n",
        "the model. For this reason, the loss to be -NDCG.\n",
        "\n",
        "As before, the model can be analysed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4N1R8fM4jFh"
      },
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}