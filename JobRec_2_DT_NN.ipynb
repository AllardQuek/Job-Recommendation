{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JobRec-2-DT-NN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2hYiX6cLve8e",
        "Bu6DaYLAviqb",
        "mYAoyfYtqHG4",
        "oLxldl0tyEIK",
        "tSdtNJUArBpl",
        "GYrw7nKN40Vm",
        "9vif6gsAjfzv",
        "S54mR6i9jkhp"
      ],
      "mount_file_id": "1skNQ6zqoAIuAJP-iI_pJIUZmayAfFSkj",
      "authorship_tag": "ABX9TyOwwqzWAi4rfko/3hKeRyiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllardQuek/Job-Recommendation/blob/main/JobRec_2_DT_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiU3aHS7Gcjl"
      },
      "source": [
        "# Job Recommendation for Undergraduates\n",
        "\n",
        "Based on:\n",
        "1. https://www.tensorflow.org/decision_forests/tutorials/beginner_colab#training_a_ranking_model\n",
        "2. https://www.tensorflow.org/decision_forests/tutorials/intermediate_colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "514JVNiBDTdH"
      },
      "source": [
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S179dVvhDKf6"
      },
      "source": [
        "#@title\n",
        "\n",
        "# Some of the model training logs can cover the full\n",
        "# screen if not compressed to a smaller viewport.\n",
        "# This magic allows setting a max height for a cell.\n",
        "@register_line_magic\n",
        "def set_cell_height(size):\n",
        "  display(\n",
        "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
        "                 str(size) + \"})\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "UscF7xhB3HVr",
        "outputId": "65382979-1d0e-48f0-fe31-c363dd77f34f"
      },
      "source": [
        "%set_cell_height 300\n",
        "!pip3 install tensorflow_decision_forests --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/34/10f20fe95d9882b82b1de8cc03c3642a85b55a40a100b3a274d65f37afbd/tensorflow_decision_forests-0.1.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_decision_forests) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->tensorflow_decision_forests) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.5->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow~=2.5->tensorflow_decision_forests) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow~=2.5->tensorflow_decision_forests) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.5->tensorflow_decision_forests) (0.4.8)\n",
            "Installing collected packages: tensorflow-decision-forests\n",
            "Successfully installed tensorflow-decision-forests-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPK_QX0AFBnO"
      },
      "source": [
        "Install [Wurlitzer](https://pypi.org/project/wurlitzer/). It can be used to show\n",
        "the detailed training logs. This is only needed in colabs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpoOVWzCFKyY",
        "outputId": "36eb10a8-9b2d-4566-a66e-033c0b819f27"
      },
      "source": [
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wurlitzer\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ac/b7082c3d228e600af37ec5cf99697d400328b13350b4d7577c213fa4faca/wurlitzer-2.1.0-py2.py3-none-any.whl\n",
            "Installing collected packages: wurlitzer\n",
            "Successfully installed wurlitzer-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZoyTgq5FWxL"
      },
      "source": [
        "Now let's import all the packages we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8HQ54CtDudY"
      },
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC5SVvaRGpJ7",
        "outputId": "5258f6dd-3e24-4307-8296-4ab47e199318"
      },
      "source": [
        "# Check the version of TensorFlow Decision Forests\n",
        "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TensorFlow Decision Forests v0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea4MbE4tFw9a"
      },
      "source": [
        "## Matchin Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "t4-5MlOQ4s1R",
        "outputId": "26caf703-6434-4b46-a31d-faba41774c73"
      },
      "source": [
        "dataset_df = pd.read_excel(\"/content/drive/MyDrive/Jobs Internships/Matchin Internship/AI ML/Datasets/100datapoints-1.xlsx\")\n",
        "dataset_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.</th>\n",
              "      <th>Name</th>\n",
              "      <th>Current Job Title with Company</th>\n",
              "      <th>Current Job Description</th>\n",
              "      <th>Past Job/Internship Experience 1</th>\n",
              "      <th>Description</th>\n",
              "      <th>Past Internship Experience 2</th>\n",
              "      <th>Description.1</th>\n",
              "      <th>Past Internship Experience 3</th>\n",
              "      <th>Description.2</th>\n",
              "      <th>Skills</th>\n",
              "      <th>School</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Eda Tan</td>\n",
              "      <td>Software Analyst at JPMorgan Chase &amp; Co</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Software Developer at LiveMore</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Amanda Lee</td>\n",
              "      <td>Systems Engineer at HP</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Intern at Embraer</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Byron Elton Tan</td>\n",
              "      <td>Engineer (Vehicle Systems) at HTX (Home Team S...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Engineer Vehicle Systems at MHA</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Kavya Nair</td>\n",
              "      <td>Graduate Design Engineer at Dyson</td>\n",
              "      <td>Design Engineer</td>\n",
              "      <td>Executive Engineer at SMRT</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Seung Kyu Kim</td>\n",
              "      <td>Siri Annotation Analyst AI/ML at Apple</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Freelance Translator at MMD Singapore</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   No.             Name  ... School Unnamed: 12\n",
              "0    1          Eda Tan  ...    NIL         NaN\n",
              "1    2       Amanda Lee  ...    NIL         NaN\n",
              "2    3  Byron Elton Tan  ...    NIL         NaN\n",
              "3    4       Kavya Nair  ...    NIL         NaN\n",
              "4    5    Seung Kyu Kim  ...    NIL         NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu6DaYLAviqb"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBcsZNJHKZBH"
      },
      "source": [
        "def split_it(title):\n",
        "    # Let's get only the title without the company for now\n",
        "    return title.partition(\" at \")[0].strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EPLw8WgwJq9q",
        "outputId": "64b3de68-b1b8-47d8-8954-34e4872e2337"
      },
      "source": [
        "dataset_df[\"CurrentJobTitle\"] = dataset_df[\"Current Job Title with Company\"].apply(split_it)\n",
        "dataset_df[\"Past1\"] = dataset_df[\"Past Job/Internship Experience 1\"].apply(split_it)\n",
        "dataset_df[\"Past2\"] = dataset_df[\"Past Internship Experience 2\"].apply(split_it)\n",
        "dataset_df[\"Past3\"] = dataset_df[\"Past Internship Experience 3\"].apply(split_it)\n",
        "\n",
        "dataset_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No.</th>\n",
              "      <th>Name</th>\n",
              "      <th>Current Job Title with Company</th>\n",
              "      <th>Current Job Description</th>\n",
              "      <th>Past Job/Internship Experience 1</th>\n",
              "      <th>Description</th>\n",
              "      <th>Past Internship Experience 2</th>\n",
              "      <th>Description.1</th>\n",
              "      <th>Past Internship Experience 3</th>\n",
              "      <th>Description.2</th>\n",
              "      <th>Skills</th>\n",
              "      <th>School</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>CurrentJobTitle</th>\n",
              "      <th>Past1</th>\n",
              "      <th>Past2</th>\n",
              "      <th>Past3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>Pranjal Verma</td>\n",
              "      <td>Lead Engineer at Farme</td>\n",
              "      <td>Farme was founded to innovate and bring fully ...</td>\n",
              "      <td>Product Design Engineer at Ideagen</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Clinic Assistant at NUH</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Research, Microsoft Excel, Photoshop, Research...</td>\n",
              "      <td>SUTD Biomedical Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lead Engineer</td>\n",
              "      <td>Product Design Engineer</td>\n",
              "      <td>Clinic Assistant</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>77</td>\n",
              "      <td>Samuel Samsudin Ng</td>\n",
              "      <td>R&amp;D Engineer at STMicroeletronics</td>\n",
              "      <td>- Audio and DSP algorithm development, impleme...</td>\n",
              "      <td>Senior DSP System Design Engineer at STMicroel...</td>\n",
              "      <td>[ ] Assist in analysing of Serious Reportable ...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Research, SolidWorks, C++, FDM, Strategic Plan...</td>\n",
              "      <td>National University of Singapore</td>\n",
              "      <td>Biomedical/Medical Engineering</td>\n",
              "      <td>R&amp;D Engineer</td>\n",
              "      <td>Senior DSP System Design Engineer</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>93</td>\n",
              "      <td>Andy Soh</td>\n",
              "      <td>Strategy &amp; Consulting at Accenture</td>\n",
              "      <td>- IT Talent Strategy\\n - B2B2X Go-to-Market St...</td>\n",
              "      <td>Chief Operations Officer at The Global Citizen...</td>\n",
              "      <td>• Scraped four years’ worth of central bank st...</td>\n",
              "      <td>Data Analyst Intern at Shell</td>\n",
              "      <td>• Developed a consistent pricing strategy to q...</td>\n",
              "      <td>Student Consultant at SMU</td>\n",
              "      <td>• Developed a data analytics framework to exam...</td>\n",
              "      <td>Microsoft Office, Management, Social Media, Re...</td>\n",
              "      <td>Singapore Management University</td>\n",
              "      <td>Economics</td>\n",
              "      <td>Strategy &amp; Consulting</td>\n",
              "      <td>Chief Operations Officer</td>\n",
              "      <td>Data Analyst Intern</td>\n",
              "      <td>Student Consultant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>59</td>\n",
              "      <td>YuLong L.</td>\n",
              "      <td>Data Analyst at Tencent</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Data Analyst and Business Intelligence Intern ...</td>\n",
              "      <td>NIl</td>\n",
              "      <td>Software Engineer Intern at JPMorgan Chase &amp; Co.</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Project Management Intern at PulseSync</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Team Leadership, Interpersonal, Microsoft Word...</td>\n",
              "      <td>Singapore Management University</td>\n",
              "      <td>Information Systems</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Data Analyst and Business Intelligence Intern</td>\n",
              "      <td>Software Engineer Intern</td>\n",
              "      <td>Project Management Intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97</td>\n",
              "      <td>Jasvin Wuu</td>\n",
              "      <td>Executive Civil Engineer at Urban Redevelopmen...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Engineer at Arup</td>\n",
              "      <td>• Coordinated regional end-to-end quote delive...</td>\n",
              "      <td>Commercial Channel Program Intern at Cisco</td>\n",
              "      <td>• Motivated 1000+ APAC midmarket Partners over...</td>\n",
              "      <td>Corporate Strategy Intern at SGX</td>\n",
              "      <td>• Contributed insights on a $2 million M&amp;A tar...</td>\n",
              "      <td>Microsoft Office, Microsoft Excel, Teamwork, R...</td>\n",
              "      <td>National University of Singapore</td>\n",
              "      <td>Economics</td>\n",
              "      <td>Executive Civil Engineer</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Commercial Channel Program Intern</td>\n",
              "      <td>Corporate Strategy Intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Wen Ting Leong</td>\n",
              "      <td>Associate Product Manager at Shopee\\n</td>\n",
              "      <td>Listing Department in Shopee</td>\n",
              "      <td>Project Engineering Intern at Ramboll Manageme...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>SolidWorks, Adobe Photoshop, Adobe Illustrator...</td>\n",
              "      <td>SUTD Mechanical Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Associate Product Manager</td>\n",
              "      <td>Project Engineering Intern</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>Albert Suryanto</td>\n",
              "      <td>Data Scientist at Bambu B2B Robo Advisor</td>\n",
              "      <td>Bambu is the global leader in digital wealth t...</td>\n",
              "      <td>Software Engineer at nucon.io</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Coding Course Instructor at First Code Academy</td>\n",
              "      <td>• Lead Instructor for coding lessons conducted...</td>\n",
              "      <td>SAP Leonardo Machine Learning - Business Devel...</td>\n",
              "      <td>• Restructured and improved the weekly Machine...</td>\n",
              "      <td>Data Visualization, Data Analysis, Tableau, R,...</td>\n",
              "      <td>SUTD Systems Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>Coding Course Instructor</td>\n",
              "      <td>SAP Leonardo Machine Learning - Business Devel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Dominic Cordeiro</td>\n",
              "      <td>Software Engineer at NCS Group</td>\n",
              "      <td>Developed backend APIs for usage by the front ...</td>\n",
              "      <td>Summer Intern NCS Group</td>\n",
              "      <td>Vehicle Systems Engineer</td>\n",
              "      <td>Image Processing 3D Intern at Panasonic R&amp;D Ce...</td>\n",
              "      <td>Integrated the hardware and software systems t...</td>\n",
              "      <td>Technik-Square Engineering Intern at Hope Technik</td>\n",
              "      <td>Merged the hardware system on the Autonomous D...</td>\n",
              "      <td>Robotics, SolidWorks, Autodesk Fusion 360, 3D ...</td>\n",
              "      <td>SUTD Electrical and Electronics Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>Summer Intern NCS Group</td>\n",
              "      <td>Image Processing 3D Intern</td>\n",
              "      <td>Technik-Square Engineering Intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>74</td>\n",
              "      <td>Li Yi Ng</td>\n",
              "      <td>Product Development Engineer at JMS Singapore ...</td>\n",
              "      <td>Product re-engineering and evaluation from fun...</td>\n",
              "      <td>Digital Marketing Intern at Able Best Employme...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Community Programs Intern at Asian Community D...</td>\n",
              "      <td>Creating curriculum for pilot resident leaders...</td>\n",
              "      <td>Stategic Marketing Intern at KPMG</td>\n",
              "      <td>Synthesized an \"Investment in Taiwan 2018\" bro...</td>\n",
              "      <td>Communications, InDesign, Social Media Marketi...</td>\n",
              "      <td>Yale-NUS College</td>\n",
              "      <td>Economics</td>\n",
              "      <td>Product Development Engineer</td>\n",
              "      <td>Digital Marketing Intern</td>\n",
              "      <td>Community Programs Intern</td>\n",
              "      <td>Stategic Marketing Intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>Jiahao Tan</td>\n",
              "      <td>Senior Associate, Airport Development at Chang...</td>\n",
              "      <td>Changi East Terminal 5 Planning Division</td>\n",
              "      <td>Head Coach and Program Lead X-Culture</td>\n",
              "      <td>Data Analytics Intern with the Consumer Home d...</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "      <td>Data Analysis, Public Speaking, Business Analy...</td>\n",
              "      <td>SUTD Systems Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Senior Associate, Airport Development</td>\n",
              "      <td>Head Coach and Program Lead X-Culture</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    No.  ...                                              Past3\n",
              "13   14  ...                                                NIL\n",
              "76   77  ...                                                NIL\n",
              "92   93  ...                                 Student Consultant\n",
              "58   59  ...                          Project Management Intern\n",
              "96   97  ...                          Corporate Strategy Intern\n",
              "6     7  ...                                                NIL\n",
              "36   37  ...  SAP Leonardo Machine Learning - Business Devel...\n",
              "7     8  ...                  Technik-Square Engineering Intern\n",
              "73   74  ...                          Stategic Marketing Intern\n",
              "33   34  ...                                                NIL\n",
              "\n",
              "[10 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "3lExWIN-OaT3",
        "outputId": "632bc784-6e0f-4aaa-97e1-9ac1398d19bb"
      },
      "source": [
        "# Pick only the columns we need for training/prediction\n",
        "dataset_df = dataset_df[[\"CurrentJobTitle\", \"Past1\", \"Past2\", \"Past3\"]]\n",
        "dataset_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CurrentJobTitle</th>\n",
              "      <th>Past1</th>\n",
              "      <th>Past2</th>\n",
              "      <th>Past3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7</td>\n",
              "      <td>Software Engineering Intern</td>\n",
              "      <td>Product Manager</td>\n",
              "      <td>Summer Technology Analyst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>68</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Commercial Channel Program Intern</td>\n",
              "      <td>Corporate Strategy Intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>32</td>\n",
              "      <td>Consultant, Advanced Analytics PwC Singapore</td>\n",
              "      <td>Lean Project Student Consultant</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>26</td>\n",
              "      <td>Associate Researcher Intern</td>\n",
              "      <td>Intern</td>\n",
              "      <td>Product Developer Intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>22</td>\n",
              "      <td>Intern</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>31</td>\n",
              "      <td>Co-Op Engineer Intern</td>\n",
              "      <td>Manufacturing Technology &amp; Strategy</td>\n",
              "      <td>Commercial &amp; Engineering Systems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6</td>\n",
              "      <td>Project Management Intern</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>66</td>\n",
              "      <td>Analyst</td>\n",
              "      <td>Student Market Researcher</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>25</td>\n",
              "      <td>Emerging Solution Engineer</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>45</td>\n",
              "      <td>Management Associate</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    CurrentJobTitle  ...                             Past3\n",
              "17                7  ...         Summer Technology Analyst\n",
              "96               68  ...         Corporate Strategy Intern\n",
              "40               32  ...                               NIL\n",
              "89               26  ...          Product Developer Intern\n",
              "28               22  ...                               NIL\n",
              "38               31  ...  Commercial & Engineering Systems\n",
              "20                6  ...                               NIL\n",
              "94               66  ...                               NIL\n",
              "31               25  ...                               NIL\n",
              "61               45  ...                               NIL\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUAc4zTAHKvC"
      },
      "source": [
        "TF-DF supports numerical, categorical amd missing feature types natively (differently than NN based models), therefore there is no need for preprocessing in the form of one-hot encoding, normalization or extra `is_present` feature.\n",
        "\n",
        "Labels are a bit different: Keras metrics expect integers. The label (`Current Job Title with Company`) is stored as a string, so let's convert it into an integer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcfEVRWlHMf0",
        "outputId": "8539b60a-f0be-434c-f12c-fc8a53d3b088"
      },
      "source": [
        "# label = \"Current Job Title with Company\"\n",
        "label = \"CurrentJobTitle\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label classes: ['Software Analyst', 'Systems Engineer', 'Engineer (Vehicle Systems)', 'Graduate Design Engineer', 'Siri Annotation Analyst AI/ML', 'User Experience Designer', 'Associate Product Manager', 'Software Engineer', 'R&D Engineer', 'Consulting Analyst', 'Engineer', 'Lead Engineer', 'Program Manager', 'Software Development Engineer', 'Banker', 'Product Analyst - South Asia', 'Regional Supply & Inventory Planner - Energy Generation Program Associate', 'Financial Consultant / Career Advisor', 'Business Integration Analyst', 'Advisory Associate - Technology Risk', 'Emerging Technology Engineer', 'Sales Engineer', 'Associate Consultant', 'Market Risk Analyst', 'Associate Data Scientist', 'Associate Solution Engineer', 'Business Analyst', 'Senior Associate, Airport Development', 'Growth and Marketing Associate', 'Senior Engineer', 'Data Scientist', 'Product Development Engineer', 'CEO & C0-Founder Everything Analytics', 'Marketing Executive', 'Business Analyst - Ministry Of Communications and Information', 'Pega Developer', 'Cloud Solutions Architect | Management Associate', 'Ernst & Young - Associate', 'User Experience Architect', 'DZH International - Software Specialist', 'Regional Data Analyst', 'Data Analyst', 'Global Data Analyst', 'Data Analyst Intern', 'Technology Consultant', 'Business Technology Consultant', 'Tech Consultant', 'Co-Founder & CEO', 'Product Manager', 'Product Manager, IoT', 'Product Engineer', 'AI Product Engineer', 'Artificial Intelligence Engineer', 'Technology Associate', 'Artificial Intelligence Apprentice', 'Research And Development Intern', 'Research and Development Executive', 'Research Technologist', 'UI Developer', 'UI/UX Developer', 'UI/UX Developer Trainee', 'Market Data Analyst', 'Customer Insights Manager', 'AI Apprentice', 'Strategy & Consulting', 'Senior Marketing Lead', 'Data & Analytics', 'Mechanical Engineer', 'Executive Civil Engineer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4pFu86ZG0lH"
      },
      "source": [
        "Split the dataset into training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2HDtlh_G02N",
        "outputId": "a45a4fe6-6b9c-4934-a9f7-0a8d2dc62969"
      },
      "source": [
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71 examples in training, 28 examples for testing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cGUjoeJOpFy"
      },
      "source": [
        "Convert the pandas dataframe (`pd.Dataframe`) into tensorflow datasets (`tf.data.Dataset`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaQ_uL9YOixR"
      },
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe5RpVtxOwrV"
      },
      "source": [
        "**Notes:** `pd_dataframe_to_tf_dataset` could have converted the label to integer for you.\n",
        "\n",
        "And, if you wanted to create the `tf.data.Dataset` yourself, there is a couple of things to remember:\n",
        "\n",
        "- The learning algorithms work with a one-epoch dataset and without shuffling.\n",
        "- The batch size does not impact the training algorithm, but a small value might slow down reading the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iil_oyOhCNx6"
      },
      "source": [
        "## Use a pretrained text embedding (Universal Sentence Encoder)\n",
        "\n",
        "The previous example trained a Random Forest using raw text features. This example will use a pre-trained TF-Hub embedding to convert text features into a dense embedding, and then train a Random Forest on top of it. In this situation, the Random Forest will only \"see\" the numerical output of the embedding (i.e. it will not see the raw text). \n",
        "\n",
        "In this experiment,  will use the [Universal-Sentence-Encoder](https://tfhub.dev/google/universal-sentence-encoder/4). Different pre-trained embeddings might be suited for different types of text (e.g. different language, different task) but also for other type of structured features (e.g. images).\n",
        "\n",
        "**Note:** This embedding is large (1GB) and therefore the final model will be slow to run (compared to classical decision tree inference).\n",
        "\n",
        "The embedding module can be applied in one of two places:\n",
        "\n",
        "1. During the dataset preparation.\n",
        "2. In the pre-processing stage of the model.\n",
        "\n",
        "The second option is often preferable: Packaging the embedding in the model makes the model easier to use (and harder to misuse).\n",
        "\n",
        "First install TF-Hub:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYGXim_DskC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27769b94-9920-422f-d649-092c639f882a"
      },
      "source": [
        "!pip install --upgrade tensorflow-hub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNSEhJgjEXww"
      },
      "source": [
        "Unlike before, you don't need to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lmKHdnoN7W2_",
        "outputId": "8a769aa6-0b07-4cdb-d182-b4b907495c91"
      },
      "source": [
        "# Create a copy of the dataset\n",
        "use_df = dataset_df\n",
        "use_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CurrentJobTitle</th>\n",
              "      <th>Past1</th>\n",
              "      <th>Past2</th>\n",
              "      <th>Past3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Software Developer</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Intern</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Engineer Vehicle Systems</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Executive Engineer</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Freelance Translator</td>\n",
              "      <td>NIL</td>\n",
              "      <td>NIL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CurrentJobTitle                     Past1 Past2 Past3\n",
              "0                0        Software Developer   NIL   NIL\n",
              "1                1                    Intern   NIL   NIL\n",
              "2                2  Engineer Vehicle Systems   NIL   NIL\n",
              "3                3        Executive Engineer   NIL   NIL\n",
              "4                4      Freelance Translator   NIL   NIL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZC3O6SR_rXf",
        "outputId": "983b76e5-d89c-4f39-d63a-248da45e1565"
      },
      "source": [
        "train_ds_pd_pasts, test_ds_pd_pasts = split_dataset(use_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "train_ds_use = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd_pasts, label=label)\n",
        "test_ds_use = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd_pasts, label=label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70 examples in training, 29 examples for testing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEsd8q_ESpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "303a52da-3e6a-4ec6-ecba-fb9abeb1bd74"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "# NNLM (https://tfhub.dev/google/nnlm-en-dim128/2) is also a good choice.\n",
        "hub_url = \"http://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "embedding = hub.KerasLayer(hub_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rR-nbwo98_x",
        "outputId": "4e2c2b53-ced1-4742-e059-83d1e94b98c4"
      },
      "source": [
        "sentence = tf.keras.layers.Input(shape=(), name=\"Past1\", dtype=tf.string)\n",
        "sentence2 = tf.keras.layers.Input(shape=(), name=\"Past2\", dtype=tf.string)\n",
        "sentence3 = tf.keras.layers.Input(shape=(), name=\"Past3\", dtype=tf.string)\n",
        "\n",
        "embedded_sentence = embedding(sentence)\n",
        "embedded_sentence2 = embedding(sentence2)\n",
        "embedded_sentence3 = embedding(sentence3)\n",
        "\n",
        "raw_inputs = {\"Past1\": sentence, \n",
        "              \"Past2\": sentence2, \n",
        "              \"Past3\": sentence3, }\n",
        "processed_inputs = {\"embedded_sentence\": embedded_sentence,\n",
        "                    \"embedded_sentence2\": embedded_sentence2,\n",
        "                    \"embedded_sentence3\": embedded_sentence3,}\n",
        "preprocessor = tf.keras.Model(inputs=raw_inputs, outputs=processed_inputs)\n",
        "\n",
        "model_2 = tfdf.keras.RandomForestModel(\n",
        "    preprocessing=preprocessor,\n",
        "    num_trees=100)\n",
        "model_2.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "with sys_pipes():\n",
        "  model_2.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 21s 34ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 2\n",
            "[INFO kernel.cc:393] Number of examples: 70\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 70\n",
            "Number of columns: 1537\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 1536 (99.9349%)\n",
            "\tCATEGORICAL: 1 (0.0650618%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 1536 (99.9349%)\n",
            "\t0: \"embedded_sentence.0\" NUMERICAL mean:0.0357989 min:-0.0590259 max:0.0750633 sd:0.031479\n",
            "\t1: \"embedded_sentence.1\" NUMERICAL mean:-0.00258252 min:-0.0682073 max:0.0720418 sd:0.0350268\n",
            "\t2: \"embedded_sentence.10\" NUMERICAL mean:-0.0271788 min:-0.0757238 max:0.0467065 sd:0.0301914\n",
            "\t3: \"embedded_sentence.100\" NUMERICAL mean:0.0386509 min:-0.0493771 max:0.0773731 sd:0.0346089\n",
            "\t4: \"embedded_sentence.101\" NUMERICAL mean:0.0288267 min:-0.0472424 max:0.0753225 sd:0.0313636\n",
            "\t5: \"embedded_sentence.102\" NUMERICAL mean:-0.019411 min:-0.0761533 max:0.0456833 sd:0.0300101\n",
            "\t6: \"embedded_sentence.103\" NUMERICAL mean:0.00242115 min:-0.0547931 max:0.0798723 sd:0.0386369\n",
            "\t7: \"embedded_sentence.104\" NUMERICAL mean:-0.0432118 min:-0.0856407 max:0.0697963 sd:0.0408061\n",
            "\t8: \"embedded_sentence.105\" NUMERICAL mean:0.0264155 min:-0.0733326 max:0.0788725 sd:0.0386794\n",
            "\t9: \"embedded_sentence.106\" NUMERICAL mean:0.0260499 min:-0.0653176 max:0.081387 sd:0.0351422\n",
            "\t10: \"embedded_sentence.107\" NUMERICAL mean:-0.00269239 min:-0.0690995 max:0.0717704 sd:0.0343817\n",
            "\t11: \"embedded_sentence.108\" NUMERICAL mean:-0.00345839 min:-0.0836577 max:0.0664608 sd:0.0365274\n",
            "\t12: \"embedded_sentence.109\" NUMERICAL mean:-0.0132133 min:-0.081663 max:0.0793973 sd:0.0433651\n",
            "\t13: \"embedded_sentence.11\" NUMERICAL mean:-0.0130599 min:-0.0802656 max:0.0717064 sd:0.0411651\n",
            "\t14: \"embedded_sentence.110\" NUMERICAL mean:0.0140889 min:-0.0657707 max:0.0889559 sd:0.030432\n",
            "\t15: \"embedded_sentence.111\" NUMERICAL mean:0.00523139 min:-0.0731574 max:0.076795 sd:0.0349854\n",
            "\t16: \"embedded_sentence.112\" NUMERICAL mean:0.00755939 min:-0.0527378 max:0.0722788 sd:0.0363022\n",
            "\t17: \"embedded_sentence.113\" NUMERICAL mean:0.0191944 min:-0.0781491 max:0.0694913 sd:0.0325555\n",
            "\t18: \"embedded_sentence.114\" NUMERICAL mean:0.00694588 min:-0.0739587 max:0.0728539 sd:0.0391611\n",
            "\t19: \"embedded_sentence.115\" NUMERICAL mean:-0.0518264 min:-0.0828875 max:0.0849213 sd:0.0256089\n",
            "\t20: \"embedded_sentence.116\" NUMERICAL mean:-0.0187063 min:-0.0768545 max:0.0836307 sd:0.0416607\n",
            "\t21: \"embedded_sentence.117\" NUMERICAL mean:0.00451035 min:-0.0675856 max:0.0638161 sd:0.0319481\n",
            "\t22: \"embedded_sentence.118\" NUMERICAL mean:0.0138233 min:-0.0844371 max:0.0746118 sd:0.0436507\n",
            "\t23: \"embedded_sentence.119\" NUMERICAL mean:0.0239095 min:-0.073622 max:0.0821238 sd:0.0450366\n",
            "\t24: \"embedded_sentence.12\" NUMERICAL mean:0.0152912 min:-0.050697 max:0.0784328 sd:0.0333271\n",
            "\t25: \"embedded_sentence.120\" NUMERICAL mean:-0.00224582 min:-0.0733434 max:0.0830014 sd:0.0404436\n",
            "\t26: \"embedded_sentence.121\" NUMERICAL mean:-0.00267929 min:-0.0780679 max:0.076483 sd:0.0393919\n",
            "\t27: \"embedded_sentence.122\" NUMERICAL mean:0.019281 min:-0.0796893 max:0.0761701 sd:0.0396546\n",
            "\t28: \"embedded_sentence.123\" NUMERICAL mean:0.0160528 min:-0.0765565 max:0.0756669 sd:0.0320424\n",
            "\t29: \"embedded_sentence.124\" NUMERICAL mean:-0.0325448 min:-0.0729553 max:0.066743 sd:0.0320239\n",
            "\t30: \"embedded_sentence.125\" NUMERICAL mean:0.0434177 min:-0.0420882 max:0.0820163 sd:0.0274992\n",
            "\t31: \"embedded_sentence.126\" NUMERICAL mean:-0.0115929 min:-0.0701076 max:0.0849505 sd:0.0366848\n",
            "\t32: \"embedded_sentence.127\" NUMERICAL mean:0.0111331 min:-0.0788968 max:0.0772092 sd:0.0368922\n",
            "\t33: \"embedded_sentence.128\" NUMERICAL mean:-0.035097 min:-0.0755569 max:0.0444558 sd:0.0256648\n",
            "\t34: \"embedded_sentence.129\" NUMERICAL mean:0.0399853 min:-0.0539551 max:0.0796494 sd:0.0316719\n",
            "\t35: \"embedded_sentence.13\" NUMERICAL mean:-0.00697639 min:-0.0758569 max:0.0735503 sd:0.0389113\n",
            "\t36: \"embedded_sentence.130\" NUMERICAL mean:-0.051926 min:-0.0936066 max:0.023117 sd:0.0282734\n",
            "\t37: \"embedded_sentence.131\" NUMERICAL mean:-0.0194559 min:-0.0778834 max:0.0863042 sd:0.0382361\n",
            "\t38: \"embedded_sentence.132\" NUMERICAL mean:0.0370249 min:-0.0316944 max:0.103266 sd:0.0301988\n",
            "\t39: \"embedded_sentence.133\" NUMERICAL mean:0.0433694 min:-0.0572975 max:0.0804199 sd:0.0325525\n",
            "\t40: \"embedded_sentence.134\" NUMERICAL mean:0.0421633 min:-0.0284754 max:0.0840883 sd:0.0242691\n",
            "\t41: \"embedded_sentence.135\" NUMERICAL mean:-2.36929e-06 min:-0.0722589 max:0.0596836 sd:0.0323746\n",
            "\t42: \"embedded_sentence.136\" NUMERICAL mean:0.00181525 min:-0.0926869 max:0.0897456 sd:0.0329864\n",
            "\t43: \"embedded_sentence.137\" NUMERICAL mean:0.035869 min:-0.0650464 max:0.0847259 sd:0.0309711\n",
            "\t44: \"embedded_sentence.138\" NUMERICAL mean:0.032815 min:-0.0195636 max:0.0660763 sd:0.0215276\n",
            "\t45: \"embedded_sentence.139\" NUMERICAL mean:-0.0325425 min:-0.0861103 max:0.0733125 sd:0.0427728\n",
            "\t46: \"embedded_sentence.14\" NUMERICAL mean:-0.00329819 min:-0.086262 max:0.0620863 sd:0.0418281\n",
            "\t47: \"embedded_sentence.140\" NUMERICAL mean:-0.045931 min:-0.0827778 max:0.048775 sd:0.0284278\n",
            "\t48: \"embedded_sentence.141\" NUMERICAL mean:-0.012463 min:-0.0562975 max:0.0664124 sd:0.0251422\n",
            "\t49: \"embedded_sentence.142\" NUMERICAL mean:-0.00529304 min:-0.0660143 max:0.0594348 sd:0.0334141\n",
            "\t50: \"embedded_sentence.143\" NUMERICAL mean:-0.0125837 min:-0.0764418 max:0.0670428 sd:0.0376273\n",
            "\t51: \"embedded_sentence.144\" NUMERICAL mean:0.0264748 min:-0.0588617 max:0.082957 sd:0.0329372\n",
            "\t52: \"embedded_sentence.145\" NUMERICAL mean:-0.040364 min:-0.0876573 max:0.073562 sd:0.0467878\n",
            "\t53: \"embedded_sentence.146\" NUMERICAL mean:-0.0279435 min:-0.0836762 max:0.0295818 sd:0.027809\n",
            "\t54: \"embedded_sentence.147\" NUMERICAL mean:0.00198262 min:-0.0739258 max:0.0745283 sd:0.0349474\n",
            "\t55: \"embedded_sentence.148\" NUMERICAL mean:0.0304077 min:-0.0801811 max:0.0799109 sd:0.0356621\n",
            "\t56: \"embedded_sentence.149\" NUMERICAL mean:0.00904397 min:-0.0939994 max:0.0844932 sd:0.040064\n",
            "\t57: \"embedded_sentence.15\" NUMERICAL mean:-0.0212384 min:-0.0695053 max:0.083231 sd:0.0348616\n",
            "\t58: \"embedded_sentence.150\" NUMERICAL mean:0.00633316 min:-0.0771131 max:0.0721757 sd:0.0398287\n",
            "\t59: \"embedded_sentence.151\" NUMERICAL mean:0.0406751 min:-0.0427358 max:0.0733965 sd:0.0252172\n",
            "\t60: \"embedded_sentence.152\" NUMERICAL mean:-0.0462958 min:-0.0779232 max:0.0570801 sd:0.0294299\n",
            "\t61: \"embedded_sentence.153\" NUMERICAL mean:-0.0253312 min:-0.0835418 max:0.0512224 sd:0.0350662\n",
            "\t62: \"embedded_sentence.154\" NUMERICAL mean:-0.0161924 min:-0.0809136 max:0.0795221 sd:0.0459371\n",
            "\t63: \"embedded_sentence.155\" NUMERICAL mean:-0.0164018 min:-0.0775489 max:0.0603761 sd:0.0328239\n",
            "\t64: \"embedded_sentence.156\" NUMERICAL mean:-0.0161381 min:-0.0869544 max:0.0888138 sd:0.0494344\n",
            "\t65: \"embedded_sentence.157\" NUMERICAL mean:-0.0253225 min:-0.0895235 max:0.0675001 sd:0.0399161\n",
            "\t66: \"embedded_sentence.158\" NUMERICAL mean:-0.018398 min:-0.0768666 max:0.0697046 sd:0.0375333\n",
            "\t67: \"embedded_sentence.159\" NUMERICAL mean:-0.0148381 min:-0.0773874 max:0.0868211 sd:0.0392598\n",
            "\t68: \"embedded_sentence.16\" NUMERICAL mean:-0.0114608 min:-0.0735041 max:0.0767334 sd:0.0334791\n",
            "\t69: \"embedded_sentence.160\" NUMERICAL mean:-0.00956927 min:-0.0814909 max:0.0790504 sd:0.0401001\n",
            "\t70: \"embedded_sentence.161\" NUMERICAL mean:0.0203402 min:-0.0647048 max:0.0816067 sd:0.0397832\n",
            "\t71: \"embedded_sentence.162\" NUMERICAL mean:-0.0292105 min:-0.0766149 max:0.071434 sd:0.0325197\n",
            "\t72: \"embedded_sentence.163\" NUMERICAL mean:0.0324153 min:-0.070381 max:0.0765828 sd:0.0311806\n",
            "\t73: \"embedded_sentence.164\" NUMERICAL mean:-0.00963655 min:-0.0654363 max:0.0662384 sd:0.0350827\n",
            "\t74: \"embedded_sentence.165\" NUMERICAL mean:0.021802 min:-0.0860975 max:0.0844574 sd:0.0516638\n",
            "\t75: \"embedded_sentence.166\" NUMERICAL mean:0.0135611 min:-0.057509 max:0.10583 sd:0.0359591\n",
            "\t76: \"embedded_sentence.167\" NUMERICAL mean:-0.0342297 min:-0.0864582 max:0.0809782 sd:0.0426746\n",
            "\t77: \"embedded_sentence.168\" NUMERICAL mean:0.00173938 min:-0.0753964 max:0.0665381 sd:0.0349471\n",
            "\t78: \"embedded_sentence.169\" NUMERICAL mean:-0.030231 min:-0.0917111 max:0.0652312 sd:0.036928\n",
            "\t79: \"embedded_sentence.17\" NUMERICAL mean:-0.0091994 min:-0.0768916 max:0.0680797 sd:0.0385454\n",
            "\t80: \"embedded_sentence.170\" NUMERICAL mean:-0.0225071 min:-0.0825829 max:0.0660808 sd:0.0348329\n",
            "\t81: \"embedded_sentence.171\" NUMERICAL mean:0.0351379 min:-0.0883627 max:0.0717479 sd:0.027005\n",
            "\t82: \"embedded_sentence.172\" NUMERICAL mean:0.00425772 min:-0.0694913 max:0.0918154 sd:0.0375819\n",
            "\t83: \"embedded_sentence.173\" NUMERICAL mean:-0.010902 min:-0.0719187 max:0.0706426 sd:0.0369805\n",
            "\t84: \"embedded_sentence.174\" NUMERICAL mean:0.0295471 min:-0.0622056 max:0.0759203 sd:0.0407971\n",
            "\t85: \"embedded_sentence.175\" NUMERICAL mean:0.0126318 min:-0.075479 max:0.081728 sd:0.0381114\n",
            "\t86: \"embedded_sentence.176\" NUMERICAL mean:0.0331165 min:-0.0828949 max:0.0772533 sd:0.0344461\n",
            "\t87: \"embedded_sentence.177\" NUMERICAL mean:-0.0273074 min:-0.0746439 max:0.0607743 sd:0.0330872\n",
            "\t88: \"embedded_sentence.178\" NUMERICAL mean:-0.000281122 min:-0.0761978 max:0.075935 sd:0.0388362\n",
            "\t89: \"embedded_sentence.179\" NUMERICAL mean:0.0111914 min:-0.0653488 max:0.0790405 sd:0.0313903\n",
            "\t90: \"embedded_sentence.18\" NUMERICAL mean:0.00879483 min:-0.0631266 max:0.0779209 sd:0.0372382\n",
            "\t91: \"embedded_sentence.180\" NUMERICAL mean:0.00203155 min:-0.0671686 max:0.067423 sd:0.0366902\n",
            "\t92: \"embedded_sentence.181\" NUMERICAL mean:0.0304307 min:-0.0890252 max:0.089172 sd:0.0432476\n",
            "\t93: \"embedded_sentence.182\" NUMERICAL mean:0.00813597 min:-0.057092 max:0.0766807 sd:0.0360551\n",
            "\t94: \"embedded_sentence.183\" NUMERICAL mean:-0.0352587 min:-0.0809291 max:0.0441239 sd:0.0324074\n",
            "\t95: \"embedded_sentence.184\" NUMERICAL mean:0.055026 min:-0.0738476 max:0.0837302 sd:0.0317252\n",
            "\t96: \"embedded_sentence.185\" NUMERICAL mean:0.0167183 min:-0.0685253 max:0.0812425 sd:0.0366366\n",
            "\t97: \"embedded_sentence.186\" NUMERICAL mean:-0.0461993 min:-0.0830524 max:0.0558014 sd:0.0377446\n",
            "\t98: \"embedded_sentence.187\" NUMERICAL mean:0.00250006 min:-0.0560024 max:0.0685151 sd:0.0350797\n",
            "\t99: \"embedded_sentence.188\" NUMERICAL mean:0.00262746 min:-0.07694 max:0.0555927 sd:0.0351634\n",
            "\t100: \"embedded_sentence.189\" NUMERICAL mean:-0.00964132 min:-0.0667877 max:0.0567525 sd:0.0267113\n",
            "\t101: \"embedded_sentence.19\" NUMERICAL mean:-0.0473124 min:-0.0991603 max:0.0872216 sd:0.0469279\n",
            "\t102: \"embedded_sentence.190\" NUMERICAL mean:0.0413631 min:-0.0599653 max:0.0837345 sd:0.0386816\n",
            "\t103: \"embedded_sentence.191\" NUMERICAL mean:-0.0224901 min:-0.0713499 max:0.0699259 sd:0.030901\n",
            "\t104: \"embedded_sentence.192\" NUMERICAL mean:0.0150031 min:-0.0580127 max:0.0793234 sd:0.0361588\n",
            "\t105: \"embedded_sentence.193\" NUMERICAL mean:0.00273055 min:-0.0748761 max:0.0524854 sd:0.0312595\n",
            "\t106: \"embedded_sentence.194\" NUMERICAL mean:-0.0179023 min:-0.0826108 max:0.0551791 sd:0.0309254\n",
            "\t107: \"embedded_sentence.195\" NUMERICAL mean:0.0438143 min:-0.0829148 max:0.0832021 sd:0.0444817\n",
            "\t108: \"embedded_sentence.196\" NUMERICAL mean:0.0276212 min:-0.0618218 max:0.0918485 sd:0.0309669\n",
            "\t109: \"embedded_sentence.197\" NUMERICAL mean:0.0269774 min:-0.0499653 max:0.0878713 sd:0.0349793\n",
            "\t110: \"embedded_sentence.198\" NUMERICAL mean:-0.00475977 min:-0.0776685 max:0.0691771 sd:0.0442277\n",
            "\t111: \"embedded_sentence.199\" NUMERICAL mean:0.011396 min:-0.0472014 max:0.0676933 sd:0.0278352\n",
            "\t112: \"embedded_sentence.2\" NUMERICAL mean:-0.0194126 min:-0.0821691 max:0.0783217 sd:0.0386326\n",
            "\t113: \"embedded_sentence.20\" NUMERICAL mean:0.0190721 min:-0.0617272 max:0.0760579 sd:0.0339998\n",
            "\t114: \"embedded_sentence.200\" NUMERICAL mean:0.00608309 min:-0.0806978 max:0.0743034 sd:0.0399125\n",
            "\t115: \"embedded_sentence.201\" NUMERICAL mean:0.0211613 min:-0.0548255 max:0.0793754 sd:0.0321254\n",
            "\t116: \"embedded_sentence.202\" NUMERICAL mean:0.00864061 min:-0.0807723 max:0.066398 sd:0.0358549\n",
            "\t117: \"embedded_sentence.203\" NUMERICAL mean:0.0229148 min:-0.0540416 max:0.0648757 sd:0.0305421\n",
            "\t118: \"embedded_sentence.204\" NUMERICAL mean:-0.000649435 min:-0.0759165 max:0.0640452 sd:0.0393411\n",
            "\t119: \"embedded_sentence.205\" NUMERICAL mean:-0.0316978 min:-0.0836376 max:0.0680075 sd:0.0408615\n",
            "\t120: \"embedded_sentence.206\" NUMERICAL mean:-0.0201012 min:-0.0745293 max:0.0857626 sd:0.0384065\n",
            "\t121: \"embedded_sentence.207\" NUMERICAL mean:0.0102246 min:-0.0711338 max:0.0750269 sd:0.0373245\n",
            "\t122: \"embedded_sentence.208\" NUMERICAL mean:-0.0268511 min:-0.0791469 max:0.06928 sd:0.028211\n",
            "\t123: \"embedded_sentence.209\" NUMERICAL mean:0.00799367 min:-0.0661981 max:0.0737173 sd:0.0371607\n",
            "\t124: \"embedded_sentence.21\" NUMERICAL mean:-0.0139034 min:-0.0672773 max:0.0717971 sd:0.0355061\n",
            "\t125: \"embedded_sentence.210\" NUMERICAL mean:0.00446928 min:-0.0625009 max:0.0745513 sd:0.0271163\n",
            "\t126: \"embedded_sentence.211\" NUMERICAL mean:0.0639041 min:-0.0498163 max:0.0945991 sd:0.030979\n",
            "\t127: \"embedded_sentence.212\" NUMERICAL mean:-0.0364687 min:-0.0787008 max:0.0484361 sd:0.034984\n",
            "\t128: \"embedded_sentence.213\" NUMERICAL mean:-0.0188171 min:-0.0694961 max:0.0873932 sd:0.0364121\n",
            "\t129: \"embedded_sentence.214\" NUMERICAL mean:-0.0288108 min:-0.0746731 max:0.0484562 sd:0.0304905\n",
            "\t130: \"embedded_sentence.215\" NUMERICAL mean:-0.0331146 min:-0.0772562 max:0.0664234 sd:0.0362199\n",
            "\t131: \"embedded_sentence.216\" NUMERICAL mean:-0.0248099 min:-0.0832034 max:0.0654591 sd:0.037309\n",
            "\t132: \"embedded_sentence.217\" NUMERICAL mean:0.0442704 min:-0.0450888 max:0.083366 sd:0.0275302\n",
            "\t133: \"embedded_sentence.218\" NUMERICAL mean:0.00553216 min:-0.0756443 max:0.076882 sd:0.0457797\n",
            "\t134: \"embedded_sentence.219\" NUMERICAL mean:0.0254888 min:-0.0611185 max:0.0833556 sd:0.0301141\n",
            "\t135: \"embedded_sentence.22\" NUMERICAL mean:0.0191351 min:-0.0820218 max:0.0814383 sd:0.0373007\n",
            "\t136: \"embedded_sentence.220\" NUMERICAL mean:0.00243143 min:-0.0795807 max:0.0682016 sd:0.0348189\n",
            "\t137: \"embedded_sentence.221\" NUMERICAL mean:-0.012786 min:-0.0892675 max:0.0626126 sd:0.0333225\n",
            "\t138: \"embedded_sentence.222\" NUMERICAL mean:-0.037855 min:-0.0787367 max:0.0764291 sd:0.0359511\n",
            "\t139: \"embedded_sentence.223\" NUMERICAL mean:-0.000159573 min:-0.0765561 max:0.0832198 sd:0.0418739\n",
            "\t140: \"embedded_sentence.224\" NUMERICAL mean:0.0302045 min:-0.0304835 max:0.0880625 sd:0.027236\n",
            "\t141: \"embedded_sentence.225\" NUMERICAL mean:0.0131337 min:-0.0696417 max:0.0730817 sd:0.0339497\n",
            "\t142: \"embedded_sentence.226\" NUMERICAL mean:-0.024403 min:-0.0854239 max:0.0509422 sd:0.0331604\n",
            "\t143: \"embedded_sentence.227\" NUMERICAL mean:0.0201963 min:-0.056712 max:0.0768536 sd:0.0303126\n",
            "\t144: \"embedded_sentence.228\" NUMERICAL mean:-0.00753546 min:-0.0849255 max:0.0566564 sd:0.0397031\n",
            "\t145: \"embedded_sentence.229\" NUMERICAL mean:0.039581 min:-0.0711373 max:0.0789386 sd:0.0328311\n",
            "\t146: \"embedded_sentence.23\" NUMERICAL mean:0.0152786 min:-0.0686987 max:0.0913555 sd:0.0375229\n",
            "\t147: \"embedded_sentence.230\" NUMERICAL mean:0.00659435 min:-0.0662031 max:0.0839686 sd:0.0352408\n",
            "\t148: \"embedded_sentence.231\" NUMERICAL mean:-0.00156059 min:-0.0716653 max:0.078397 sd:0.0332061\n",
            "\t149: \"embedded_sentence.232\" NUMERICAL mean:-0.0187319 min:-0.0818736 max:0.0655883 sd:0.0357422\n",
            "\t150: \"embedded_sentence.233\" NUMERICAL mean:0.0615774 min:-0.0440538 max:0.0948178 sd:0.0264556\n",
            "\t151: \"embedded_sentence.234\" NUMERICAL mean:0.0298504 min:-0.0865054 max:0.0795443 sd:0.051165\n",
            "\t152: \"embedded_sentence.235\" NUMERICAL mean:0.00940399 min:-0.0817663 max:0.0712504 sd:0.0401087\n",
            "\t153: \"embedded_sentence.236\" NUMERICAL mean:0.0157153 min:-0.0860296 max:0.0798284 sd:0.0361356\n",
            "\t154: \"embedded_sentence.237\" NUMERICAL mean:0.00107973 min:-0.0751875 max:0.0860184 sd:0.0506073\n",
            "\t155: \"embedded_sentence.238\" NUMERICAL mean:0.0225065 min:-0.078869 max:0.0819642 sd:0.0314543\n",
            "\t156: \"embedded_sentence.239\" NUMERICAL mean:0.0464812 min:-0.0356576 max:0.0815517 sd:0.0285294\n",
            "\t157: \"embedded_sentence.24\" NUMERICAL mean:-0.00244111 min:-0.0805156 max:0.074729 sd:0.0340652\n",
            "\t158: \"embedded_sentence.240\" NUMERICAL mean:-0.0170355 min:-0.0617654 max:0.0693955 sd:0.0346728\n",
            "\t159: \"embedded_sentence.241\" NUMERICAL mean:0.0352814 min:-0.0634249 max:0.082308 sd:0.0368714\n",
            "\t160: \"embedded_sentence.242\" NUMERICAL mean:0.0177102 min:-0.0891722 max:0.0714762 sd:0.0390066\n",
            "\t161: \"embedded_sentence.243\" NUMERICAL mean:0.000152727 min:-0.0723597 max:0.0468541 sd:0.0302644\n",
            "\t162: \"embedded_sentence.244\" NUMERICAL mean:0.017247 min:-0.0807658 max:0.080284 sd:0.0350749\n",
            "\t163: \"embedded_sentence.245\" NUMERICAL mean:0.0167744 min:-0.0735885 max:0.0722009 sd:0.0347249\n",
            "\t164: \"embedded_sentence.246\" NUMERICAL mean:-0.00424084 min:-0.0626324 max:0.0778429 sd:0.0357012\n",
            "\t165: \"embedded_sentence.247\" NUMERICAL mean:-0.0127889 min:-0.0776296 max:0.0734491 sd:0.0432015\n",
            "\t166: \"embedded_sentence.248\" NUMERICAL mean:-0.00086637 min:-0.0756049 max:0.0747615 sd:0.032462\n",
            "\t167: \"embedded_sentence.249\" NUMERICAL mean:0.0346236 min:-0.0353792 max:0.0752507 sd:0.0292378\n",
            "\t168: \"embedded_sentence.25\" NUMERICAL mean:0.0115991 min:-0.0625373 max:0.0595552 sd:0.0324006\n",
            "\t169: \"embedded_sentence.250\" NUMERICAL mean:-0.0384793 min:-0.0870535 max:0.0660651 sd:0.0403059\n",
            "\t170: \"embedded_sentence.251\" NUMERICAL mean:-0.0259502 min:-0.0819012 max:0.0432647 sd:0.0357367\n",
            "\t171: \"embedded_sentence.252\" NUMERICAL mean:0.0275049 min:-0.0740106 max:0.0804422 sd:0.0376954\n",
            "\t172: \"embedded_sentence.253\" NUMERICAL mean:0.0347791 min:-0.0629444 max:0.0795641 sd:0.0270028\n",
            "\t173: \"embedded_sentence.254\" NUMERICAL mean:-0.0207639 min:-0.0800113 max:0.0610206 sd:0.0314929\n",
            "\t174: \"embedded_sentence.255\" NUMERICAL mean:0.02464 min:-0.0769853 max:0.0739095 sd:0.0346442\n",
            "\t175: \"embedded_sentence.256\" NUMERICAL mean:0.0209206 min:-0.0625298 max:0.0859185 sd:0.036393\n",
            "\t176: \"embedded_sentence.257\" NUMERICAL mean:-0.0300773 min:-0.0793583 max:0.0713053 sd:0.0437357\n",
            "\t177: \"embedded_sentence.258\" NUMERICAL mean:-0.0210587 min:-0.0873917 max:0.0609652 sd:0.0429468\n",
            "\t178: \"embedded_sentence.259\" NUMERICAL mean:0.00643261 min:-0.0768722 max:0.0735791 sd:0.0372274\n",
            "\t179: \"embedded_sentence.26\" NUMERICAL mean:-0.0273967 min:-0.0918748 max:0.0725399 sd:0.037758\n",
            "\t180: \"embedded_sentence.260\" NUMERICAL mean:-0.021244 min:-0.0772436 max:0.0521317 sd:0.0360408\n",
            "\t181: \"embedded_sentence.261\" NUMERICAL mean:-0.00328048 min:-0.0593286 max:0.0614885 sd:0.0299232\n",
            "\t182: \"embedded_sentence.262\" NUMERICAL mean:0.023422 min:-0.0744443 max:0.0866054 sd:0.0366867\n",
            "\t183: \"embedded_sentence.263\" NUMERICAL mean:0.0167197 min:-0.104903 max:0.0808588 sd:0.0525887\n",
            "\t184: \"embedded_sentence.264\" NUMERICAL mean:0.0330956 min:-0.069252 max:0.0878201 sd:0.0434618\n",
            "\t185: \"embedded_sentence.265\" NUMERICAL mean:0.0358076 min:-0.0377798 max:0.0885664 sd:0.0316254\n",
            "\t186: \"embedded_sentence.266\" NUMERICAL mean:0.00308986 min:-0.0760089 max:0.0800082 sd:0.0432756\n",
            "\t187: \"embedded_sentence.267\" NUMERICAL mean:0.0112794 min:-0.0592024 max:0.075966 sd:0.0344149\n",
            "\t188: \"embedded_sentence.268\" NUMERICAL mean:-0.028368 min:-0.0843989 max:0.0799839 sd:0.0390886\n",
            "\t189: \"embedded_sentence.269\" NUMERICAL mean:0.0223756 min:-0.0558281 max:0.0697993 sd:0.0326468\n",
            "\t190: \"embedded_sentence.27\" NUMERICAL mean:-0.00743157 min:-0.0752205 max:0.0763223 sd:0.0378096\n",
            "\t191: \"embedded_sentence.270\" NUMERICAL mean:0.0158274 min:-0.0875574 max:0.0810878 sd:0.0414072\n",
            "\t192: \"embedded_sentence.271\" NUMERICAL mean:-0.042787 min:-0.0866613 max:0.0480975 sd:0.0258119\n",
            "\t193: \"embedded_sentence.272\" NUMERICAL mean:-0.0183297 min:-0.0810027 max:0.0690094 sd:0.0393091\n",
            "\t194: \"embedded_sentence.273\" NUMERICAL mean:-0.00118236 min:-0.0814088 max:0.0783293 sd:0.045767\n",
            "\t195: \"embedded_sentence.274\" NUMERICAL mean:-0.0340281 min:-0.0840398 max:0.0763469 sd:0.0410844\n",
            "\t196: \"embedded_sentence.275\" NUMERICAL mean:0.00249319 min:-0.0834039 max:0.0750842 sd:0.03952\n",
            "\t197: \"embedded_sentence.276\" NUMERICAL mean:-0.0266695 min:-0.0830568 max:0.048392 sd:0.0332808\n",
            "\t198: \"embedded_sentence.277\" NUMERICAL mean:0.0377472 min:-0.0742992 max:0.0850457 sd:0.0385697\n",
            "\t199: \"embedded_sentence.278\" NUMERICAL mean:0.0592141 min:-0.0633884 max:0.0842636 sd:0.0233725\n",
            "\t200: \"embedded_sentence.279\" NUMERICAL mean:0.00687817 min:-0.0790718 max:0.0832499 sd:0.0379981\n",
            "\t201: \"embedded_sentence.28\" NUMERICAL mean:-0.0125514 min:-0.0822671 max:0.0677329 sd:0.0344028\n",
            "\t202: \"embedded_sentence.280\" NUMERICAL mean:-0.0114394 min:-0.0794456 max:0.0752715 sd:0.0458722\n",
            "\t203: \"embedded_sentence.281\" NUMERICAL mean:0.0138441 min:-0.0659065 max:0.0823036 sd:0.0356909\n",
            "\t204: \"embedded_sentence.282\" NUMERICAL mean:-0.0348531 min:-0.0798667 max:0.0765971 sd:0.0313822\n",
            "\t205: \"embedded_sentence.283\" NUMERICAL mean:-0.00967688 min:-0.0835352 max:0.0795079 sd:0.040778\n",
            "\t206: \"embedded_sentence.284\" NUMERICAL mean:0.0335809 min:-0.0815059 max:0.0951515 sd:0.0411877\n",
            "\t207: \"embedded_sentence.285\" NUMERICAL mean:0.00433271 min:-0.0898771 max:0.0805461 sd:0.0329737\n",
            "\t208: \"embedded_sentence.286\" NUMERICAL mean:0.0163445 min:-0.071054 max:0.0823116 sd:0.0320453\n",
            "\t209: \"embedded_sentence.287\" NUMERICAL mean:0.0228164 min:-0.0623593 max:0.064562 sd:0.0303927\n",
            "\t210: \"embedded_sentence.288\" NUMERICAL mean:0.0424976 min:-0.0758694 max:0.0852485 sd:0.0425663\n",
            "\t211: \"embedded_sentence.289\" NUMERICAL mean:-0.0270538 min:-0.0865591 max:0.0793046 sd:0.0377994\n",
            "\t212: \"embedded_sentence.29\" NUMERICAL mean:0.013423 min:-0.0834269 max:0.0782221 sd:0.0398129\n",
            "\t213: \"embedded_sentence.290\" NUMERICAL mean:-0.0193844 min:-0.0780246 max:0.0409491 sd:0.0309942\n",
            "\t214: \"embedded_sentence.291\" NUMERICAL mean:-0.0327238 min:-0.0777506 max:0.0637962 sd:0.0341642\n",
            "\t215: \"embedded_sentence.292\" NUMERICAL mean:0.0582689 min:-0.042315 max:0.084116 sd:0.0284736\n",
            "\t216: \"embedded_sentence.293\" NUMERICAL mean:-0.0105715 min:-0.0755889 max:0.071668 sd:0.0320513\n",
            "\t217: \"embedded_sentence.294\" NUMERICAL mean:-0.0259117 min:-0.0737211 max:0.0834666 sd:0.0317714\n",
            "\t218: \"embedded_sentence.295\" NUMERICAL mean:-0.00266669 min:-0.083322 max:0.0703104 sd:0.0391032\n",
            "\t219: \"embedded_sentence.296\" NUMERICAL mean:-0.0442234 min:-0.0823031 max:0.056815 sd:0.031527\n",
            "\t220: \"embedded_sentence.297\" NUMERICAL mean:0.0157018 min:-0.0740327 max:0.0778626 sd:0.0395038\n",
            "\t221: \"embedded_sentence.298\" NUMERICAL mean:0.0227059 min:-0.0719425 max:0.0796342 sd:0.0355545\n",
            "\t222: \"embedded_sentence.299\" NUMERICAL mean:0.0275387 min:-0.0919997 max:0.0760884 sd:0.036031\n",
            "\t223: \"embedded_sentence.3\" NUMERICAL mean:0.0109735 min:-0.065528 max:0.0715574 sd:0.0293502\n",
            "\t224: \"embedded_sentence.30\" NUMERICAL mean:-0.039575 min:-0.080054 max:0.0535282 sd:0.0360571\n",
            "\t225: \"embedded_sentence.300\" NUMERICAL mean:-0.00627467 min:-0.0548773 max:0.0768326 sd:0.0316667\n",
            "\t226: \"embedded_sentence.301\" NUMERICAL mean:0.00394474 min:-0.0725813 max:0.0652802 sd:0.0394275\n",
            "\t227: \"embedded_sentence.302\" NUMERICAL mean:0.0223218 min:-0.0452923 max:0.0707708 sd:0.0285138\n",
            "\t228: \"embedded_sentence.303\" NUMERICAL mean:-0.0225351 min:-0.0759377 max:0.0520054 sd:0.0330412\n",
            "\t229: \"embedded_sentence.304\" NUMERICAL mean:-0.0197555 min:-0.0866426 max:0.0862007 sd:0.0468797\n",
            "\t230: \"embedded_sentence.305\" NUMERICAL mean:0.0184168 min:-0.0462846 max:0.0695461 sd:0.0326673\n",
            "\t231: \"embedded_sentence.306\" NUMERICAL mean:0.0200188 min:-0.0780316 max:0.0880667 sd:0.0353519\n",
            "\t232: \"embedded_sentence.307\" NUMERICAL mean:0.0283828 min:-0.0504185 max:0.0862493 sd:0.0330502\n",
            "\t233: \"embedded_sentence.308\" NUMERICAL mean:-0.0256525 min:-0.0879955 max:0.0598434 sd:0.0342206\n",
            "\t234: \"embedded_sentence.309\" NUMERICAL mean:-0.0123148 min:-0.0682094 max:0.0723346 sd:0.0378071\n",
            "\t235: \"embedded_sentence.31\" NUMERICAL mean:0.021117 min:-0.0629395 max:0.0888751 sd:0.0447906\n",
            "\t236: \"embedded_sentence.310\" NUMERICAL mean:0.00782165 min:-0.0700361 max:0.0822932 sd:0.0376634\n",
            "\t237: \"embedded_sentence.311\" NUMERICAL mean:-0.0099554 min:-0.0653961 max:0.0511641 sd:0.0323074\n",
            "\t238: \"embedded_sentence.312\" NUMERICAL mean:0.0410484 min:-0.0587718 max:0.0872839 sd:0.0357026\n",
            "\t239: \"embedded_sentence.313\" NUMERICAL mean:0.0194003 min:-0.0850738 max:0.0867256 sd:0.0402682\n",
            "\t240: \"embedded_sentence.314\" NUMERICAL mean:0.0480244 min:-0.0335197 max:0.0823478 sd:0.0261477\n",
            "\t241: \"embedded_sentence.315\" NUMERICAL mean:0.0212374 min:-0.0678512 max:0.0760378 sd:0.0385766\n",
            "\t242: \"embedded_sentence.316\" NUMERICAL mean:0.0143044 min:-0.0640765 max:0.0820166 sd:0.0470788\n",
            "\t243: \"embedded_sentence.317\" NUMERICAL mean:0.0222731 min:-0.0633166 max:0.0774522 sd:0.030308\n",
            "\t244: \"embedded_sentence.318\" NUMERICAL mean:-0.0307099 min:-0.0790352 max:0.0549647 sd:0.0335662\n",
            "\t245: \"embedded_sentence.319\" NUMERICAL mean:-0.0067447 min:-0.0829605 max:0.0699305 sd:0.0406562\n",
            "\t246: \"embedded_sentence.32\" NUMERICAL mean:0.0225939 min:-0.0609571 max:0.0766326 sd:0.0416499\n",
            "\t247: \"embedded_sentence.320\" NUMERICAL mean:-0.00501981 min:-0.0759592 max:0.0780565 sd:0.0471653\n",
            "\t248: \"embedded_sentence.321\" NUMERICAL mean:-0.00777292 min:-0.0721943 max:0.0758194 sd:0.0401996\n",
            "\t249: \"embedded_sentence.322\" NUMERICAL mean:-0.0377841 min:-0.0748938 max:0.0446261 sd:0.0296488\n",
            "\t250: \"embedded_sentence.323\" NUMERICAL mean:-0.0310188 min:-0.077809 max:0.0718169 sd:0.0376774\n",
            "\t251: \"embedded_sentence.324\" NUMERICAL mean:-0.0433293 min:-0.0766825 max:0.0308656 sd:0.0233978\n",
            "\t252: \"embedded_sentence.325\" NUMERICAL mean:-0.0150461 min:-0.0703027 max:0.0739426 sd:0.0386225\n",
            "\t253: \"embedded_sentence.326\" NUMERICAL mean:-0.00257256 min:-0.0809643 max:0.0730759 sd:0.0388314\n",
            "\t254: \"embedded_sentence.327\" NUMERICAL mean:0.00530114 min:-0.069333 max:0.0668117 sd:0.0342033\n",
            "\t255: \"embedded_sentence.328\" NUMERICAL mean:0.00791141 min:-0.0864593 max:0.0696973 sd:0.0371834\n",
            "\t256: \"embedded_sentence.329\" NUMERICAL mean:0.00595962 min:-0.0771694 max:0.0788658 sd:0.043626\n",
            "\t257: \"embedded_sentence.33\" NUMERICAL mean:0.0196839 min:-0.0637504 max:0.0804701 sd:0.0363572\n",
            "\t258: \"embedded_sentence.330\" NUMERICAL mean:0.0229219 min:-0.0698491 max:0.0739313 sd:0.035298\n",
            "\t259: \"embedded_sentence.331\" NUMERICAL mean:0.00839804 min:-0.0689163 max:0.0711193 sd:0.0370427\n",
            "\t260: \"embedded_sentence.332\" NUMERICAL mean:-0.00380759 min:-0.0797291 max:0.0811894 sd:0.0497672\n",
            "\t261: \"embedded_sentence.333\" NUMERICAL mean:0.0582728 min:-0.0289569 max:0.0924059 sd:0.026068\n",
            "\t262: \"embedded_sentence.334\" NUMERICAL mean:-0.0114265 min:-0.0867338 max:0.0734299 sd:0.0449418\n",
            "\t263: \"embedded_sentence.335\" NUMERICAL mean:0.012286 min:-0.0533135 max:0.0699002 sd:0.0314429\n",
            "\t264: \"embedded_sentence.336\" NUMERICAL mean:0.0198541 min:-0.0687936 max:0.0714806 sd:0.0320248\n",
            "\t265: \"embedded_sentence.337\" NUMERICAL mean:0.00735547 min:-0.0752081 max:0.0788973 sd:0.0410371\n",
            "\t266: \"embedded_sentence.338\" NUMERICAL mean:0.0170284 min:-0.0600387 max:0.0755349 sd:0.0398358\n",
            "\t267: \"embedded_sentence.339\" NUMERICAL mean:-0.0135715 min:-0.0785495 max:0.063897 sd:0.0367419\n",
            "\t268: \"embedded_sentence.34\" NUMERICAL mean:-0.0196417 min:-0.0743627 max:0.0705113 sd:0.0380715\n",
            "\t269: \"embedded_sentence.340\" NUMERICAL mean:-0.028729 min:-0.0750284 max:0.087154 sd:0.0375742\n",
            "\t270: \"embedded_sentence.341\" NUMERICAL mean:0.0116676 min:-0.0802034 max:0.0743391 sd:0.0376693\n",
            "\t271: \"embedded_sentence.342\" NUMERICAL mean:-0.00166578 min:-0.0788179 max:0.0728691 sd:0.0453696\n",
            "\t272: \"embedded_sentence.343\" NUMERICAL mean:-0.00349357 min:-0.0651521 max:0.0482279 sd:0.0278587\n",
            "\t273: \"embedded_sentence.344\" NUMERICAL mean:-0.0442302 min:-0.0854489 max:0.0579887 sd:0.0376781\n",
            "\t274: \"embedded_sentence.345\" NUMERICAL mean:0.00955099 min:-0.0893032 max:0.059991 sd:0.0296514\n",
            "\t275: \"embedded_sentence.346\" NUMERICAL mean:0.0174308 min:-0.0672549 max:0.0748291 sd:0.04067\n",
            "\t276: \"embedded_sentence.347\" NUMERICAL mean:-0.0229732 min:-0.07749 max:0.0616518 sd:0.0403675\n",
            "\t277: \"embedded_sentence.348\" NUMERICAL mean:-0.033434 min:-0.0806635 max:0.0722603 sd:0.0396217\n",
            "\t278: \"embedded_sentence.349\" NUMERICAL mean:-0.0055644 min:-0.0742253 max:0.0757934 sd:0.035778\n",
            "\t279: \"embedded_sentence.35\" NUMERICAL mean:0.014361 min:-0.0806167 max:0.0797197 sd:0.0370183\n",
            "\t280: \"embedded_sentence.350\" NUMERICAL mean:0.0225361 min:-0.0722717 max:0.0663954 sd:0.0326755\n",
            "\t281: \"embedded_sentence.351\" NUMERICAL mean:0.0300289 min:-0.0485124 max:0.0833599 sd:0.0371702\n",
            "\t282: \"embedded_sentence.352\" NUMERICAL mean:-0.00462248 min:-0.0653807 max:0.0659088 sd:0.0334302\n",
            "\t283: \"embedded_sentence.353\" NUMERICAL mean:0.00666329 min:-0.078464 max:0.0854649 sd:0.0371282\n",
            "\t284: \"embedded_sentence.354\" NUMERICAL mean:-0.0284591 min:-0.0884343 max:0.0654864 sd:0.043854\n",
            "\t285: \"embedded_sentence.355\" NUMERICAL mean:-0.0788759 min:-0.100014 max:0.0210155 sd:0.0191847\n",
            "\t286: \"embedded_sentence.356\" NUMERICAL mean:-0.0788993 min:-0.0905494 max:-0.0624306 sd:0.00550873\n",
            "\t287: \"embedded_sentence.357\" NUMERICAL mean:-0.0349562 min:-0.079427 max:0.064622 sd:0.0332165\n",
            "\t288: \"embedded_sentence.358\" NUMERICAL mean:-0.0220106 min:-0.0827981 max:0.0740604 sd:0.0430104\n",
            "\t289: \"embedded_sentence.359\" NUMERICAL mean:-0.0276887 min:-0.0916611 max:0.0639629 sd:0.0352666\n",
            "\t290: \"embedded_sentence.36\" NUMERICAL mean:-0.0285937 min:-0.0853022 max:0.0684688 sd:0.0381512\n",
            "\t291: \"embedded_sentence.360\" NUMERICAL mean:-0.00177742 min:-0.0831604 max:0.0842245 sd:0.0381571\n",
            "\t292: \"embedded_sentence.361\" NUMERICAL mean:-0.0311686 min:-0.0815011 max:0.0623102 sd:0.035312\n",
            "\t293: \"embedded_sentence.362\" NUMERICAL mean:0.0298541 min:-0.0614273 max:0.0845038 sd:0.0393185\n",
            "\t294: \"embedded_sentence.363\" NUMERICAL mean:-0.00128708 min:-0.0774253 max:0.0701537 sd:0.0414326\n",
            "\t295: \"embedded_sentence.364\" NUMERICAL mean:0.0408012 min:-0.0807785 max:0.0813582 sd:0.032957\n",
            "\t296: \"embedded_sentence.365\" NUMERICAL mean:-0.0153317 min:-0.0808916 max:0.0763638 sd:0.0471189\n",
            "\t297: \"embedded_sentence.366\" NUMERICAL mean:0.0455958 min:-0.0162523 max:0.0965971 sd:0.0235857\n",
            "\t298: \"embedded_sentence.367\" NUMERICAL mean:-0.00701359 min:-0.0762497 max:0.0659646 sd:0.0385213\n",
            "\t299: \"embedded_sentence.368\" NUMERICAL mean:-0.0359492 min:-0.0816734 max:0.0672256 sd:0.0429016\n",
            "\t300: \"embedded_sentence.369\" NUMERICAL mean:0.00640632 min:-0.0814059 max:0.0754608 sd:0.0379337\n",
            "\t301: \"embedded_sentence.37\" NUMERICAL mean:0.00504404 min:-0.0879483 max:0.064684 sd:0.0347914\n",
            "\t302: \"embedded_sentence.370\" NUMERICAL mean:-0.00874935 min:-0.0792215 max:0.077237 sd:0.0361274\n",
            "\t303: \"embedded_sentence.371\" NUMERICAL mean:-0.00586843 min:-0.0714364 max:0.0708017 sd:0.0324064\n",
            "\t304: \"embedded_sentence.372\" NUMERICAL mean:0.0194231 min:-0.0589803 max:0.0803305 sd:0.0368643\n",
            "\t305: \"embedded_sentence.373\" NUMERICAL mean:-0.0257737 min:-0.089325 max:0.0537828 sd:0.0405766\n",
            "\t306: \"embedded_sentence.374\" NUMERICAL mean:-0.0235245 min:-0.0770707 max:0.069187 sd:0.0409149\n",
            "\t307: \"embedded_sentence.375\" NUMERICAL mean:-0.0246378 min:-0.0771708 max:0.0242677 sd:0.0274022\n",
            "\t308: \"embedded_sentence.376\" NUMERICAL mean:-0.0022441 min:-0.0517912 max:0.0730348 sd:0.033963\n",
            "\t309: \"embedded_sentence.377\" NUMERICAL mean:-0.00781242 min:-0.0678445 max:0.0604693 sd:0.0292672\n",
            "\t310: \"embedded_sentence.378\" NUMERICAL mean:-0.0185267 min:-0.0760462 max:0.0820767 sd:0.0416886\n",
            "\t311: \"embedded_sentence.379\" NUMERICAL mean:-0.0152597 min:-0.0876335 max:0.0718256 sd:0.0463338\n",
            "\t312: \"embedded_sentence.38\" NUMERICAL mean:-0.0199251 min:-0.079927 max:0.073479 sd:0.0422266\n",
            "\t313: \"embedded_sentence.380\" NUMERICAL mean:-0.00399614 min:-0.0828622 max:0.0705452 sd:0.0401308\n",
            "\t314: \"embedded_sentence.381\" NUMERICAL mean:0.0241371 min:-0.068978 max:0.081524 sd:0.0416748\n",
            "\t315: \"embedded_sentence.382\" NUMERICAL mean:0.00176158 min:-0.0763458 max:0.0700894 sd:0.0329525\n",
            "\t316: \"embedded_sentence.383\" NUMERICAL mean:-0.00087757 min:-0.0631595 max:0.0594737 sd:0.0345251\n",
            "\t317: \"embedded_sentence.384\" NUMERICAL mean:0.0253097 min:-0.059738 max:0.0949161 sd:0.0384887\n",
            "\t318: \"embedded_sentence.385\" NUMERICAL mean:-0.0194464 min:-0.0808327 max:0.0657919 sd:0.0390259\n",
            "\t319: \"embedded_sentence.386\" NUMERICAL mean:0.011601 min:-0.0718917 max:0.0751224 sd:0.0395317\n",
            "\t320: \"embedded_sentence.387\" NUMERICAL mean:-0.0153612 min:-0.0807437 max:0.0478622 sd:0.0389967\n",
            "\t321: \"embedded_sentence.388\" NUMERICAL mean:0.0119063 min:-0.067852 max:0.0831801 sd:0.0404161\n",
            "\t322: \"embedded_sentence.389\" NUMERICAL mean:-0.0227314 min:-0.0722493 max:0.0774961 sd:0.034235\n",
            "\t323: \"embedded_sentence.39\" NUMERICAL mean:0.00829343 min:-0.0770154 max:0.0785993 sd:0.0389864\n",
            "\t324: \"embedded_sentence.390\" NUMERICAL mean:0.0039018 min:-0.0705778 max:0.0737282 sd:0.035979\n",
            "\t325: \"embedded_sentence.391\" NUMERICAL mean:-0.00205884 min:-0.0820763 max:0.0562057 sd:0.0360898\n",
            "\t326: \"embedded_sentence.392\" NUMERICAL mean:0.014118 min:-0.0756523 max:0.0823177 sd:0.0381743\n",
            "\t327: \"embedded_sentence.393\" NUMERICAL mean:0.00805616 min:-0.0848088 max:0.0714094 sd:0.0379654\n",
            "\t328: \"embedded_sentence.394\" NUMERICAL mean:-0.00953896 min:-0.0809694 max:0.0784933 sd:0.0475012\n",
            "\t329: \"embedded_sentence.395\" NUMERICAL mean:0.0404188 min:-0.0513777 max:0.0716407 sd:0.025338\n",
            "\t330: \"embedded_sentence.396\" NUMERICAL mean:0.00281051 min:-0.0850881 max:0.0683595 sd:0.0335449\n",
            "\t331: \"embedded_sentence.397\" NUMERICAL mean:0.00146827 min:-0.083841 max:0.0835662 sd:0.0514376\n",
            "\t332: \"embedded_sentence.398\" NUMERICAL mean:-0.0482759 min:-0.0828958 max:0.0523383 sd:0.0293302\n",
            "\t333: \"embedded_sentence.399\" NUMERICAL mean:0.0186825 min:-0.0804101 max:0.0682217 sd:0.0347639\n",
            "\t334: \"embedded_sentence.4\" NUMERICAL mean:-0.0278772 min:-0.0874862 max:0.0706529 sd:0.0398605\n",
            "\t335: \"embedded_sentence.40\" NUMERICAL mean:0.0138614 min:-0.0521671 max:0.0648172 sd:0.029565\n",
            "\t336: \"embedded_sentence.400\" NUMERICAL mean:0.0268303 min:-0.0596512 max:0.0749968 sd:0.0303717\n",
            "\t337: \"embedded_sentence.401\" NUMERICAL mean:0.0272829 min:-0.0751545 max:0.0867256 sd:0.0429414\n",
            "\t338: \"embedded_sentence.402\" NUMERICAL mean:-0.0227331 min:-0.081605 max:0.0714869 sd:0.0380736\n",
            "\t339: \"embedded_sentence.403\" NUMERICAL mean:0.0348202 min:-0.0682734 max:0.0872808 sd:0.0362838\n",
            "\t340: \"embedded_sentence.404\" NUMERICAL mean:0.0144886 min:-0.0572904 max:0.0780648 sd:0.0356722\n",
            "\t341: \"embedded_sentence.405\" NUMERICAL mean:-0.00467554 min:-0.0770446 max:0.0689772 sd:0.0370764\n",
            "\t342: \"embedded_sentence.406\" NUMERICAL mean:0.0189093 min:-0.0586151 max:0.0999265 sd:0.0360447\n",
            "\t343: \"embedded_sentence.407\" NUMERICAL mean:-0.0259729 min:-0.0857579 max:0.0718043 sd:0.0362588\n",
            "\t344: \"embedded_sentence.408\" NUMERICAL mean:0.00955649 min:-0.0485003 max:0.058361 sd:0.0299664\n",
            "\t345: \"embedded_sentence.409\" NUMERICAL mean:-0.0420645 min:-0.0996782 max:0.0483754 sd:0.0315941\n",
            "\t346: \"embedded_sentence.41\" NUMERICAL mean:0.000823617 min:-0.0709596 max:0.0766829 sd:0.0361026\n",
            "\t347: \"embedded_sentence.410\" NUMERICAL mean:0.00436321 min:-0.0722293 max:0.0794261 sd:0.029779\n",
            "\t348: \"embedded_sentence.411\" NUMERICAL mean:-0.00306586 min:-0.105031 max:0.0695964 sd:0.0420315\n",
            "\t349: \"embedded_sentence.412\" NUMERICAL mean:0.0178588 min:-0.0440445 max:0.0713572 sd:0.0279036\n",
            "\t350: \"embedded_sentence.413\" NUMERICAL mean:-0.0116066 min:-0.0792279 max:0.0540618 sd:0.0335298\n",
            "\t351: \"embedded_sentence.414\" NUMERICAL mean:-0.00763478 min:-0.0719135 max:0.0684086 sd:0.0391698\n",
            "\t352: \"embedded_sentence.415\" NUMERICAL mean:-0.049657 min:-0.0842108 max:0.0396418 sd:0.0335665\n",
            "\t353: \"embedded_sentence.416\" NUMERICAL mean:0.0175341 min:-0.0470833 max:0.0746447 sd:0.0297356\n",
            "\t354: \"embedded_sentence.417\" NUMERICAL mean:-0.0338575 min:-0.0842422 max:0.0541928 sd:0.0366249\n",
            "\t355: \"embedded_sentence.418\" NUMERICAL mean:-0.0114321 min:-0.0704121 max:0.0657331 sd:0.0370387\n",
            "\t356: \"embedded_sentence.419\" NUMERICAL mean:0.030628 min:-0.0808672 max:0.0879296 sd:0.0438133\n",
            "\t357: \"embedded_sentence.42\" NUMERICAL mean:-0.0137281 min:-0.0670732 max:0.0807279 sd:0.0401933\n",
            "\t358: \"embedded_sentence.420\" NUMERICAL mean:0.0374805 min:-0.0549901 max:0.0800029 sd:0.0334007\n",
            "\t359: \"embedded_sentence.421\" NUMERICAL mean:-0.0340358 min:-0.0975557 max:0.0761603 sd:0.0447019\n",
            "\t360: \"embedded_sentence.422\" NUMERICAL mean:-0.0135243 min:-0.077385 max:0.0533647 sd:0.0314903\n",
            "\t361: \"embedded_sentence.423\" NUMERICAL mean:-0.0141158 min:-0.0902323 max:0.0778361 sd:0.0393443\n",
            "\t362: \"embedded_sentence.424\" NUMERICAL mean:0.0432992 min:-0.0779931 max:0.0909423 sd:0.0282088\n",
            "\t363: \"embedded_sentence.425\" NUMERICAL mean:-0.00148562 min:-0.068354 max:0.0691327 sd:0.0379957\n",
            "\t364: \"embedded_sentence.426\" NUMERICAL mean:0.00474777 min:-0.0672496 max:0.0773843 sd:0.0351355\n",
            "\t365: \"embedded_sentence.427\" NUMERICAL mean:0.00262557 min:-0.0725931 max:0.0722884 sd:0.0367855\n",
            "\t366: \"embedded_sentence.428\" NUMERICAL mean:0.00694581 min:-0.0768751 max:0.0774612 sd:0.0437757\n",
            "\t367: \"embedded_sentence.429\" NUMERICAL mean:-0.0371115 min:-0.0838133 max:0.0650296 sd:0.0385155\n",
            "\t368: \"embedded_sentence.43\" NUMERICAL mean:-0.0558896 min:-0.0796828 max:0.059075 sd:0.0201988\n",
            "\t369: \"embedded_sentence.430\" NUMERICAL mean:-0.0175854 min:-0.0780223 max:0.0780971 sd:0.0400757\n",
            "\t370: \"embedded_sentence.431\" NUMERICAL mean:-0.027527 min:-0.0811385 max:0.0764573 sd:0.0386435\n",
            "\t371: \"embedded_sentence.432\" NUMERICAL mean:0.00892949 min:-0.0607044 max:0.0591585 sd:0.0362754\n",
            "\t372: \"embedded_sentence.433\" NUMERICAL mean:-0.0191692 min:-0.0782618 max:0.070944 sd:0.0343317\n",
            "\t373: \"embedded_sentence.434\" NUMERICAL mean:0.0332217 min:-0.0493838 max:0.0875988 sd:0.0402805\n",
            "\t374: \"embedded_sentence.435\" NUMERICAL mean:-0.0195782 min:-0.0640299 max:0.0418949 sd:0.0241874\n",
            "\t375: \"embedded_sentence.436\" NUMERICAL mean:0.0137593 min:-0.0630824 max:0.0941098 sd:0.0368142\n",
            "\t376: \"embedded_sentence.437\" NUMERICAL mean:-0.0024445 min:-0.0742889 max:0.0691585 sd:0.0364965\n",
            "\t377: \"embedded_sentence.438\" NUMERICAL mean:-0.00263357 min:-0.0839615 max:0.0814647 sd:0.048948\n",
            "\t378: \"embedded_sentence.439\" NUMERICAL mean:-0.0248149 min:-0.0881238 max:0.0779414 sd:0.0474483\n",
            "\t379: \"embedded_sentence.44\" NUMERICAL mean:0.0370308 min:-0.0587965 max:0.0800364 sd:0.0380777\n",
            "\t380: \"embedded_sentence.440\" NUMERICAL mean:-0.0110758 min:-0.0790894 max:0.070974 sd:0.0412782\n",
            "\t381: \"embedded_sentence.441\" NUMERICAL mean:-0.00656586 min:-0.0808748 max:0.0779769 sd:0.0367172\n",
            "\t382: \"embedded_sentence.442\" NUMERICAL mean:-0.0310249 min:-0.0747254 max:0.0687385 sd:0.0395077\n",
            "\t383: \"embedded_sentence.443\" NUMERICAL mean:0.0276181 min:-0.0693127 max:0.0843496 sd:0.0309691\n",
            "\t384: \"embedded_sentence.444\" NUMERICAL mean:-0.0160506 min:-0.0726527 max:0.0785865 sd:0.0408837\n",
            "\t385: \"embedded_sentence.445\" NUMERICAL mean:0.0381386 min:-0.0625765 max:0.0816138 sd:0.0374081\n",
            "\t386: \"embedded_sentence.446\" NUMERICAL mean:-0.0078742 min:-0.0712189 max:0.0736013 sd:0.0346724\n",
            "\t387: \"embedded_sentence.447\" NUMERICAL mean:-0.0370262 min:-0.0884793 max:0.048316 sd:0.0355491\n",
            "\t388: \"embedded_sentence.448\" NUMERICAL mean:-0.0157044 min:-0.0677465 max:0.0596271 sd:0.0361444\n",
            "\t389: \"embedded_sentence.449\" NUMERICAL mean:0.0129341 min:-0.0842162 max:0.0759926 sd:0.0415138\n",
            "\t390: \"embedded_sentence.45\" NUMERICAL mean:0.0225399 min:-0.0680591 max:0.0779646 sd:0.0391585\n",
            "\t391: \"embedded_sentence.450\" NUMERICAL mean:-0.0186089 min:-0.0791741 max:0.0779056 sd:0.0463209\n",
            "\t392: \"embedded_sentence.451\" NUMERICAL mean:-0.0086478 min:-0.0803339 max:0.069028 sd:0.0386333\n",
            "\t393: \"embedded_sentence.452\" NUMERICAL mean:0.0360307 min:-0.0586402 max:0.0864786 sd:0.0347994\n",
            "\t394: \"embedded_sentence.453\" NUMERICAL mean:0.0151845 min:-0.060841 max:0.0690229 sd:0.0315696\n",
            "\t395: \"embedded_sentence.454\" NUMERICAL mean:0.00369977 min:-0.0598162 max:0.0610199 sd:0.0327578\n",
            "\t396: \"embedded_sentence.455\" NUMERICAL mean:0.0258822 min:-0.0676811 max:0.0879509 sd:0.0329757\n",
            "\t397: \"embedded_sentence.456\" NUMERICAL mean:0.0228207 min:-0.0595525 max:0.0739628 sd:0.0356399\n",
            "\t398: \"embedded_sentence.457\" NUMERICAL mean:-0.00919838 min:-0.0779078 max:0.0703613 sd:0.0363464\n",
            "\t399: \"embedded_sentence.458\" NUMERICAL mean:-0.00688491 min:-0.0615589 max:0.0660894 sd:0.0332784\n",
            "\t400: \"embedded_sentence.459\" NUMERICAL mean:0.047063 min:-0.0283602 max:0.0826302 sd:0.0238518\n",
            "\t401: \"embedded_sentence.46\" NUMERICAL mean:-0.000590734 min:-0.0742701 max:0.0497962 sd:0.0291884\n",
            "\t402: \"embedded_sentence.460\" NUMERICAL mean:0.0281995 min:-0.0947348 max:0.0810154 sd:0.0451458\n",
            "\t403: \"embedded_sentence.461\" NUMERICAL mean:0.0161795 min:-0.0409674 max:0.0817031 sd:0.0327648\n",
            "\t404: \"embedded_sentence.462\" NUMERICAL mean:0.0274356 min:-0.0677833 max:0.0789436 sd:0.037275\n",
            "\t405: \"embedded_sentence.463\" NUMERICAL mean:-0.034339 min:-0.0795225 max:0.0457841 sd:0.0333808\n",
            "\t406: \"embedded_sentence.464\" NUMERICAL mean:-0.0300743 min:-0.0717198 max:0.0567023 sd:0.0312124\n",
            "\t407: \"embedded_sentence.465\" NUMERICAL mean:0.0210828 min:-0.0651981 max:0.0686894 sd:0.0320781\n",
            "\t408: \"embedded_sentence.466\" NUMERICAL mean:-0.00885337 min:-0.0916214 max:0.0691794 sd:0.0398694\n",
            "\t409: \"embedded_sentence.467\" NUMERICAL mean:0.0508712 min:-0.0523744 max:0.0913361 sd:0.0314682\n",
            "\t410: \"embedded_sentence.468\" NUMERICAL mean:0.0172176 min:-0.0734606 max:0.0718448 sd:0.0378393\n",
            "\t411: \"embedded_sentence.469\" NUMERICAL mean:0.0376763 min:-0.0620117 max:0.0784966 sd:0.038163\n",
            "\t412: \"embedded_sentence.47\" NUMERICAL mean:0.0294399 min:-0.0376849 max:0.0773504 sd:0.0294927\n",
            "\t413: \"embedded_sentence.470\" NUMERICAL mean:0.00594709 min:-0.0825779 max:0.0770046 sd:0.042778\n",
            "\t414: \"embedded_sentence.471\" NUMERICAL mean:0.0185647 min:-0.0942869 max:0.0753416 sd:0.0455154\n",
            "\t415: \"embedded_sentence.472\" NUMERICAL mean:-0.00669755 min:-0.0690151 max:0.0778486 sd:0.0356706\n",
            "\t416: \"embedded_sentence.473\" NUMERICAL mean:0.0163883 min:-0.0796148 max:0.077126 sd:0.0367696\n",
            "\t417: \"embedded_sentence.474\" NUMERICAL mean:-0.0319723 min:-0.0810425 max:0.077947 sd:0.0310451\n",
            "\t418: \"embedded_sentence.475\" NUMERICAL mean:0.0126871 min:-0.0768386 max:0.0821439 sd:0.0408217\n",
            "\t419: \"embedded_sentence.476\" NUMERICAL mean:-0.0058006 min:-0.0820514 max:0.0774247 sd:0.0414219\n",
            "\t420: \"embedded_sentence.477\" NUMERICAL mean:0.0164313 min:-0.0771249 max:0.0915238 sd:0.0390837\n",
            "\t421: \"embedded_sentence.478\" NUMERICAL mean:-0.00811178 min:-0.0739104 max:0.0747874 sd:0.0394363\n",
            "\t422: \"embedded_sentence.479\" NUMERICAL mean:0.056908 min:-0.077169 max:0.0879324 sd:0.032631\n",
            "\t423: \"embedded_sentence.48\" NUMERICAL mean:-0.00831354 min:-0.0805021 max:0.0745382 sd:0.0373131\n",
            "\t424: \"embedded_sentence.480\" NUMERICAL mean:0.0340663 min:-0.0541576 max:0.0760103 sd:0.0311689\n",
            "\t425: \"embedded_sentence.481\" NUMERICAL mean:0.0281501 min:-0.0697471 max:0.0766281 sd:0.0473833\n",
            "\t426: \"embedded_sentence.482\" NUMERICAL mean:-0.0296032 min:-0.0790471 max:0.0677854 sd:0.0322557\n",
            "\t427: \"embedded_sentence.483\" NUMERICAL mean:-0.0399118 min:-0.0808663 max:0.0448455 sd:0.0284762\n",
            "\t428: \"embedded_sentence.484\" NUMERICAL mean:0.0341099 min:-0.0558603 max:0.0826933 sd:0.0351117\n",
            "\t429: \"embedded_sentence.485\" NUMERICAL mean:0.0202912 min:-0.0813488 max:0.0883773 sd:0.0394558\n",
            "\t430: \"embedded_sentence.486\" NUMERICAL mean:0.0277676 min:-0.050995 max:0.0833272 sd:0.0359776\n",
            "\t431: \"embedded_sentence.487\" NUMERICAL mean:-0.00332446 min:-0.0639273 max:0.0755401 sd:0.0368859\n",
            "\t432: \"embedded_sentence.488\" NUMERICAL mean:0.00760294 min:-0.0752665 max:0.0793795 sd:0.0346328\n",
            "\t433: \"embedded_sentence.489\" NUMERICAL mean:0.0435674 min:-0.079983 max:0.0886065 sd:0.0480396\n",
            "\t434: \"embedded_sentence.49\" NUMERICAL mean:0.0104912 min:-0.0793007 max:0.0720239 sd:0.0338251\n",
            "\t435: \"embedded_sentence.490\" NUMERICAL mean:-0.0203639 min:-0.0669026 max:0.0650408 sd:0.0290566\n",
            "\t436: \"embedded_sentence.491\" NUMERICAL mean:-0.00745827 min:-0.0736993 max:0.0771926 sd:0.0379056\n",
            "\t437: \"embedded_sentence.492\" NUMERICAL mean:-0.0170211 min:-0.0856717 max:0.0537128 sd:0.037623\n",
            "\t438: \"embedded_sentence.493\" NUMERICAL mean:-0.0102207 min:-0.0731444 max:0.0705913 sd:0.03405\n",
            "\t439: \"embedded_sentence.494\" NUMERICAL mean:-0.00163574 min:-0.0797456 max:0.0725934 sd:0.0320148\n",
            "\t440: \"embedded_sentence.495\" NUMERICAL mean:0.0309343 min:-0.0752993 max:0.0753515 sd:0.0348822\n",
            "\t441: \"embedded_sentence.496\" NUMERICAL mean:0.0107524 min:-0.0506103 max:0.0911993 sd:0.0373655\n",
            "\t442: \"embedded_sentence.497\" NUMERICAL mean:0.000457684 min:-0.0675777 max:0.0775547 sd:0.0321428\n",
            "\t443: \"embedded_sentence.498\" NUMERICAL mean:-0.0130577 min:-0.0729729 max:0.0621996 sd:0.0387552\n",
            "\t444: \"embedded_sentence.499\" NUMERICAL mean:0.0163562 min:-0.0635633 max:0.084455 sd:0.0408272\n",
            "\t445: \"embedded_sentence.5\" NUMERICAL mean:0.00287269 min:-0.0796232 max:0.0735568 sd:0.0420939\n",
            "\t446: \"embedded_sentence.50\" NUMERICAL mean:-0.0243017 min:-0.0810146 max:0.0914319 sd:0.0375477\n",
            "\t447: \"embedded_sentence.500\" NUMERICAL mean:0.00577078 min:-0.0606071 max:0.0815171 sd:0.0292864\n",
            "\t448: \"embedded_sentence.501\" NUMERICAL mean:-0.00126198 min:-0.0688537 max:0.0702631 sd:0.0382268\n",
            "\t449: \"embedded_sentence.502\" NUMERICAL mean:0.014632 min:-0.0570222 max:0.0823616 sd:0.0315859\n",
            "\t450: \"embedded_sentence.503\" NUMERICAL mean:-0.0574546 min:-0.107859 max:0.0587122 sd:0.0334601\n",
            "\t451: \"embedded_sentence.504\" NUMERICAL mean:0.0390909 min:-0.040366 max:0.0805919 sd:0.0332383\n",
            "\t452: \"embedded_sentence.505\" NUMERICAL mean:-0.00561029 min:-0.080067 max:0.0732293 sd:0.0410567\n",
            "\t453: \"embedded_sentence.506\" NUMERICAL mean:-0.0315276 min:-0.0862128 max:0.0606837 sd:0.0438491\n",
            "\t454: \"embedded_sentence.507\" NUMERICAL mean:0.0178565 min:-0.0451097 max:0.0823762 sd:0.0294841\n",
            "\t455: \"embedded_sentence.508\" NUMERICAL mean:-0.00131239 min:-0.0651441 max:0.068837 sd:0.0361529\n",
            "\t456: \"embedded_sentence.509\" NUMERICAL mean:0.0180438 min:-0.061729 max:0.0764285 sd:0.0332434\n",
            "\t457: \"embedded_sentence.51\" NUMERICAL mean:0.015723 min:-0.0610338 max:0.0777108 sd:0.0318838\n",
            "\t458: \"embedded_sentence.510\" NUMERICAL mean:-0.0104173 min:-0.0689908 max:0.0663311 sd:0.0342406\n",
            "\t459: \"embedded_sentence.511\" NUMERICAL mean:-0.00160672 min:-0.0789533 max:0.0727818 sd:0.0316859\n",
            "\t460: \"embedded_sentence.52\" NUMERICAL mean:0.0296473 min:-0.0565677 max:0.0874048 sd:0.0397248\n",
            "\t461: \"embedded_sentence.53\" NUMERICAL mean:-0.00964311 min:-0.0733984 max:0.0821537 sd:0.0392856\n",
            "\t462: \"embedded_sentence.54\" NUMERICAL mean:0.0104937 min:-0.0648488 max:0.0697552 sd:0.0348411\n",
            "\t463: \"embedded_sentence.55\" NUMERICAL mean:-0.0201243 min:-0.071305 max:0.0713218 sd:0.0366174\n",
            "\t464: \"embedded_sentence.56\" NUMERICAL mean:0.0191385 min:-0.0794736 max:0.0817766 sd:0.0376926\n",
            "\t465: \"embedded_sentence.57\" NUMERICAL mean:0.0386905 min:-0.0647658 max:0.0799806 sd:0.0397074\n",
            "\t466: \"embedded_sentence.58\" NUMERICAL mean:0.050534 min:-0.0289757 max:0.0867318 sd:0.0257662\n",
            "\t467: \"embedded_sentence.59\" NUMERICAL mean:-0.0130537 min:-0.0746273 max:0.0649449 sd:0.0357598\n",
            "\t468: \"embedded_sentence.6\" NUMERICAL mean:-0.0242042 min:-0.0781765 max:0.0735644 sd:0.0369912\n",
            "\t469: \"embedded_sentence.60\" NUMERICAL mean:-0.00510067 min:-0.0782155 max:0.101297 sd:0.0467118\n",
            "\t470: \"embedded_sentence.61\" NUMERICAL mean:0.0157195 min:-0.0646103 max:0.0723724 sd:0.0387326\n",
            "\t471: \"embedded_sentence.62\" NUMERICAL mean:-0.0468927 min:-0.103818 max:0.0312615 sd:0.0268411\n",
            "\t472: \"embedded_sentence.63\" NUMERICAL mean:0.0136953 min:-0.0532384 max:0.0770181 sd:0.0293992\n",
            "\t473: \"embedded_sentence.64\" NUMERICAL mean:-0.0325405 min:-0.0787247 max:0.0800101 sd:0.0381814\n",
            "\t474: \"embedded_sentence.65\" NUMERICAL mean:0.0026855 min:-0.0616548 max:0.0671982 sd:0.0369998\n",
            "\t475: \"embedded_sentence.66\" NUMERICAL mean:-0.0490697 min:-0.0877227 max:0.0726405 sd:0.0313396\n",
            "\t476: \"embedded_sentence.67\" NUMERICAL mean:-0.0378798 min:-0.0788305 max:0.0295633 sd:0.0296842\n",
            "\t477: \"embedded_sentence.68\" NUMERICAL mean:0.00610726 min:-0.0660878 max:0.0704555 sd:0.0334505\n",
            "\t478: \"embedded_sentence.69\" NUMERICAL mean:0.000104403 min:-0.0745449 max:0.0582581 sd:0.0330829\n",
            "\t479: \"embedded_sentence.7\" NUMERICAL mean:-0.0233748 min:-0.0805028 max:0.060864 sd:0.0273036\n",
            "\t480: \"embedded_sentence.70\" NUMERICAL mean:0.00827185 min:-0.0660739 max:0.0748736 sd:0.0394094\n",
            "\t481: \"embedded_sentence.71\" NUMERICAL mean:-0.0632964 min:-0.0927853 max:0.00433284 sd:0.0159018\n",
            "\t482: \"embedded_sentence.72\" NUMERICAL mean:-0.0341216 min:-0.0854397 max:0.0736807 sd:0.0333676\n",
            "\t483: \"embedded_sentence.73\" NUMERICAL mean:-0.0343786 min:-0.0759104 max:0.0781546 sd:0.0322886\n",
            "\t484: \"embedded_sentence.74\" NUMERICAL mean:0.0134318 min:-0.0651456 max:0.0720606 sd:0.0311196\n",
            "\t485: \"embedded_sentence.75\" NUMERICAL mean:-0.0771745 min:-0.101963 max:0.0147622 sd:0.0165604\n",
            "\t486: \"embedded_sentence.76\" NUMERICAL mean:0.00302819 min:-0.0683713 max:0.0601201 sd:0.0374015\n",
            "\t487: \"embedded_sentence.77\" NUMERICAL mean:0.0347543 min:-0.0722241 max:0.0817311 sd:0.043051\n",
            "\t488: \"embedded_sentence.78\" NUMERICAL mean:-0.0144626 min:-0.0755501 max:0.0542633 sd:0.0329179\n",
            "\t489: \"embedded_sentence.79\" NUMERICAL mean:-0.00988388 min:-0.0721479 max:0.069856 sd:0.0312016\n",
            "\t490: \"embedded_sentence.8\" NUMERICAL mean:0.0402018 min:-0.0445913 max:0.0800416 sd:0.0289963\n",
            "\t491: \"embedded_sentence.80\" NUMERICAL mean:-0.0015006 min:-0.0719386 max:0.0834234 sd:0.0400285\n",
            "\t492: \"embedded_sentence.81\" NUMERICAL mean:0.00165668 min:-0.0592601 max:0.067834 sd:0.0323447\n",
            "\t493: \"embedded_sentence.82\" NUMERICAL mean:-0.0456349 min:-0.0797028 max:0.0416147 sd:0.0245749\n",
            "\t494: \"embedded_sentence.83\" NUMERICAL mean:-0.0181125 min:-0.0747527 max:0.0506477 sd:0.0321729\n",
            "\t495: \"embedded_sentence.84\" NUMERICAL mean:-0.0322626 min:-0.0731468 max:0.0738302 sd:0.0339358\n",
            "\t496: \"embedded_sentence.85\" NUMERICAL mean:0.0302258 min:-0.0306568 max:0.0823555 sd:0.0278906\n",
            "\t497: \"embedded_sentence.86\" NUMERICAL mean:-0.0348474 min:-0.0795576 max:0.0399601 sd:0.0293985\n",
            "\t498: \"embedded_sentence.87\" NUMERICAL mean:0.0047317 min:-0.0697568 max:0.0758233 sd:0.0375167\n",
            "\t499: \"embedded_sentence.88\" NUMERICAL mean:0.0322177 min:-0.0721227 max:0.0740824 sd:0.0314123\n",
            "\t500: \"embedded_sentence.89\" NUMERICAL mean:-0.0540658 min:-0.0866316 max:0.0513888 sd:0.0315279\n",
            "\t501: \"embedded_sentence.9\" NUMERICAL mean:-0.059726 min:-0.100117 max:0.0235476 sd:0.0263506\n",
            "\t502: \"embedded_sentence.90\" NUMERICAL mean:-0.000389289 min:-0.0558731 max:0.0773061 sd:0.03197\n",
            "\t503: \"embedded_sentence.91\" NUMERICAL mean:0.021633 min:-0.058184 max:0.077174 sd:0.0322223\n",
            "\t504: \"embedded_sentence.92\" NUMERICAL mean:0.000428954 min:-0.0699097 max:0.0771425 sd:0.0330219\n",
            "\t505: \"embedded_sentence.93\" NUMERICAL mean:0.0205384 min:-0.0659931 max:0.0724044 sd:0.0295989\n",
            "\t506: \"embedded_sentence.94\" NUMERICAL mean:-0.0155533 min:-0.0707579 max:0.0700451 sd:0.027792\n",
            "\t507: \"embedded_sentence.95\" NUMERICAL mean:0.0467709 min:-0.049754 max:0.0995549 sd:0.037268\n",
            "\t508: \"embedded_sentence.96\" NUMERICAL mean:-0.0222744 min:-0.0818576 max:0.0703905 sd:0.034568\n",
            "\t509: \"embedded_sentence.97\" NUMERICAL mean:-0.00794452 min:-0.0746586 max:0.0689082 sd:0.0364234\n",
            "\t510: \"embedded_sentence.98\" NUMERICAL mean:-0.00482172 min:-0.0781338 max:0.0801934 sd:0.0320434\n",
            "\t511: \"embedded_sentence.99\" NUMERICAL mean:-0.0423658 min:-0.0896277 max:0.0488905 sd:0.0357174\n",
            "\t512: \"embedded_sentence2.0\" NUMERICAL mean:0.0123462 min:-0.0527605 max:0.0808236 sd:0.0477446\n",
            "\t513: \"embedded_sentence2.1\" NUMERICAL mean:-0.0151664 min:-0.0913043 max:0.0675866 sd:0.0446902\n",
            "\t514: \"embedded_sentence2.10\" NUMERICAL mean:-0.00887142 min:-0.0709464 max:0.06105 sd:0.0345883\n",
            "\t515: \"embedded_sentence2.100\" NUMERICAL mean:0.0338634 min:-0.0657826 max:0.0864192 sd:0.0329784\n",
            "\t516: \"embedded_sentence2.101\" NUMERICAL mean:0.0129504 min:-0.0507474 max:0.0664688 sd:0.0305678\n",
            "\t517: \"embedded_sentence2.102\" NUMERICAL mean:-0.0162993 min:-0.0735262 max:0.0594755 sd:0.0331859\n",
            "\t518: \"embedded_sentence2.103\" NUMERICAL mean:-0.0158665 min:-0.0682637 max:0.0763534 sd:0.041344\n",
            "\t519: \"embedded_sentence2.104\" NUMERICAL mean:-0.0180674 min:-0.0862448 max:0.0781639 sd:0.0532744\n",
            "\t520: \"embedded_sentence2.105\" NUMERICAL mean:0.0286009 min:-0.079627 max:0.0831613 sd:0.0389006\n",
            "\t521: \"embedded_sentence2.106\" NUMERICAL mean:0.00661507 min:-0.0593526 max:0.0869567 sd:0.0488886\n",
            "\t522: \"embedded_sentence2.107\" NUMERICAL mean:-0.00548193 min:-0.0781101 max:0.0613035 sd:0.0330172\n",
            "\t523: \"embedded_sentence2.108\" NUMERICAL mean:0.00501562 min:-0.0725667 max:0.0712355 sd:0.0490868\n",
            "\t524: \"embedded_sentence2.109\" NUMERICAL mean:-0.00552805 min:-0.0808814 max:0.0677031 sd:0.0384193\n",
            "\t525: \"embedded_sentence2.11\" NUMERICAL mean:0.00853866 min:-0.0752352 max:0.0717064 sd:0.0491183\n",
            "\t526: \"embedded_sentence2.110\" NUMERICAL mean:-0.00351152 min:-0.0657707 max:0.0788189 sd:0.0487156\n",
            "\t527: \"embedded_sentence2.111\" NUMERICAL mean:-0.0145103 min:-0.0731574 max:0.0751192 sd:0.047902\n",
            "\t528: \"embedded_sentence2.112\" NUMERICAL mean:-0.00844298 min:-0.0677139 max:0.0552819 sd:0.0352342\n",
            "\t529: \"embedded_sentence2.113\" NUMERICAL mean:0.0135362 min:-0.0617361 max:0.0701431 sd:0.0307805\n",
            "\t530: \"embedded_sentence2.114\" NUMERICAL mean:-0.00672448 min:-0.067842 max:0.0649794 sd:0.0407188\n",
            "\t531: \"embedded_sentence2.115\" NUMERICAL mean:-0.0182481 min:-0.0902418 max:0.0849213 sd:0.0627178\n",
            "\t532: \"embedded_sentence2.116\" NUMERICAL mean:-0.0273545 min:-0.0853614 max:0.072015 sd:0.0370931\n",
            "\t533: \"embedded_sentence2.117\" NUMERICAL mean:-0.00409607 min:-0.0749218 max:0.0704839 sd:0.0307156\n",
            "\t534: \"embedded_sentence2.118\" NUMERICAL mean:0.0198628 min:-0.0834247 max:0.0717532 sd:0.0396961\n",
            "\t535: \"embedded_sentence2.119\" NUMERICAL mean:0.0107749 min:-0.0802629 max:0.0836874 sd:0.0446316\n",
            "\t536: \"embedded_sentence2.12\" NUMERICAL mean:0.0190427 min:-0.064721 max:0.0819669 sd:0.034969\n",
            "\t537: \"embedded_sentence2.120\" NUMERICAL mean:0.00159464 min:-0.0774442 max:0.072458 sd:0.0357018\n",
            "\t538: \"embedded_sentence2.121\" NUMERICAL mean:0.0042404 min:-0.0709949 max:0.074133 sd:0.0318924\n",
            "\t539: \"embedded_sentence2.122\" NUMERICAL mean:0.0220409 min:-0.0702892 max:0.0845741 sd:0.0349485\n",
            "\t540: \"embedded_sentence2.123\" NUMERICAL mean:0.00306961 min:-0.0737149 max:0.0841505 sd:0.040867\n",
            "\t541: \"embedded_sentence2.124\" NUMERICAL mean:-0.00560942 min:-0.0775171 max:0.0511765 sd:0.0425227\n",
            "\t542: \"embedded_sentence2.125\" NUMERICAL mean:0.035106 min:-0.0415539 max:0.0852254 sd:0.0280872\n",
            "\t543: \"embedded_sentence2.126\" NUMERICAL mean:-0.00533662 min:-0.0690037 max:0.0757178 sd:0.0341604\n",
            "\t544: \"embedded_sentence2.127\" NUMERICAL mean:0.0260927 min:-0.0300601 max:0.0715377 sd:0.0207213\n",
            "\t545: \"embedded_sentence2.128\" NUMERICAL mean:-0.0190929 min:-0.0789931 max:0.0716411 sd:0.0365346\n",
            "\t546: \"embedded_sentence2.129\" NUMERICAL mean:0.0197397 min:-0.0481218 max:0.0831691 sd:0.0502395\n",
            "\t547: \"embedded_sentence2.13\" NUMERICAL mean:-0.0201247 min:-0.066643 max:0.0745028 sd:0.0433603\n",
            "\t548: \"embedded_sentence2.130\" NUMERICAL mean:-0.0581398 min:-0.0961509 max:0.0189132 sd:0.0276868\n",
            "\t549: \"embedded_sentence2.131\" NUMERICAL mean:-0.0157484 min:-0.0856819 max:0.0677152 sd:0.0335234\n",
            "\t550: \"embedded_sentence2.132\" NUMERICAL mean:0.0402373 min:-0.0492875 max:0.084885 sd:0.0272942\n",
            "\t551: \"embedded_sentence2.133\" NUMERICAL mean:0.0351657 min:-0.0719509 max:0.0875444 sd:0.0353052\n",
            "\t552: \"embedded_sentence2.134\" NUMERICAL mean:0.0348288 min:-0.0368716 max:0.0697773 sd:0.0286566\n",
            "\t553: \"embedded_sentence2.135\" NUMERICAL mean:0.00734174 min:-0.0536586 max:0.0664751 sd:0.0287056\n",
            "\t554: \"embedded_sentence2.136\" NUMERICAL mean:0.0226323 min:-0.0701437 max:0.0897456 sd:0.0482035\n",
            "\t555: \"embedded_sentence2.137\" NUMERICAL mean:0.0292432 min:-0.0634837 max:0.0854309 sd:0.0261671\n",
            "\t556: \"embedded_sentence2.138\" NUMERICAL mean:0.0142181 min:-0.0374041 max:0.0755159 sd:0.0314898\n",
            "\t557: \"embedded_sentence2.139\" NUMERICAL mean:-0.0281028 min:-0.0911198 max:0.0633269 sd:0.039668\n",
            "\t558: \"embedded_sentence2.14\" NUMERICAL mean:0.000158059 min:-0.0750283 max:0.0692935 sd:0.0345869\n",
            "\t559: \"embedded_sentence2.140\" NUMERICAL mean:-0.029336 min:-0.0827778 max:0.0778079 sd:0.0362972\n",
            "\t560: \"embedded_sentence2.141\" NUMERICAL mean:-0.0175209 min:-0.0564503 max:0.0386498 sd:0.0183532\n",
            "\t561: \"embedded_sentence2.142\" NUMERICAL mean:-0.00795558 min:-0.0516394 max:0.0684424 sd:0.0353147\n",
            "\t562: \"embedded_sentence2.143\" NUMERICAL mean:-0.0178309 min:-0.079079 max:0.0683642 sd:0.0288007\n",
            "\t563: \"embedded_sentence2.144\" NUMERICAL mean:0.0184815 min:-0.0732723 max:0.0869558 sd:0.0352934\n",
            "\t564: \"embedded_sentence2.145\" NUMERICAL mean:-0.028788 min:-0.0839392 max:0.0789977 sd:0.0448187\n",
            "\t565: \"embedded_sentence2.146\" NUMERICAL mean:-0.00791367 min:-0.0877311 max:0.0518093 sd:0.036232\n",
            "\t566: \"embedded_sentence2.147\" NUMERICAL mean:-0.00280325 min:-0.0775695 max:0.0764042 sd:0.0329562\n",
            "\t567: \"embedded_sentence2.148\" NUMERICAL mean:-0.000112864 min:-0.0883235 max:0.0804217 sd:0.0579615\n",
            "\t568: \"embedded_sentence2.149\" NUMERICAL mean:-0.0188254 min:-0.0939994 max:0.0758592 sd:0.0548003\n",
            "\t569: \"embedded_sentence2.15\" NUMERICAL mean:-0.0113984 min:-0.0787552 max:0.0737994 sd:0.0364383\n",
            "\t570: \"embedded_sentence2.150\" NUMERICAL mean:-0.00214051 min:-0.0771131 max:0.083842 sd:0.03853\n",
            "\t571: \"embedded_sentence2.151\" NUMERICAL mean:0.0337298 min:-0.0157786 max:0.095609 sd:0.0288502\n",
            "\t572: \"embedded_sentence2.152\" NUMERICAL mean:-0.0476109 min:-0.0854795 max:0.0438619 sd:0.0252962\n",
            "\t573: \"embedded_sentence2.153\" NUMERICAL mean:-0.0211591 min:-0.0800424 max:0.0738529 sd:0.0393037\n",
            "\t574: \"embedded_sentence2.154\" NUMERICAL mean:-0.0156637 min:-0.0942057 max:0.0862941 sd:0.0413823\n",
            "\t575: \"embedded_sentence2.155\" NUMERICAL mean:-0.0220593 min:-0.067853 max:0.0488189 sd:0.0308855\n",
            "\t576: \"embedded_sentence2.156\" NUMERICAL mean:-0.00286141 min:-0.0801896 max:0.074638 sd:0.0425606\n",
            "\t577: \"embedded_sentence2.157\" NUMERICAL mean:-0.0268132 min:-0.0817791 max:0.0721597 sd:0.0379902\n",
            "\t578: \"embedded_sentence2.158\" NUMERICAL mean:-0.01624 min:-0.0875979 max:0.0770304 sd:0.0407085\n",
            "\t579: \"embedded_sentence2.159\" NUMERICAL mean:0.00339943 min:-0.067954 max:0.0876771 sd:0.0371274\n",
            "\t580: \"embedded_sentence2.16\" NUMERICAL mean:-0.010992 min:-0.0749945 max:0.0784479 sd:0.0351221\n",
            "\t581: \"embedded_sentence2.160\" NUMERICAL mean:0.00161509 min:-0.0861216 max:0.0513021 sd:0.0437013\n",
            "\t582: \"embedded_sentence2.161\" NUMERICAL mean:0.0213387 min:-0.0793771 max:0.0754653 sd:0.0314714\n",
            "\t583: \"embedded_sentence2.162\" NUMERICAL mean:-0.0417786 min:-0.0778947 max:0.0395843 sd:0.0329632\n",
            "\t584: \"embedded_sentence2.163\" NUMERICAL mean:0.00359882 min:-0.070381 max:0.0775324 sd:0.0522927\n",
            "\t585: \"embedded_sentence2.164\" NUMERICAL mean:-0.015434 min:-0.0833028 max:0.0544725 sd:0.040605\n",
            "\t586: \"embedded_sentence2.165\" NUMERICAL mean:0.0208485 min:-0.0826672 max:0.0804939 sd:0.0482238\n",
            "\t587: \"embedded_sentence2.166\" NUMERICAL mean:-0.00351958 min:-0.0615305 max:0.0681417 sd:0.0339206\n",
            "\t588: \"embedded_sentence2.167\" NUMERICAL mean:-0.0220344 min:-0.0803588 max:0.0508269 sd:0.036268\n",
            "\t589: \"embedded_sentence2.168\" NUMERICAL mean:0.0101252 min:-0.0874119 max:0.0665381 sd:0.0437148\n",
            "\t590: \"embedded_sentence2.169\" NUMERICAL mean:-0.0276971 min:-0.089031 max:0.0620028 sd:0.0321665\n",
            "\t591: \"embedded_sentence2.17\" NUMERICAL mean:0.00516464 min:-0.0866021 max:0.0529727 sd:0.0433961\n",
            "\t592: \"embedded_sentence2.170\" NUMERICAL mean:-0.0209022 min:-0.0920079 max:0.0532017 sd:0.0304353\n",
            "\t593: \"embedded_sentence2.171\" NUMERICAL mean:0.00468555 min:-0.0883627 max:0.0821762 sd:0.0588566\n",
            "\t594: \"embedded_sentence2.172\" NUMERICAL mean:0.00397368 min:-0.0534814 max:0.0613572 sd:0.0304008\n",
            "\t595: \"embedded_sentence2.173\" NUMERICAL mean:-0.00962107 min:-0.0684398 max:0.0720157 sd:0.0329022\n",
            "\t596: \"embedded_sentence2.174\" NUMERICAL mean:0.0175826 min:-0.0737179 max:0.0810825 sd:0.0439863\n",
            "\t597: \"embedded_sentence2.175\" NUMERICAL mean:0.0138989 min:-0.0618769 max:0.0678762 sd:0.0305592\n",
            "\t598: \"embedded_sentence2.176\" NUMERICAL mean:0.0153215 min:-0.0862236 max:0.0803185 sd:0.0383515\n",
            "\t599: \"embedded_sentence2.177\" NUMERICAL mean:-0.0220689 min:-0.0739036 max:0.0593477 sd:0.0322763\n",
            "\t600: \"embedded_sentence2.178\" NUMERICAL mean:0.00537639 min:-0.0857829 max:0.06997 sd:0.0385768\n",
            "\t601: \"embedded_sentence2.179\" NUMERICAL mean:0.0130978 min:-0.0611233 max:0.0777072 sd:0.0354644\n",
            "\t602: \"embedded_sentence2.18\" NUMERICAL mean:0.00872935 min:-0.0701376 max:0.0776935 sd:0.0331198\n",
            "\t603: \"embedded_sentence2.180\" NUMERICAL mean:0.00571731 min:-0.0831096 max:0.0718734 sd:0.0386057\n",
            "\t604: \"embedded_sentence2.181\" NUMERICAL mean:0.00572931 min:-0.0565342 max:0.0816136 sd:0.0472139\n",
            "\t605: \"embedded_sentence2.182\" NUMERICAL mean:0.0067709 min:-0.0590161 max:0.0805751 sd:0.0299863\n",
            "\t606: \"embedded_sentence2.183\" NUMERICAL mean:-0.0177438 min:-0.082842 max:0.080142 sd:0.0412254\n",
            "\t607: \"embedded_sentence2.184\" NUMERICAL mean:0.0227921 min:-0.0659862 max:0.0818822 sd:0.0565153\n",
            "\t608: \"embedded_sentence2.185\" NUMERICAL mean:0.000439133 min:-0.0532223 max:0.0767318 sd:0.0402057\n",
            "\t609: \"embedded_sentence2.186\" NUMERICAL mean:-0.020881 min:-0.0819139 max:0.0642534 sd:0.0494202\n",
            "\t610: \"embedded_sentence2.187\" NUMERICAL mean:0.0148807 min:-0.0604209 max:0.0615141 sd:0.0274473\n",
            "\t611: \"embedded_sentence2.188\" NUMERICAL mean:0.00960078 min:-0.0738273 max:0.0655209 sd:0.0359611\n",
            "\t612: \"embedded_sentence2.189\" NUMERICAL mean:-0.0230758 min:-0.0667877 max:0.0622724 sd:0.0366832\n",
            "\t613: \"embedded_sentence2.19\" NUMERICAL mean:-0.0316748 min:-0.0937038 max:0.068073 sd:0.0516283\n",
            "\t614: \"embedded_sentence2.190\" NUMERICAL mean:0.0171234 min:-0.0634672 max:0.0860102 sd:0.0439872\n",
            "\t615: \"embedded_sentence2.191\" NUMERICAL mean:-0.00577997 min:-0.072512 max:0.0699259 sd:0.0542301\n",
            "\t616: \"embedded_sentence2.192\" NUMERICAL mean:0.0229174 min:-0.0470759 max:0.0818387 sd:0.0348455\n",
            "\t617: \"embedded_sentence2.193\" NUMERICAL mean:0.0058385 min:-0.0637253 max:0.0601895 sd:0.02677\n",
            "\t618: \"embedded_sentence2.194\" NUMERICAL mean:-0.00199488 min:-0.0805096 max:0.0743463 sd:0.0350309\n",
            "\t619: \"embedded_sentence2.195\" NUMERICAL mean:0.00472528 min:-0.0829148 max:0.0827207 sd:0.0648587\n",
            "\t620: \"embedded_sentence2.196\" NUMERICAL mean:0.0170734 min:-0.0599416 max:0.0778634 sd:0.0298948\n",
            "\t621: \"embedded_sentence2.197\" NUMERICAL mean:0.0178251 min:-0.0719684 max:0.0861071 sd:0.0387654\n",
            "\t622: \"embedded_sentence2.198\" NUMERICAL mean:0.00693784 min:-0.0821698 max:0.0727656 sd:0.0431246\n",
            "\t623: \"embedded_sentence2.199\" NUMERICAL mean:0.00129044 min:-0.0765864 max:0.0623623 sd:0.0254055\n",
            "\t624: \"embedded_sentence2.2\" NUMERICAL mean:-0.0171501 min:-0.0828137 max:0.0791502 sd:0.0327498\n",
            "\t625: \"embedded_sentence2.20\" NUMERICAL mean:0.0245557 min:-0.0675191 max:0.0744072 sd:0.031039\n",
            "\t626: \"embedded_sentence2.200\" NUMERICAL mean:-0.0180756 min:-0.0785245 max:0.0766488 sd:0.0489761\n",
            "\t627: \"embedded_sentence2.201\" NUMERICAL mean:0.0297112 min:-0.0653618 max:0.0774767 sd:0.0338634\n",
            "\t628: \"embedded_sentence2.202\" NUMERICAL mean:0.0195851 min:-0.0804977 max:0.0838642 sd:0.0367561\n",
            "\t629: \"embedded_sentence2.203\" NUMERICAL mean:0.0321462 min:-0.0806359 max:0.0860979 sd:0.0374816\n",
            "\t630: \"embedded_sentence2.204\" NUMERICAL mean:-0.00605831 min:-0.0686418 max:0.0771102 sd:0.0337381\n",
            "\t631: \"embedded_sentence2.205\" NUMERICAL mean:-0.0224641 min:-0.0874932 max:0.0811924 sd:0.0419406\n",
            "\t632: \"embedded_sentence2.206\" NUMERICAL mean:-0.0321758 min:-0.0818558 max:0.0659045 sd:0.0353981\n",
            "\t633: \"embedded_sentence2.207\" NUMERICAL mean:-0.00904687 min:-0.0651867 max:0.0675347 sd:0.040495\n",
            "\t634: \"embedded_sentence2.208\" NUMERICAL mean:-0.0205382 min:-0.0864329 max:0.0795135 sd:0.0345004\n",
            "\t635: \"embedded_sentence2.209\" NUMERICAL mean:0.0181799 min:-0.0627909 max:0.0764713 sd:0.0348082\n",
            "\t636: \"embedded_sentence2.21\" NUMERICAL mean:0.00695909 min:-0.0674347 max:0.063291 sd:0.0371288\n",
            "\t637: \"embedded_sentence2.210\" NUMERICAL mean:0.0020144 min:-0.074545 max:0.0599624 sd:0.0420484\n",
            "\t638: \"embedded_sentence2.211\" NUMERICAL mean:0.0519262 min:-0.0669801 max:0.096596 sd:0.0341849\n",
            "\t639: \"embedded_sentence2.212\" NUMERICAL mean:-0.0406826 min:-0.07898 max:0.0692102 sd:0.0353134\n",
            "\t640: \"embedded_sentence2.213\" NUMERICAL mean:-0.0155481 min:-0.0738364 max:0.0787932 sd:0.0346769\n",
            "\t641: \"embedded_sentence2.214\" NUMERICAL mean:-0.0403905 min:-0.086778 max:0.0465393 sd:0.028456\n",
            "\t642: \"embedded_sentence2.215\" NUMERICAL mean:-0.00206362 min:-0.0821886 max:0.0670137 sd:0.0501328\n",
            "\t643: \"embedded_sentence2.216\" NUMERICAL mean:-0.0212601 min:-0.0840595 max:0.0760743 sd:0.0367109\n",
            "\t644: \"embedded_sentence2.217\" NUMERICAL mean:0.0287134 min:-0.041166 max:0.0773915 sd:0.0328858\n",
            "\t645: \"embedded_sentence2.218\" NUMERICAL mean:0.0167713 min:-0.0705603 max:0.0672244 sd:0.033959\n",
            "\t646: \"embedded_sentence2.219\" NUMERICAL mean:0.0247998 min:-0.038218 max:0.0787864 sd:0.0270224\n",
            "\t647: \"embedded_sentence2.22\" NUMERICAL mean:0.00382324 min:-0.087339 max:0.0739769 sd:0.0368404\n",
            "\t648: \"embedded_sentence2.220\" NUMERICAL mean:-0.00783274 min:-0.0867692 max:0.0745684 sd:0.0435853\n",
            "\t649: \"embedded_sentence2.221\" NUMERICAL mean:0.00800857 min:-0.0788465 max:0.0714592 sd:0.0412715\n",
            "\t650: \"embedded_sentence2.222\" NUMERICAL mean:-0.0340411 min:-0.0787367 max:0.0755541 sd:0.0347833\n",
            "\t651: \"embedded_sentence2.223\" NUMERICAL mean:-0.000552199 min:-0.074074 max:0.0713022 sd:0.0393119\n",
            "\t652: \"embedded_sentence2.224\" NUMERICAL mean:0.0127946 min:-0.0304835 max:0.0711413 sd:0.0341403\n",
            "\t653: \"embedded_sentence2.225\" NUMERICAL mean:0.00893576 min:-0.0866762 max:0.0732745 sd:0.0334875\n",
            "\t654: \"embedded_sentence2.226\" NUMERICAL mean:-0.0370986 min:-0.0860908 max:0.0445624 sd:0.0279342\n",
            "\t655: \"embedded_sentence2.227\" NUMERICAL mean:-0.00380615 min:-0.056712 max:0.0766359 sd:0.0414272\n",
            "\t656: \"embedded_sentence2.228\" NUMERICAL mean:-0.0264416 min:-0.0767093 max:0.0711875 sd:0.0409371\n",
            "\t657: \"embedded_sentence2.229\" NUMERICAL mean:0.0195228 min:-0.0814239 max:0.0767912 sd:0.0392089\n",
            "\t658: \"embedded_sentence2.23\" NUMERICAL mean:0.0202475 min:-0.0691307 max:0.0733152 sd:0.0414317\n",
            "\t659: \"embedded_sentence2.230\" NUMERICAL mean:0.026432 min:-0.073482 max:0.0859756 sd:0.0490657\n",
            "\t660: \"embedded_sentence2.231\" NUMERICAL mean:0.0147708 min:-0.0658474 max:0.0735047 sd:0.031412\n",
            "\t661: \"embedded_sentence2.232\" NUMERICAL mean:-0.000129624 min:-0.0675057 max:0.0835063 sd:0.0389054\n",
            "\t662: \"embedded_sentence2.233\" NUMERICAL mean:0.0673043 min:-0.0299502 max:0.0966489 sd:0.0302151\n",
            "\t663: \"embedded_sentence2.234\" NUMERICAL mean:0.0264618 min:-0.0862668 max:0.0779408 sd:0.0402697\n",
            "\t664: \"embedded_sentence2.235\" NUMERICAL mean:-0.0104867 min:-0.078944 max:0.0800741 sd:0.0559335\n",
            "\t665: \"embedded_sentence2.236\" NUMERICAL mean:-0.0156589 min:-0.0860296 max:0.0680975 sd:0.0520843\n",
            "\t666: \"embedded_sentence2.237\" NUMERICAL mean:0.00369565 min:-0.0800982 max:0.0918075 sd:0.0448407\n",
            "\t667: \"embedded_sentence2.238\" NUMERICAL mean:-0.00315057 min:-0.078869 max:0.078666 sd:0.0531917\n",
            "\t668: \"embedded_sentence2.239\" NUMERICAL mean:0.0241347 min:-0.0279532 max:0.0838543 sd:0.0392784\n",
            "\t669: \"embedded_sentence2.24\" NUMERICAL mean:0.00259308 min:-0.0663409 max:0.0789592 sd:0.0311\n",
            "\t670: \"embedded_sentence2.240\" NUMERICAL mean:0.0144907 min:-0.0581236 max:0.0680161 sd:0.0423654\n",
            "\t671: \"embedded_sentence2.241\" NUMERICAL mean:0.033725 min:-0.0789988 max:0.082308 sd:0.0428508\n",
            "\t672: \"embedded_sentence2.242\" NUMERICAL mean:0.00908377 min:-0.0776871 max:0.074621 sd:0.0409837\n",
            "\t673: \"embedded_sentence2.243\" NUMERICAL mean:-0.00831655 min:-0.0714251 max:0.0797192 sd:0.0319844\n",
            "\t674: \"embedded_sentence2.244\" NUMERICAL mean:0.00657153 min:-0.0698456 max:0.0854472 sd:0.0344289\n",
            "\t675: \"embedded_sentence2.245\" NUMERICAL mean:0.0264588 min:-0.0557211 max:0.0731504 sd:0.0290979\n",
            "\t676: \"embedded_sentence2.246\" NUMERICAL mean:-0.0135045 min:-0.0638307 max:0.074578 sd:0.0425529\n",
            "\t677: \"embedded_sentence2.247\" NUMERICAL mean:-0.00826509 min:-0.0820952 max:0.0828814 sd:0.0386842\n",
            "\t678: \"embedded_sentence2.248\" NUMERICAL mean:0.0129247 min:-0.0713391 max:0.066943 sd:0.032662\n",
            "\t679: \"embedded_sentence2.249\" NUMERICAL mean:0.0193974 min:-0.0685111 max:0.0836464 sd:0.0340797\n",
            "\t680: \"embedded_sentence2.25\" NUMERICAL mean:0.0134056 min:-0.0756752 max:0.0884163 sd:0.0393005\n",
            "\t681: \"embedded_sentence2.250\" NUMERICAL mean:-0.0191455 min:-0.0917943 max:0.0686348 sd:0.0471624\n",
            "\t682: \"embedded_sentence2.251\" NUMERICAL mean:-0.0119355 min:-0.0868737 max:0.0616713 sd:0.0399264\n",
            "\t683: \"embedded_sentence2.252\" NUMERICAL mean:-0.00580041 min:-0.0740106 max:0.0836739 sd:0.0524559\n",
            "\t684: \"embedded_sentence2.253\" NUMERICAL mean:0.00336319 min:-0.0860804 max:0.0836794 sd:0.051236\n",
            "\t685: \"embedded_sentence2.254\" NUMERICAL mean:0.00204333 min:-0.0743615 max:0.0610206 sd:0.0447723\n",
            "\t686: \"embedded_sentence2.255\" NUMERICAL mean:0.0134253 min:-0.0395279 max:0.0752859 sd:0.0305973\n",
            "\t687: \"embedded_sentence2.256\" NUMERICAL mean:0.00191654 min:-0.0805357 max:0.0880775 sd:0.0422446\n",
            "\t688: \"embedded_sentence2.257\" NUMERICAL mean:-0.0174785 min:-0.0762353 max:0.0708803 sd:0.0386975\n",
            "\t689: \"embedded_sentence2.258\" NUMERICAL mean:-0.0369017 min:-0.0815477 max:0.077842 sd:0.0434083\n",
            "\t690: \"embedded_sentence2.259\" NUMERICAL mean:0.0181714 min:-0.0702444 max:0.0790684 sd:0.0357594\n",
            "\t691: \"embedded_sentence2.26\" NUMERICAL mean:-0.0198372 min:-0.0870415 max:0.0560423 sd:0.0434523\n",
            "\t692: \"embedded_sentence2.260\" NUMERICAL mean:-0.0255301 min:-0.0755614 max:0.067677 sd:0.0338651\n",
            "\t693: \"embedded_sentence2.261\" NUMERICAL mean:-0.0086894 min:-0.0614247 max:0.0702728 sd:0.0298241\n",
            "\t694: \"embedded_sentence2.262\" NUMERICAL mean:-0.000599357 min:-0.0744443 max:0.0892358 sd:0.0545703\n",
            "\t695: \"embedded_sentence2.263\" NUMERICAL mean:-0.000587105 min:-0.0853669 max:0.0787243 sd:0.0529565\n",
            "\t696: \"embedded_sentence2.264\" NUMERICAL mean:0.0169723 min:-0.0598327 max:0.0946651 sd:0.037869\n",
            "\t697: \"embedded_sentence2.265\" NUMERICAL mean:0.032689 min:-0.066297 max:0.0865237 sd:0.0340307\n",
            "\t698: \"embedded_sentence2.266\" NUMERICAL mean:-0.00948948 min:-0.0751631 max:0.0797366 sd:0.0402221\n",
            "\t699: \"embedded_sentence2.267\" NUMERICAL mean:-0.00399877 min:-0.0603747 max:0.0833858 sd:0.0443705\n",
            "\t700: \"embedded_sentence2.268\" NUMERICAL mean:0.00982609 min:-0.0808889 max:0.0799839 sd:0.0542791\n",
            "\t701: \"embedded_sentence2.269\" NUMERICAL mean:0.0259602 min:-0.068019 max:0.0660116 sd:0.037326\n",
            "\t702: \"embedded_sentence2.27\" NUMERICAL mean:-0.0141467 min:-0.0854791 max:0.0733076 sd:0.037083\n",
            "\t703: \"embedded_sentence2.270\" NUMERICAL mean:0.0105553 min:-0.0509597 max:0.0810878 sd:0.0327951\n",
            "\t704: \"embedded_sentence2.271\" NUMERICAL mean:-0.0210529 min:-0.0796802 max:0.0480975 sd:0.0485746\n",
            "\t705: \"embedded_sentence2.272\" NUMERICAL mean:-0.00663389 min:-0.0783965 max:0.0675071 sd:0.0428135\n",
            "\t706: \"embedded_sentence2.273\" NUMERICAL mean:-0.00912785 min:-0.0785323 max:0.0742134 sd:0.0381768\n",
            "\t707: \"embedded_sentence2.274\" NUMERICAL mean:0.00417452 min:-0.0891858 max:0.0763469 sd:0.0580628\n",
            "\t708: \"embedded_sentence2.275\" NUMERICAL mean:-0.0150525 min:-0.0757518 max:0.0772725 sd:0.0377978\n",
            "\t709: \"embedded_sentence2.276\" NUMERICAL mean:-0.0177575 min:-0.0683899 max:0.0697312 sd:0.0349387\n",
            "\t710: \"embedded_sentence2.277\" NUMERICAL mean:0.00882231 min:-0.0821933 max:0.0832746 sd:0.061736\n",
            "\t711: \"embedded_sentence2.278\" NUMERICAL mean:0.0494764 min:-0.0193603 max:0.0849769 sd:0.0241703\n",
            "\t712: \"embedded_sentence2.279\" NUMERICAL mean:0.0229094 min:-0.0749329 max:0.0832499 sd:0.050145\n",
            "\t713: \"embedded_sentence2.28\" NUMERICAL mean:-0.0110355 min:-0.069163 max:0.066043 sd:0.029529\n",
            "\t714: \"embedded_sentence2.280\" NUMERICAL mean:-0.0238039 min:-0.0793055 max:0.0628222 sd:0.0451213\n",
            "\t715: \"embedded_sentence2.281\" NUMERICAL mean:0.00287875 min:-0.0753153 max:0.0863069 sd:0.0407768\n",
            "\t716: \"embedded_sentence2.282\" NUMERICAL mean:-0.0093302 min:-0.0791649 max:0.0765971 sd:0.0571354\n",
            "\t717: \"embedded_sentence2.283\" NUMERICAL mean:0.0103914 min:-0.082498 max:0.0689792 sd:0.047526\n",
            "\t718: \"embedded_sentence2.284\" NUMERICAL mean:0.00927705 min:-0.0680467 max:0.0853541 sd:0.0502909\n",
            "\t719: \"embedded_sentence2.285\" NUMERICAL mean:0.00968136 min:-0.0814478 max:0.0623404 sd:0.0383653\n",
            "\t720: \"embedded_sentence2.286\" NUMERICAL mean:0.0044168 min:-0.082919 max:0.0829516 sd:0.0318357\n",
            "\t721: \"embedded_sentence2.287\" NUMERICAL mean:0.0149036 min:-0.0501273 max:0.0804128 sd:0.036252\n",
            "\t722: \"embedded_sentence2.288\" NUMERICAL mean:0.0105515 min:-0.0828118 max:0.0814973 sd:0.0523887\n",
            "\t723: \"embedded_sentence2.289\" NUMERICAL mean:-0.0102129 min:-0.0838379 max:0.0789106 sd:0.0554235\n",
            "\t724: \"embedded_sentence2.29\" NUMERICAL mean:0.0110061 min:-0.07503 max:0.0809013 sd:0.0356955\n",
            "\t725: \"embedded_sentence2.290\" NUMERICAL mean:-0.00792453 min:-0.0710948 max:0.0741516 sd:0.0389426\n",
            "\t726: \"embedded_sentence2.291\" NUMERICAL mean:-0.043235 min:-0.0777152 max:0.0398145 sd:0.0289337\n",
            "\t727: \"embedded_sentence2.292\" NUMERICAL mean:0.0313345 min:-0.070697 max:0.0897744 sd:0.0446146\n",
            "\t728: \"embedded_sentence2.293\" NUMERICAL mean:-0.0145085 min:-0.0654311 max:0.0789761 sd:0.0454897\n",
            "\t729: \"embedded_sentence2.294\" NUMERICAL mean:-0.00132624 min:-0.0686686 max:0.0832412 sd:0.0365092\n",
            "\t730: \"embedded_sentence2.295\" NUMERICAL mean:-0.00828464 min:-0.0871794 max:0.073657 sd:0.0344339\n",
            "\t731: \"embedded_sentence2.296\" NUMERICAL mean:-0.0179537 min:-0.0866052 max:0.0497966 sd:0.0482086\n",
            "\t732: \"embedded_sentence2.297\" NUMERICAL mean:0.00763293 min:-0.0688455 max:0.08188 sd:0.0356247\n",
            "\t733: \"embedded_sentence2.298\" NUMERICAL mean:0.0319753 min:-0.069706 max:0.0796342 sd:0.0429273\n",
            "\t734: \"embedded_sentence2.299\" NUMERICAL mean:-0.00796326 min:-0.0897167 max:0.0818327 sd:0.0475635\n",
            "\t735: \"embedded_sentence2.3\" NUMERICAL mean:-0.0103813 min:-0.065528 max:0.0699651 sd:0.0403156\n",
            "\t736: \"embedded_sentence2.30\" NUMERICAL mean:-0.0167926 min:-0.0802795 max:0.0749603 sd:0.0452165\n",
            "\t737: \"embedded_sentence2.300\" NUMERICAL mean:-0.0148555 min:-0.0731661 max:0.0771753 sd:0.0377081\n",
            "\t738: \"embedded_sentence2.301\" NUMERICAL mean:-0.00852967 min:-0.0756811 max:0.081017 sd:0.0395505\n",
            "\t739: \"embedded_sentence2.302\" NUMERICAL mean:0.0131355 min:-0.0282218 max:0.0699739 sd:0.0344674\n",
            "\t740: \"embedded_sentence2.303\" NUMERICAL mean:-0.0105522 min:-0.084354 max:0.0656942 sd:0.037089\n",
            "\t741: \"embedded_sentence2.304\" NUMERICAL mean:-0.0270984 min:-0.089356 max:0.0696964 sd:0.0336381\n",
            "\t742: \"embedded_sentence2.305\" NUMERICAL mean:0.00693004 min:-0.0717157 max:0.0669379 sd:0.0314258\n",
            "\t743: \"embedded_sentence2.306\" NUMERICAL mean:0.00907671 min:-0.0714008 max:0.0826993 sd:0.0426646\n",
            "\t744: \"embedded_sentence2.307\" NUMERICAL mean:0.00618309 min:-0.0504185 max:0.0763353 sd:0.0422712\n",
            "\t745: \"embedded_sentence2.308\" NUMERICAL mean:-0.00753247 min:-0.0780787 max:0.0600227 sd:0.0511586\n",
            "\t746: \"embedded_sentence2.309\" NUMERICAL mean:-0.0133178 min:-0.08671 max:0.0865314 sd:0.0370332\n",
            "\t747: \"embedded_sentence2.31\" NUMERICAL mean:0.0252545 min:-0.0719637 max:0.0844605 sd:0.0347902\n",
            "\t748: \"embedded_sentence2.310\" NUMERICAL mean:0.00660692 min:-0.0755928 max:0.0667959 sd:0.0321865\n",
            "\t749: \"embedded_sentence2.311\" NUMERICAL mean:0.00722599 min:-0.0755751 max:0.0606027 sd:0.0320421\n",
            "\t750: \"embedded_sentence2.312\" NUMERICAL mean:0.0531863 min:-0.0891218 max:0.0879348 sd:0.0355986\n",
            "\t751: \"embedded_sentence2.313\" NUMERICAL mean:0.0223574 min:-0.0802088 max:0.0797547 sd:0.0375885\n",
            "\t752: \"embedded_sentence2.314\" NUMERICAL mean:0.0349655 min:-0.0610494 max:0.0813647 sd:0.0293397\n",
            "\t753: \"embedded_sentence2.315\" NUMERICAL mean:0.0154295 min:-0.0600232 max:0.0836341 sd:0.033915\n",
            "\t754: \"embedded_sentence2.316\" NUMERICAL mean:0.0144996 min:-0.0580794 max:0.0821854 sd:0.039863\n",
            "\t755: \"embedded_sentence2.317\" NUMERICAL mean:0.0095089 min:-0.0406667 max:0.075947 sd:0.0328754\n",
            "\t756: \"embedded_sentence2.318\" NUMERICAL mean:-0.0314607 min:-0.0785444 max:0.0664592 sd:0.0302066\n",
            "\t757: \"embedded_sentence2.319\" NUMERICAL mean:0.0123175 min:-0.0636567 max:0.0633423 sd:0.0377969\n",
            "\t758: \"embedded_sentence2.32\" NUMERICAL mean:0.000948213 min:-0.0650374 max:0.0837039 sd:0.0455039\n",
            "\t759: \"embedded_sentence2.320\" NUMERICAL mean:0.00282915 min:-0.0759592 max:0.0734154 sd:0.0388518\n",
            "\t760: \"embedded_sentence2.321\" NUMERICAL mean:-0.0224096 min:-0.0799443 max:0.078055 sd:0.0454782\n",
            "\t761: \"embedded_sentence2.322\" NUMERICAL mean:-0.011439 min:-0.0758097 max:0.0533834 sd:0.0419318\n",
            "\t762: \"embedded_sentence2.323\" NUMERICAL mean:-0.00509111 min:-0.0737002 max:0.0775577 sd:0.0426845\n",
            "\t763: \"embedded_sentence2.324\" NUMERICAL mean:-0.045045 min:-0.0850709 max:0.0388442 sd:0.0220955\n",
            "\t764: \"embedded_sentence2.325\" NUMERICAL mean:0.00175865 min:-0.0797546 max:0.0808108 sd:0.0401857\n",
            "\t765: \"embedded_sentence2.326\" NUMERICAL mean:0.00774197 min:-0.0661196 max:0.0817188 sd:0.0302958\n",
            "\t766: \"embedded_sentence2.327\" NUMERICAL mean:0.0168888 min:-0.0685388 max:0.0767028 sd:0.0356964\n",
            "\t767: \"embedded_sentence2.328\" NUMERICAL mean:0.00657491 min:-0.0935048 max:0.0750954 sd:0.0381714\n",
            "\t768: \"embedded_sentence2.329\" NUMERICAL mean:0.00563279 min:-0.076006 max:0.0836584 sd:0.0390454\n",
            "\t769: \"embedded_sentence2.33\" NUMERICAL mean:-0.002642 min:-0.0570788 max:0.0782447 sd:0.0415748\n",
            "\t770: \"embedded_sentence2.330\" NUMERICAL mean:0.0193063 min:-0.0833957 max:0.0792725 sd:0.0376853\n",
            "\t771: \"embedded_sentence2.331\" NUMERICAL mean:0.00890736 min:-0.0689163 max:0.0737507 sd:0.034364\n",
            "\t772: \"embedded_sentence2.332\" NUMERICAL mean:0.0116579 min:-0.0889824 max:0.0739874 sd:0.0506503\n",
            "\t773: \"embedded_sentence2.333\" NUMERICAL mean:0.065428 min:0.0068313 max:0.0870155 sd:0.0167864\n",
            "\t774: \"embedded_sentence2.334\" NUMERICAL mean:-0.0173568 min:-0.0837529 max:0.0669047 sd:0.0374293\n",
            "\t775: \"embedded_sentence2.335\" NUMERICAL mean:-0.00202704 min:-0.0575524 max:0.0718485 sd:0.0422847\n",
            "\t776: \"embedded_sentence2.336\" NUMERICAL mean:0.0288208 min:-0.0539819 max:0.0753513 sd:0.0330132\n",
            "\t777: \"embedded_sentence2.337\" NUMERICAL mean:-0.00240874 min:-0.0727389 max:0.0800589 sd:0.0365497\n",
            "\t778: \"embedded_sentence2.338\" NUMERICAL mean:0.00391833 min:-0.0627742 max:0.0860634 sd:0.0442877\n",
            "\t779: \"embedded_sentence2.339\" NUMERICAL mean:0.000420376 min:-0.0834412 max:0.082527 sd:0.043392\n",
            "\t780: \"embedded_sentence2.34\" NUMERICAL mean:-0.00570926 min:-0.0853184 max:0.0846191 sd:0.0405036\n",
            "\t781: \"embedded_sentence2.340\" NUMERICAL mean:-0.00423633 min:-0.0786805 max:0.0737942 sd:0.0478059\n",
            "\t782: \"embedded_sentence2.341\" NUMERICAL mean:-0.00534044 min:-0.0798595 max:0.0754641 sd:0.04286\n",
            "\t783: \"embedded_sentence2.342\" NUMERICAL mean:0.0185517 min:-0.0760298 max:0.0724034 sd:0.0448926\n",
            "\t784: \"embedded_sentence2.343\" NUMERICAL mean:-0.00227295 min:-0.0793022 max:0.0653123 sd:0.0405197\n",
            "\t785: \"embedded_sentence2.344\" NUMERICAL mean:-0.0282011 min:-0.0935726 max:0.0735403 sd:0.0390834\n",
            "\t786: \"embedded_sentence2.345\" NUMERICAL mean:0.00937608 min:-0.0719239 max:0.074384 sd:0.0342504\n",
            "\t787: \"embedded_sentence2.346\" NUMERICAL mean:0.0150901 min:-0.0718229 max:0.0849172 sd:0.0351308\n",
            "\t788: \"embedded_sentence2.347\" NUMERICAL mean:-0.0161768 min:-0.0725603 max:0.0660656 sd:0.0312497\n",
            "\t789: \"embedded_sentence2.348\" NUMERICAL mean:-0.0119722 min:-0.0821343 max:0.0714232 sd:0.0442602\n",
            "\t790: \"embedded_sentence2.349\" NUMERICAL mean:0.00416713 min:-0.0656701 max:0.0524137 sd:0.0298128\n",
            "\t791: \"embedded_sentence2.35\" NUMERICAL mean:-0.00510102 min:-0.0870217 max:0.0755286 sd:0.0420046\n",
            "\t792: \"embedded_sentence2.350\" NUMERICAL mean:0.0135709 min:-0.0717465 max:0.0667112 sd:0.0345342\n",
            "\t793: \"embedded_sentence2.351\" NUMERICAL mean:0.020002 min:-0.0704181 max:0.0792851 sd:0.0398982\n",
            "\t794: \"embedded_sentence2.352\" NUMERICAL mean:-0.00798582 min:-0.0761048 max:0.058867 sd:0.0333228\n",
            "\t795: \"embedded_sentence2.353\" NUMERICAL mean:0.0246967 min:-0.0788241 max:0.077884 sd:0.0376638\n",
            "\t796: \"embedded_sentence2.354\" NUMERICAL mean:-0.01995 min:-0.0991506 max:0.0691048 sd:0.0401472\n",
            "\t797: \"embedded_sentence2.355\" NUMERICAL mean:-0.0526179 min:-0.0983981 max:0.0221484 sd:0.047753\n",
            "\t798: \"embedded_sentence2.356\" NUMERICAL mean:-0.0799925 min:-0.0908387 max:-0.0545929 sd:0.00592576\n",
            "\t799: \"embedded_sentence2.357\" NUMERICAL mean:-0.0102205 min:-0.0779454 max:0.0687033 sd:0.0411549\n",
            "\t800: \"embedded_sentence2.358\" NUMERICAL mean:-0.00821417 min:-0.0831657 max:0.0638129 sd:0.0458071\n",
            "\t801: \"embedded_sentence2.359\" NUMERICAL mean:-0.0184498 min:-0.0800664 max:0.053565 sd:0.0343251\n",
            "\t802: \"embedded_sentence2.36\" NUMERICAL mean:-0.0116783 min:-0.0898448 max:0.0826488 sd:0.0451665\n",
            "\t803: \"embedded_sentence2.360\" NUMERICAL mean:0.0123441 min:-0.0805492 max:0.0829915 sd:0.050387\n",
            "\t804: \"embedded_sentence2.361\" NUMERICAL mean:-0.0306645 min:-0.0813411 max:0.0700526 sd:0.0431236\n",
            "\t805: \"embedded_sentence2.362\" NUMERICAL mean:0.0376189 min:-0.0753495 max:0.0780635 sd:0.0308815\n",
            "\t806: \"embedded_sentence2.363\" NUMERICAL mean:-0.00814579 min:-0.0794879 max:0.0696893 sd:0.0363616\n",
            "\t807: \"embedded_sentence2.364\" NUMERICAL mean:0.0325083 min:-0.0795449 max:0.0842538 sd:0.0298927\n",
            "\t808: \"embedded_sentence2.365\" NUMERICAL mean:-0.0201292 min:-0.0820643 max:0.0763638 sd:0.0367155\n",
            "\t809: \"embedded_sentence2.366\" NUMERICAL mean:0.0384514 min:-0.0195052 max:0.0875316 sd:0.0221458\n",
            "\t810: \"embedded_sentence2.367\" NUMERICAL mean:-0.0054198 min:-0.0800003 max:0.0610607 sd:0.0381835\n",
            "\t811: \"embedded_sentence2.368\" NUMERICAL mean:-0.0177865 min:-0.0859691 max:0.0572954 sd:0.0487297\n",
            "\t812: \"embedded_sentence2.369\" NUMERICAL mean:0.00210119 min:-0.074175 max:0.0631019 sd:0.0326934\n",
            "\t813: \"embedded_sentence2.37\" NUMERICAL mean:0.00373972 min:-0.0723695 max:0.0763134 sd:0.0335919\n",
            "\t814: \"embedded_sentence2.370\" NUMERICAL mean:-0.00925519 min:-0.0822611 max:0.0722498 sd:0.0310188\n",
            "\t815: \"embedded_sentence2.371\" NUMERICAL mean:-0.0150806 min:-0.0640964 max:0.0655466 sd:0.0370182\n",
            "\t816: \"embedded_sentence2.372\" NUMERICAL mean:0.0254511 min:-0.0381569 max:0.0763019 sd:0.0284257\n",
            "\t817: \"embedded_sentence2.373\" NUMERICAL mean:-0.0288334 min:-0.0886891 max:0.0688345 sd:0.0321252\n",
            "\t818: \"embedded_sentence2.374\" NUMERICAL mean:-0.016686 min:-0.0770707 max:0.0754735 sd:0.0358421\n",
            "\t819: \"embedded_sentence2.375\" NUMERICAL mean:-0.0330578 min:-0.083093 max:0.0600023 sd:0.0355759\n",
            "\t820: \"embedded_sentence2.376\" NUMERICAL mean:0.0154207 min:-0.0759428 max:0.0803494 sd:0.0400413\n",
            "\t821: \"embedded_sentence2.377\" NUMERICAL mean:0.00832516 min:-0.068427 max:0.0655917 sd:0.0395809\n",
            "\t822: \"embedded_sentence2.378\" NUMERICAL mean:-0.0296347 min:-0.0762851 max:0.0631694 sd:0.0384652\n",
            "\t823: \"embedded_sentence2.379\" NUMERICAL mean:-0.0108109 min:-0.0795726 max:0.0778716 sd:0.0438156\n",
            "\t824: \"embedded_sentence2.38\" NUMERICAL mean:-0.00487311 min:-0.0759098 max:0.0804896 sd:0.0374886\n",
            "\t825: \"embedded_sentence2.380\" NUMERICAL mean:-0.0106948 min:-0.0582772 max:0.0564613 sd:0.0335087\n",
            "\t826: \"embedded_sentence2.381\" NUMERICAL mean:0.0198735 min:-0.0774607 max:0.0798762 sd:0.0436073\n",
            "\t827: \"embedded_sentence2.382\" NUMERICAL mean:-0.00358317 min:-0.0833196 max:0.0710166 sd:0.0351494\n",
            "\t828: \"embedded_sentence2.383\" NUMERICAL mean:0.013516 min:-0.0746033 max:0.0715749 sd:0.0368466\n",
            "\t829: \"embedded_sentence2.384\" NUMERICAL mean:0.0392074 min:-0.0531051 max:0.0949161 sd:0.0470117\n",
            "\t830: \"embedded_sentence2.385\" NUMERICAL mean:-0.0340898 min:-0.0754408 max:0.0427557 sd:0.027564\n",
            "\t831: \"embedded_sentence2.386\" NUMERICAL mean:-0.000875753 min:-0.0543273 max:0.0752772 sd:0.0411099\n",
            "\t832: \"embedded_sentence2.387\" NUMERICAL mean:0.00426714 min:-0.0902572 max:0.0700292 sd:0.0398437\n",
            "\t833: \"embedded_sentence2.388\" NUMERICAL mean:-0.00290384 min:-0.0713923 max:0.0776933 sd:0.042965\n",
            "\t834: \"embedded_sentence2.389\" NUMERICAL mean:0.00551717 min:-0.074378 max:0.0774961 sd:0.0533483\n",
            "\t835: \"embedded_sentence2.39\" NUMERICAL mean:0.0126597 min:-0.0729709 max:0.0736936 sd:0.03608\n",
            "\t836: \"embedded_sentence2.390\" NUMERICAL mean:-0.00687144 min:-0.0752259 max:0.0756678 sd:0.0370655\n",
            "\t837: \"embedded_sentence2.391\" NUMERICAL mean:-0.00598193 min:-0.0770558 max:0.0676974 sd:0.0313346\n",
            "\t838: \"embedded_sentence2.392\" NUMERICAL mean:0.0200116 min:-0.0618151 max:0.0812708 sd:0.0375904\n",
            "\t839: \"embedded_sentence2.393\" NUMERICAL mean:-0.00619506 min:-0.0823618 max:0.078136 sd:0.0435537\n",
            "\t840: \"embedded_sentence2.394\" NUMERICAL mean:-0.0173875 min:-0.0841615 max:0.0763074 sd:0.0537408\n",
            "\t841: \"embedded_sentence2.395\" NUMERICAL mean:0.0127307 min:-0.0495448 max:0.07729 sd:0.0435626\n",
            "\t842: \"embedded_sentence2.396\" NUMERICAL mean:-0.0184289 min:-0.0850881 max:0.0728457 sd:0.0524155\n",
            "\t843: \"embedded_sentence2.397\" NUMERICAL mean:0.0126241 min:-0.0842012 max:0.0814402 sd:0.0473058\n",
            "\t844: \"embedded_sentence2.398\" NUMERICAL mean:-0.0171808 min:-0.0812003 max:0.0523383 sd:0.0479762\n",
            "\t845: \"embedded_sentence2.399\" NUMERICAL mean:-0.0131101 min:-0.0701813 max:0.0593826 sd:0.0400831\n",
            "\t846: \"embedded_sentence2.4\" NUMERICAL mean:-0.0134462 min:-0.0901561 max:0.0491411 sd:0.0449491\n",
            "\t847: \"embedded_sentence2.40\" NUMERICAL mean:0.00225251 min:-0.0512129 max:0.0707294 sd:0.0300938\n",
            "\t848: \"embedded_sentence2.400\" NUMERICAL mean:-0.00122316 min:-0.0705824 max:0.0788684 sd:0.045616\n",
            "\t849: \"embedded_sentence2.401\" NUMERICAL mean:0.0166858 min:-0.0795988 max:0.081805 sd:0.0364448\n",
            "\t850: \"embedded_sentence2.402\" NUMERICAL mean:-0.021969 min:-0.0810356 max:0.0664156 sd:0.0373547\n",
            "\t851: \"embedded_sentence2.403\" NUMERICAL mean:0.0222404 min:-0.0584714 max:0.0800366 sd:0.0348552\n",
            "\t852: \"embedded_sentence2.404\" NUMERICAL mean:0.0233043 min:-0.0466107 max:0.086945 sd:0.0354967\n",
            "\t853: \"embedded_sentence2.405\" NUMERICAL mean:-0.0287327 min:-0.0738025 max:0.0678135 sd:0.0401103\n",
            "\t854: \"embedded_sentence2.406\" NUMERICAL mean:0.0112828 min:-0.0704947 max:0.0757626 sd:0.032\n",
            "\t855: \"embedded_sentence2.407\" NUMERICAL mean:-0.00179158 min:-0.0763893 max:0.0662969 sd:0.0421649\n",
            "\t856: \"embedded_sentence2.408\" NUMERICAL mean:-0.00114509 min:-0.0562289 max:0.0492456 sd:0.0246542\n",
            "\t857: \"embedded_sentence2.409\" NUMERICAL mean:-0.0140389 min:-0.084427 max:0.0483754 sd:0.0429629\n",
            "\t858: \"embedded_sentence2.41\" NUMERICAL mean:0.00034756 min:-0.0745402 max:0.0674623 sd:0.0324694\n",
            "\t859: \"embedded_sentence2.410\" NUMERICAL mean:-0.0117539 min:-0.0722293 max:0.0595227 sd:0.0427232\n",
            "\t860: \"embedded_sentence2.411\" NUMERICAL mean:-0.00167064 min:-0.0889823 max:0.0701388 sd:0.0345472\n",
            "\t861: \"embedded_sentence2.412\" NUMERICAL mean:-0.00338232 min:-0.0550628 max:0.0788749 sd:0.0380731\n",
            "\t862: \"embedded_sentence2.413\" NUMERICAL mean:-0.0302879 min:-0.0783483 max:0.069227 sd:0.0365715\n",
            "\t863: \"embedded_sentence2.414\" NUMERICAL mean:-0.0147953 min:-0.0758279 max:0.0627389 sd:0.0414282\n",
            "\t864: \"embedded_sentence2.415\" NUMERICAL mean:-0.0175627 min:-0.0838205 max:0.0705915 sd:0.0450759\n",
            "\t865: \"embedded_sentence2.416\" NUMERICAL mean:0.00567428 min:-0.0530562 max:0.0687008 sd:0.0398285\n",
            "\t866: \"embedded_sentence2.417\" NUMERICAL mean:-0.0221494 min:-0.0872156 max:0.0301344 sd:0.0310375\n",
            "\t867: \"embedded_sentence2.418\" NUMERICAL mean:-0.0127107 min:-0.0858369 max:0.0751944 sd:0.0368455\n",
            "\t868: \"embedded_sentence2.419\" NUMERICAL mean:-0.00500495 min:-0.0797443 max:0.082348 sd:0.0587844\n",
            "\t869: \"embedded_sentence2.42\" NUMERICAL mean:-0.019431 min:-0.0741195 max:0.0825754 sd:0.0394789\n",
            "\t870: \"embedded_sentence2.420\" NUMERICAL mean:0.0313658 min:-0.0813124 max:0.0777622 sd:0.0344636\n",
            "\t871: \"embedded_sentence2.421\" NUMERICAL mean:-0.0114311 min:-0.0912561 max:0.0777037 sd:0.0617406\n",
            "\t872: \"embedded_sentence2.422\" NUMERICAL mean:-0.00998876 min:-0.0858222 max:0.0691655 sd:0.0304274\n",
            "\t873: \"embedded_sentence2.423\" NUMERICAL mean:0.010753 min:-0.0885053 max:0.0778361 sd:0.0525666\n",
            "\t874: \"embedded_sentence2.424\" NUMERICAL mean:0.00997538 min:-0.0756834 max:0.0730024 sd:0.0440853\n",
            "\t875: \"embedded_sentence2.425\" NUMERICAL mean:-0.0114688 min:-0.0574781 max:0.0648068 sd:0.0379194\n",
            "\t876: \"embedded_sentence2.426\" NUMERICAL mean:0.0103913 min:-0.0482843 max:0.0799845 sd:0.0313462\n",
            "\t877: \"embedded_sentence2.427\" NUMERICAL mean:-0.000630241 min:-0.0783369 max:0.0718576 sd:0.0334697\n",
            "\t878: \"embedded_sentence2.428\" NUMERICAL mean:0.0231665 min:-0.0768751 max:0.0730099 sd:0.0328046\n",
            "\t879: \"embedded_sentence2.429\" NUMERICAL mean:-0.0318108 min:-0.0867469 max:0.0311857 sd:0.037868\n",
            "\t880: \"embedded_sentence2.43\" NUMERICAL mean:-0.0276397 min:-0.0814448 max:0.059075 sd:0.0536794\n",
            "\t881: \"embedded_sentence2.430\" NUMERICAL mean:-0.00799249 min:-0.082898 max:0.0535824 sd:0.0432905\n",
            "\t882: \"embedded_sentence2.431\" NUMERICAL mean:-0.0123672 min:-0.0848102 max:0.0733984 sd:0.0403097\n",
            "\t883: \"embedded_sentence2.432\" NUMERICAL mean:-0.000817015 min:-0.0756521 max:0.0672366 sd:0.0346495\n",
            "\t884: \"embedded_sentence2.433\" NUMERICAL mean:-0.0309955 min:-0.0838173 max:0.0850113 sd:0.03635\n",
            "\t885: \"embedded_sentence2.434\" NUMERICAL mean:0.0360395 min:-0.0739195 max:0.0957033 sd:0.0350421\n",
            "\t886: \"embedded_sentence2.435\" NUMERICAL mean:-0.0210011 min:-0.0862496 max:0.0442261 sd:0.0278148\n",
            "\t887: \"embedded_sentence2.436\" NUMERICAL mean:0.00339981 min:-0.0767763 max:0.0857405 sd:0.0359867\n",
            "\t888: \"embedded_sentence2.437\" NUMERICAL mean:-0.0259212 min:-0.0835049 max:0.0718285 sd:0.0430465\n",
            "\t889: \"embedded_sentence2.438\" NUMERICAL mean:-0.0206666 min:-0.0798826 max:0.0642645 sd:0.0392487\n",
            "\t890: \"embedded_sentence2.439\" NUMERICAL mean:-0.0216745 min:-0.0858287 max:0.0814685 sd:0.0397778\n",
            "\t891: \"embedded_sentence2.44\" NUMERICAL mean:0.0190302 min:-0.0466481 max:0.0771718 sd:0.0338935\n",
            "\t892: \"embedded_sentence2.440\" NUMERICAL mean:-0.0023238 min:-0.0819156 max:0.0492605 sd:0.0406254\n",
            "\t893: \"embedded_sentence2.441\" NUMERICAL mean:-0.0150634 min:-0.0831123 max:0.0563454 sd:0.028397\n",
            "\t894: \"embedded_sentence2.442\" NUMERICAL mean:-0.00549855 min:-0.0773279 max:0.0687385 sd:0.0523461\n",
            "\t895: \"embedded_sentence2.443\" NUMERICAL mean:0.0393483 min:-0.0496633 max:0.0756468 sd:0.0343949\n",
            "\t896: \"embedded_sentence2.444\" NUMERICAL mean:-0.0227734 min:-0.0781126 max:0.0756875 sd:0.0399806\n",
            "\t897: \"embedded_sentence2.445\" NUMERICAL mean:0.0119851 min:-0.0804587 max:0.0851473 sd:0.0477441\n",
            "\t898: \"embedded_sentence2.446\" NUMERICAL mean:-0.00595149 min:-0.0791334 max:0.0765662 sd:0.0336604\n",
            "\t899: \"embedded_sentence2.447\" NUMERICAL mean:-0.0170188 min:-0.0877762 max:0.0826047 sd:0.0355899\n",
            "\t900: \"embedded_sentence2.448\" NUMERICAL mean:-0.011309 min:-0.0789317 max:0.0679382 sd:0.0387022\n",
            "\t901: \"embedded_sentence2.449\" NUMERICAL mean:-0.00097196 min:-0.0816727 max:0.0759926 sd:0.0472311\n",
            "\t902: \"embedded_sentence2.45\" NUMERICAL mean:0.00971464 min:-0.0653166 max:0.0809786 sd:0.0410144\n",
            "\t903: \"embedded_sentence2.450\" NUMERICAL mean:-0.0301561 min:-0.0832013 max:0.0836189 sd:0.036489\n",
            "\t904: \"embedded_sentence2.451\" NUMERICAL mean:-0.0125823 min:-0.0737568 max:0.0640174 sd:0.0316804\n",
            "\t905: \"embedded_sentence2.452\" NUMERICAL mean:0.0416744 min:-0.0513553 max:0.0874275 sd:0.0330362\n",
            "\t906: \"embedded_sentence2.453\" NUMERICAL mean:0.0252183 min:-0.0623617 max:0.0808668 sd:0.0328793\n",
            "\t907: \"embedded_sentence2.454\" NUMERICAL mean:0.0147362 min:-0.0724566 max:0.0635439 sd:0.0324436\n",
            "\t908: \"embedded_sentence2.455\" NUMERICAL mean:0.03425 min:-0.0758163 max:0.0793117 sd:0.0339216\n",
            "\t909: \"embedded_sentence2.456\" NUMERICAL mean:0.00327309 min:-0.0751563 max:0.077431 sd:0.0481826\n",
            "\t910: \"embedded_sentence2.457\" NUMERICAL mean:-0.00279639 min:-0.0795461 max:0.0701151 sd:0.0344538\n",
            "\t911: \"embedded_sentence2.458\" NUMERICAL mean:-0.0220378 min:-0.0821334 max:0.071066 sd:0.0411032\n",
            "\t912: \"embedded_sentence2.459\" NUMERICAL mean:0.0496268 min:-0.0555944 max:0.0869316 sd:0.0351432\n",
            "\t913: \"embedded_sentence2.46\" NUMERICAL mean:-0.0146491 min:-0.0540595 max:0.0552609 sd:0.0322227\n",
            "\t914: \"embedded_sentence2.460\" NUMERICAL mean:0.00588165 min:-0.0775202 max:0.0775987 sd:0.0406034\n",
            "\t915: \"embedded_sentence2.461\" NUMERICAL mean:0.0182925 min:-0.0646884 max:0.0736591 sd:0.0292854\n",
            "\t916: \"embedded_sentence2.462\" NUMERICAL mean:0.0118762 min:-0.0562219 max:0.079913 sd:0.0392368\n",
            "\t917: \"embedded_sentence2.463\" NUMERICAL mean:-0.0224546 min:-0.0887982 max:0.0733025 sd:0.0384269\n",
            "\t918: \"embedded_sentence2.464\" NUMERICAL mean:-0.00972001 min:-0.0609981 max:0.058239 sd:0.0330876\n",
            "\t919: \"embedded_sentence2.465\" NUMERICAL mean:-0.00195269 min:-0.0542599 max:0.0592777 sd:0.0321969\n",
            "\t920: \"embedded_sentence2.466\" NUMERICAL mean:-0.00435349 min:-0.0796764 max:0.071952 sd:0.0376801\n",
            "\t921: \"embedded_sentence2.467\" NUMERICAL mean:0.0273343 min:-0.0312811 max:0.0836156 sd:0.0413453\n",
            "\t922: \"embedded_sentence2.468\" NUMERICAL mean:0.0093302 min:-0.0797892 max:0.0697639 sd:0.0405441\n",
            "\t923: \"embedded_sentence2.469\" NUMERICAL mean:0.0127858 min:-0.0674835 max:0.083262 sd:0.0465274\n",
            "\t924: \"embedded_sentence2.47\" NUMERICAL mean:0.0195851 min:-0.0558285 max:0.0867272 sd:0.0299765\n",
            "\t925: \"embedded_sentence2.470\" NUMERICAL mean:-0.0107612 min:-0.0699484 max:0.0678541 sd:0.0450109\n",
            "\t926: \"embedded_sentence2.471\" NUMERICAL mean:-0.00177483 min:-0.0717399 max:0.0762583 sd:0.0419899\n",
            "\t927: \"embedded_sentence2.472\" NUMERICAL mean:-0.0160775 min:-0.0723245 max:0.0689706 sd:0.032161\n",
            "\t928: \"embedded_sentence2.473\" NUMERICAL mean:0.0132474 min:-0.0722808 max:0.0812135 sd:0.0367423\n",
            "\t929: \"embedded_sentence2.474\" NUMERICAL mean:-0.012633 min:-0.0814547 max:0.0732926 sd:0.0515941\n",
            "\t930: \"embedded_sentence2.475\" NUMERICAL mean:0.0120767 min:-0.0546293 max:0.0839213 sd:0.0350117\n",
            "\t931: \"embedded_sentence2.476\" NUMERICAL mean:-0.0311036 min:-0.0820514 max:0.0866585 sd:0.0484308\n",
            "\t932: \"embedded_sentence2.477\" NUMERICAL mean:0.0176285 min:-0.0809594 max:0.0866258 sd:0.0349388\n",
            "\t933: \"embedded_sentence2.478\" NUMERICAL mean:0.000158 min:-0.0723485 max:0.0661264 sd:0.034853\n",
            "\t934: \"embedded_sentence2.479\" NUMERICAL mean:0.0601472 min:0.00717998 max:0.0868173 sd:0.0147036\n",
            "\t935: \"embedded_sentence2.48\" NUMERICAL mean:-0.00693035 min:-0.0827113 max:0.0782221 sd:0.0317891\n",
            "\t936: \"embedded_sentence2.480\" NUMERICAL mean:0.0256845 min:-0.0553871 max:0.0896636 sd:0.0305442\n",
            "\t937: \"embedded_sentence2.481\" NUMERICAL mean:-0.000951209 min:-0.0760451 max:0.0799961 sd:0.0559929\n",
            "\t938: \"embedded_sentence2.482\" NUMERICAL mean:-0.00850473 min:-0.0849784 max:0.0666722 sd:0.038209\n",
            "\t939: \"embedded_sentence2.483\" NUMERICAL mean:-0.016479 min:-0.082453 max:0.0299536 sd:0.0369402\n",
            "\t940: \"embedded_sentence2.484\" NUMERICAL mean:0.00991199 min:-0.0562975 max:0.0767573 sd:0.0474883\n",
            "\t941: \"embedded_sentence2.485\" NUMERICAL mean:-0.00819981 min:-0.0813488 max:0.0799579 sd:0.0547739\n",
            "\t942: \"embedded_sentence2.486\" NUMERICAL mean:0.00742546 min:-0.0726915 max:0.0878008 sd:0.0474443\n",
            "\t943: \"embedded_sentence2.487\" NUMERICAL mean:-0.0021232 min:-0.0549021 max:0.0719126 sd:0.0307164\n",
            "\t944: \"embedded_sentence2.488\" NUMERICAL mean:0.0209274 min:-0.0790685 max:0.0793795 sd:0.0479536\n",
            "\t945: \"embedded_sentence2.489\" NUMERICAL mean:0.0217536 min:-0.0847975 max:0.0950378 sd:0.0451171\n",
            "\t946: \"embedded_sentence2.49\" NUMERICAL mean:0.0002065 min:-0.0707125 max:0.068604 sd:0.0326858\n",
            "\t947: \"embedded_sentence2.490\" NUMERICAL mean:-0.0126062 min:-0.0736673 max:0.0505946 sd:0.0337933\n",
            "\t948: \"embedded_sentence2.491\" NUMERICAL mean:-0.0120319 min:-0.0731348 max:0.0775618 sd:0.0464551\n",
            "\t949: \"embedded_sentence2.492\" NUMERICAL mean:-0.0273719 min:-0.0871333 max:0.0748383 sd:0.0373257\n",
            "\t950: \"embedded_sentence2.493\" NUMERICAL mean:-0.000576465 min:-0.0654965 max:0.0713618 sd:0.0289987\n",
            "\t951: \"embedded_sentence2.494\" NUMERICAL mean:-0.00600028 min:-0.0640997 max:0.0661104 sd:0.0331993\n",
            "\t952: \"embedded_sentence2.495\" NUMERICAL mean:0.0140474 min:-0.0732603 max:0.0874045 sd:0.040761\n",
            "\t953: \"embedded_sentence2.496\" NUMERICAL mean:0.0084089 min:-0.0661219 max:0.0747899 sd:0.0338398\n",
            "\t954: \"embedded_sentence2.497\" NUMERICAL mean:0.0107825 min:-0.073171 max:0.0738034 sd:0.0396245\n",
            "\t955: \"embedded_sentence2.498\" NUMERICAL mean:-0.00200011 min:-0.0736527 max:0.0621178 sd:0.041913\n",
            "\t956: \"embedded_sentence2.499\" NUMERICAL mean:-0.00811455 min:-0.0719774 max:0.0759223 sd:0.0453904\n",
            "\t957: \"embedded_sentence2.5\" NUMERICAL mean:0.0216816 min:-0.0663799 max:0.0805036 sd:0.0394509\n",
            "\t958: \"embedded_sentence2.50\" NUMERICAL mean:0.00406868 min:-0.0847508 max:0.0879229 sd:0.0570367\n",
            "\t959: \"embedded_sentence2.500\" NUMERICAL mean:-0.00725188 min:-0.0626466 max:0.0729601 sd:0.035287\n",
            "\t960: \"embedded_sentence2.501\" NUMERICAL mean:-0.0146837 min:-0.063589 max:0.0643597 sd:0.0379392\n",
            "\t961: \"embedded_sentence2.502\" NUMERICAL mean:-0.00444428 min:-0.0826436 max:0.0817105 sd:0.0434329\n",
            "\t962: \"embedded_sentence2.503\" NUMERICAL mean:-0.0703854 min:-0.0936837 max:0.0534076 sd:0.0313745\n",
            "\t963: \"embedded_sentence2.504\" NUMERICAL mean:0.0216996 min:-0.0404099 max:0.0859719 sd:0.0375263\n",
            "\t964: \"embedded_sentence2.505\" NUMERICAL mean:-0.0135934 min:-0.0809763 max:0.067549 sd:0.0425939\n",
            "\t965: \"embedded_sentence2.506\" NUMERICAL mean:-0.0396236 min:-0.0862128 max:0.0639335 sd:0.0388056\n",
            "\t966: \"embedded_sentence2.507\" NUMERICAL mean:0.0295608 min:-0.0725049 max:0.0766674 sd:0.0357324\n",
            "\t967: \"embedded_sentence2.508\" NUMERICAL mean:-0.0138376 min:-0.0559159 max:0.0567758 sd:0.0281486\n",
            "\t968: \"embedded_sentence2.509\" NUMERICAL mean:-0.00119029 min:-0.0662389 max:0.0720393 sd:0.0372087\n",
            "\t969: \"embedded_sentence2.51\" NUMERICAL mean:0.00917122 min:-0.0456062 max:0.0705054 sd:0.0433962\n",
            "\t970: \"embedded_sentence2.510\" NUMERICAL mean:-0.00790373 min:-0.0679693 max:0.0734747 sd:0.028156\n",
            "\t971: \"embedded_sentence2.511\" NUMERICAL mean:-0.019362 min:-0.0726672 max:0.0659069 sd:0.0410621\n",
            "\t972: \"embedded_sentence2.52\" NUMERICAL mean:0.0400837 min:-0.0408771 max:0.0757813 sd:0.031465\n",
            "\t973: \"embedded_sentence2.53\" NUMERICAL mean:0.00742256 min:-0.0705274 max:0.0821537 sd:0.0547691\n",
            "\t974: \"embedded_sentence2.54\" NUMERICAL mean:-0.00534229 min:-0.0786544 max:0.0799104 sd:0.0396754\n",
            "\t975: \"embedded_sentence2.55\" NUMERICAL mean:-0.0182216 min:-0.0842774 max:0.0707748 sd:0.04083\n",
            "\t976: \"embedded_sentence2.56\" NUMERICAL mean:0.0274589 min:-0.0399425 max:0.0710339 sd:0.025258\n",
            "\t977: \"embedded_sentence2.57\" NUMERICAL mean:0.00259768 min:-0.075004 max:0.0778597 sd:0.0558734\n",
            "\t978: \"embedded_sentence2.58\" NUMERICAL mean:0.0416277 min:-0.0153215 max:0.0865427 sd:0.0263845\n",
            "\t979: \"embedded_sentence2.59\" NUMERICAL mean:-0.0171267 min:-0.0673355 max:0.0839901 sd:0.0379616\n",
            "\t980: \"embedded_sentence2.6\" NUMERICAL mean:-0.0127991 min:-0.0774928 max:0.0742184 sd:0.0397294\n",
            "\t981: \"embedded_sentence2.60\" NUMERICAL mean:-0.0224063 min:-0.0785819 max:0.0737737 sd:0.0356535\n",
            "\t982: \"embedded_sentence2.61\" NUMERICAL mean:-0.0110432 min:-0.0780114 max:0.0722687 sd:0.0463815\n",
            "\t983: \"embedded_sentence2.62\" NUMERICAL mean:-0.0225687 min:-0.0855532 max:0.0312615 sd:0.0387885\n",
            "\t984: \"embedded_sentence2.63\" NUMERICAL mean:-0.0138822 min:-0.0840089 max:0.0525789 sd:0.0373926\n",
            "\t985: \"embedded_sentence2.64\" NUMERICAL mean:-0.0271719 min:-0.0807795 max:0.0473222 sd:0.0332065\n",
            "\t986: \"embedded_sentence2.65\" NUMERICAL mean:-0.0037809 min:-0.0634501 max:0.0671982 sd:0.0302281\n",
            "\t987: \"embedded_sentence2.66\" NUMERICAL mean:-0.040047 min:-0.0891938 max:0.0525084 sd:0.0340907\n",
            "\t988: \"embedded_sentence2.67\" NUMERICAL mean:-0.0347701 min:-0.0812207 max:0.0632564 sd:0.0339868\n",
            "\t989: \"embedded_sentence2.68\" NUMERICAL mean:0.00191106 min:-0.0614828 max:0.0746871 sd:0.0345312\n",
            "\t990: \"embedded_sentence2.69\" NUMERICAL mean:0.0184955 min:-0.0563188 max:0.0610995 sd:0.0353831\n",
            "\t991: \"embedded_sentence2.7\" NUMERICAL mean:-0.0197609 min:-0.0746279 max:0.0399548 sd:0.0258295\n",
            "\t992: \"embedded_sentence2.70\" NUMERICAL mean:-0.012577 min:-0.0715264 max:0.0744554 sd:0.0469598\n",
            "\t993: \"embedded_sentence2.71\" NUMERICAL mean:-0.0364967 min:-0.0935656 max:0.041973 sd:0.0372723\n",
            "\t994: \"embedded_sentence2.72\" NUMERICAL mean:-0.0345519 min:-0.0896165 max:0.0286085 sd:0.025159\n",
            "\t995: \"embedded_sentence2.73\" NUMERICAL mean:-0.0098439 min:-0.0754623 max:0.0904601 sd:0.0473064\n",
            "\t996: \"embedded_sentence2.74\" NUMERICAL mean:-0.000743604 min:-0.0847301 max:0.082273 sd:0.0342435\n",
            "\t997: \"embedded_sentence2.75\" NUMERICAL mean:-0.0530832 min:-0.0997146 max:0.0147622 sd:0.0416333\n",
            "\t998: \"embedded_sentence2.76\" NUMERICAL mean:-0.00516978 min:-0.0569984 max:0.0787828 sd:0.0374096\n",
            "\t999: \"embedded_sentence2.77\" NUMERICAL mean:0.0106272 min:-0.0761918 max:0.0817311 sd:0.0399919\n",
            "\t1000: \"embedded_sentence2.78\" NUMERICAL mean:-0.0144294 min:-0.0796465 max:0.071511 sd:0.0356382\n",
            "\t1001: \"embedded_sentence2.79\" NUMERICAL mean:-0.0281316 min:-0.0709536 max:0.0347653 sd:0.033537\n",
            "\t1002: \"embedded_sentence2.8\" NUMERICAL mean:0.0210292 min:-0.0788077 max:0.0899742 sd:0.0482739\n",
            "\t1003: \"embedded_sentence2.80\" NUMERICAL mean:0.00117171 min:-0.0823701 max:0.0795478 sd:0.0388054\n",
            "\t1004: \"embedded_sentence2.81\" NUMERICAL mean:0.0113181 min:-0.0657497 max:0.0710837 sd:0.034583\n",
            "\t1005: \"embedded_sentence2.82\" NUMERICAL mean:-0.0331033 min:-0.078397 max:0.0166077 sd:0.0310011\n",
            "\t1006: \"embedded_sentence2.83\" NUMERICAL mean:-0.0124031 min:-0.0698296 max:0.0715785 sd:0.0346627\n",
            "\t1007: \"embedded_sentence2.84\" NUMERICAL mean:-0.0293154 min:-0.0730909 max:0.0445317 sd:0.0302838\n",
            "\t1008: \"embedded_sentence2.85\" NUMERICAL mean:0.020573 min:-0.0597586 max:0.0858496 sd:0.0342415\n",
            "\t1009: \"embedded_sentence2.86\" NUMERICAL mean:-0.0113394 min:-0.0811838 max:0.0649226 sd:0.0413248\n",
            "\t1010: \"embedded_sentence2.87\" NUMERICAL mean:0.0109334 min:-0.0841363 max:0.0725963 sd:0.0319937\n",
            "\t1011: \"embedded_sentence2.88\" NUMERICAL mean:0.0321917 min:-0.0657271 max:0.0807916 sd:0.0303238\n",
            "\t1012: \"embedded_sentence2.89\" NUMERICAL mean:-0.0229363 min:-0.0869571 max:0.0530866 sd:0.0435674\n",
            "\t1013: \"embedded_sentence2.9\" NUMERICAL mean:-0.0399061 min:-0.0911646 max:0.0648994 sd:0.0442538\n",
            "\t1014: \"embedded_sentence2.90\" NUMERICAL mean:0.00886666 min:-0.0742001 max:0.0671625 sd:0.0452588\n",
            "\t1015: \"embedded_sentence2.91\" NUMERICAL mean:0.0259947 min:-0.0548004 max:0.0672113 sd:0.0260776\n",
            "\t1016: \"embedded_sentence2.92\" NUMERICAL mean:0.00866121 min:-0.0731228 max:0.0778529 sd:0.0341337\n",
            "\t1017: \"embedded_sentence2.93\" NUMERICAL mean:0.0222674 min:-0.0609382 max:0.0755306 sd:0.033203\n",
            "\t1018: \"embedded_sentence2.94\" NUMERICAL mean:-0.0111276 min:-0.0687289 max:0.0771702 sd:0.0291744\n",
            "\t1019: \"embedded_sentence2.95\" NUMERICAL mean:0.0282472 min:-0.0594988 max:0.0914948 sd:0.0420873\n",
            "\t1020: \"embedded_sentence2.96\" NUMERICAL mean:-0.0133404 min:-0.0809273 max:0.0569203 sd:0.0278334\n",
            "\t1021: \"embedded_sentence2.97\" NUMERICAL mean:0.0105104 min:-0.0776563 max:0.0691548 sd:0.0374411\n",
            "\t1022: \"embedded_sentence2.98\" NUMERICAL mean:-0.0145707 min:-0.0755602 max:0.0547723 sd:0.0287259\n",
            "\t1023: \"embedded_sentence2.99\" NUMERICAL mean:-0.0322461 min:-0.092401 max:0.0542666 sd:0.0362605\n",
            "\t1024: \"embedded_sentence3.0\" NUMERICAL mean:-0.012883 min:-0.0527605 max:0.0786784 sd:0.0476715\n",
            "\t1025: \"embedded_sentence3.1\" NUMERICAL mean:-0.0231689 min:-0.075578 max:0.0805118 sd:0.0464229\n",
            "\t1026: \"embedded_sentence3.10\" NUMERICAL mean:-0.00613912 min:-0.0715079 max:0.0548345 sd:0.0340392\n",
            "\t1027: \"embedded_sentence3.100\" NUMERICAL mean:0.0217714 min:-0.0696627 max:0.0851645 sd:0.0313123\n",
            "\t1028: \"embedded_sentence3.101\" NUMERICAL mean:0.0048894 min:-0.0503826 max:0.0724849 sd:0.0310316\n",
            "\t1029: \"embedded_sentence3.102\" NUMERICAL mean:-0.00592775 min:-0.0688044 max:0.0449554 sd:0.0263416\n",
            "\t1030: \"embedded_sentence3.103\" NUMERICAL mean:-0.0338845 min:-0.0799086 max:0.0608811 sd:0.0351386\n",
            "\t1031: \"embedded_sentence3.104\" NUMERICAL mean:0.00589036 min:-0.0813981 max:0.0587698 sd:0.0562696\n",
            "\t1032: \"embedded_sentence3.105\" NUMERICAL mean:0.0402762 min:-0.0586636 max:0.080041 sd:0.029423\n",
            "\t1033: \"embedded_sentence3.106\" NUMERICAL mean:-0.0139023 min:-0.0622832 max:0.0800829 sd:0.0518682\n",
            "\t1034: \"embedded_sentence3.107\" NUMERICAL mean:-0.00377902 min:-0.070907 max:0.0729387 sd:0.0275702\n",
            "\t1035: \"embedded_sentence3.108\" NUMERICAL mean:0.0250951 min:-0.0846081 max:0.0664608 sd:0.049121\n",
            "\t1036: \"embedded_sentence3.109\" NUMERICAL mean:0.00767456 min:-0.0765212 max:0.0700321 sd:0.0343897\n",
            "\t1037: \"embedded_sentence3.11\" NUMERICAL mean:0.0279705 min:-0.0816538 max:0.0717064 sd:0.0518551\n",
            "\t1038: \"embedded_sentence3.110\" NUMERICAL mean:-0.0231278 min:-0.0657707 max:0.0808842 sd:0.0503234\n",
            "\t1039: \"embedded_sentence3.111\" NUMERICAL mean:-0.0402862 min:-0.0731574 max:0.0854803 sd:0.0424644\n",
            "\t1040: \"embedded_sentence3.112\" NUMERICAL mean:-0.0200561 min:-0.0572308 max:0.0739925 sd:0.0285631\n",
            "\t1041: \"embedded_sentence3.113\" NUMERICAL mean:0.013101 min:-0.0651272 max:0.0751122 sd:0.0268467\n",
            "\t1042: \"embedded_sentence3.114\" NUMERICAL mean:-0.0181136 min:-0.0762976 max:0.0834244 sd:0.0386826\n",
            "\t1043: \"embedded_sentence3.115\" NUMERICAL mean:0.0168969 min:-0.0807347 max:0.0849213 sd:0.0711273\n",
            "\t1044: \"embedded_sentence3.116\" NUMERICAL mean:-0.0290146 min:-0.0764733 max:0.0623469 sd:0.0252889\n",
            "\t1045: \"embedded_sentence3.117\" NUMERICAL mean:-0.00208549 min:-0.057718 max:0.0809525 sd:0.0257445\n",
            "\t1046: \"embedded_sentence3.118\" NUMERICAL mean:0.0291105 min:-0.0635652 max:0.0661499 sd:0.0380529\n",
            "\t1047: \"embedded_sentence3.119\" NUMERICAL mean:0.00440428 min:-0.0769609 max:0.0775689 sd:0.0387274\n",
            "\t1048: \"embedded_sentence3.12\" NUMERICAL mean:0.0240366 min:-0.0670997 max:0.0810342 sd:0.03401\n",
            "\t1049: \"embedded_sentence3.120\" NUMERICAL mean:0.0117002 min:-0.0710274 max:0.0660757 sd:0.0313921\n",
            "\t1050: \"embedded_sentence3.121\" NUMERICAL mean:-0.00523814 min:-0.0814657 max:0.0855937 sd:0.0291729\n",
            "\t1051: \"embedded_sentence3.122\" NUMERICAL mean:0.0252268 min:-0.0628974 max:0.0893786 sd:0.0327387\n",
            "\t1052: \"embedded_sentence3.123\" NUMERICAL mean:-0.0189389 min:-0.0669866 max:0.0631347 sd:0.0375678\n",
            "\t1053: \"embedded_sentence3.124\" NUMERICAL mean:0.0125779 min:-0.0868021 max:0.0640064 sd:0.0460175\n",
            "\t1054: \"embedded_sentence3.125\" NUMERICAL mean:0.0367622 min:-0.038562 max:0.0820163 sd:0.0229019\n",
            "\t1055: \"embedded_sentence3.126\" NUMERICAL mean:0.0109653 min:-0.0673444 max:0.0784845 sd:0.0298398\n",
            "\t1056: \"embedded_sentence3.127\" NUMERICAL mean:0.0197745 min:-0.0417764 max:0.0552596 sd:0.0184259\n",
            "\t1057: \"embedded_sentence3.128\" NUMERICAL mean:-0.00590728 min:-0.0819424 max:0.0610756 sd:0.034357\n",
            "\t1058: \"embedded_sentence3.129\" NUMERICAL mean:-0.0050102 min:-0.0481218 max:0.089866 sd:0.052286\n",
            "\t1059: \"embedded_sentence3.13\" NUMERICAL mean:-0.029295 min:-0.066643 max:0.0496725 sd:0.0447327\n",
            "\t1060: \"embedded_sentence3.130\" NUMERICAL mean:-0.0629496 min:-0.0811514 max:0.0269508 sd:0.0213026\n",
            "\t1061: \"embedded_sentence3.131\" NUMERICAL mean:-0.0112093 min:-0.0776987 max:0.0686747 sd:0.0281614\n",
            "\t1062: \"embedded_sentence3.132\" NUMERICAL mean:0.0433236 min:-0.0325578 max:0.0782681 sd:0.0227128\n",
            "\t1063: \"embedded_sentence3.133\" NUMERICAL mean:0.0475714 min:-0.0350837 max:0.0810143 sd:0.0222069\n",
            "\t1064: \"embedded_sentence3.134\" NUMERICAL mean:0.0487355 min:-0.057349 max:0.0772781 sd:0.0264944\n",
            "\t1065: \"embedded_sentence3.135\" NUMERICAL mean:0.0170069 min:-0.0493666 max:0.0717696 sd:0.0221054\n",
            "\t1066: \"embedded_sentence3.136\" NUMERICAL mean:0.0472823 min:-0.0680487 max:0.0897456 sd:0.0489742\n",
            "\t1067: \"embedded_sentence3.137\" NUMERICAL mean:0.0326284 min:-0.0245819 max:0.0854309 sd:0.0221515\n",
            "\t1068: \"embedded_sentence3.138\" NUMERICAL mean:0.00468585 min:-0.0482091 max:0.0692426 sd:0.0305279\n",
            "\t1069: \"embedded_sentence3.139\" NUMERICAL mean:-0.0411959 min:-0.0938319 max:0.0433206 sd:0.0262301\n",
            "\t1070: \"embedded_sentence3.14\" NUMERICAL mean:-0.00886526 min:-0.0791295 max:0.0717761 sd:0.0256248\n",
            "\t1071: \"embedded_sentence3.140\" NUMERICAL mean:-0.0387975 min:-0.0827778 max:0.069515 sd:0.0240868\n",
            "\t1072: \"embedded_sentence3.141\" NUMERICAL mean:-0.015929 min:-0.0595824 max:0.0421987 sd:0.0179595\n",
            "\t1073: \"embedded_sentence3.142\" NUMERICAL mean:-0.0286969 min:-0.0551218 max:0.0597964 sd:0.0307234\n",
            "\t1074: \"embedded_sentence3.143\" NUMERICAL mean:-0.0133089 min:-0.0656165 max:0.066467 sd:0.0229923\n",
            "\t1075: \"embedded_sentence3.144\" NUMERICAL mean:0.0241552 min:-0.0633935 max:0.0730216 sd:0.0222557\n",
            "\t1076: \"embedded_sentence3.145\" NUMERICAL mean:-0.0256776 min:-0.0877561 max:0.0723638 sd:0.0388311\n",
            "\t1077: \"embedded_sentence3.146\" NUMERICAL mean:0.00137573 min:-0.0744498 max:0.02865 sd:0.0335771\n",
            "\t1078: \"embedded_sentence3.147\" NUMERICAL mean:0.00933952 min:-0.0502419 max:0.0587874 sd:0.0211479\n",
            "\t1079: \"embedded_sentence3.148\" NUMERICAL mean:-0.0214523 min:-0.0692774 max:0.0827912 sd:0.0561175\n",
            "\t1080: \"embedded_sentence3.149\" NUMERICAL mean:-0.0434682 min:-0.0939994 max:0.076389 sd:0.0569738\n",
            "\t1081: \"embedded_sentence3.15\" NUMERICAL mean:0.00216224 min:-0.0740132 max:0.0810192 sd:0.0346731\n",
            "\t1082: \"embedded_sentence3.150\" NUMERICAL mean:-0.00773791 min:-0.0826414 max:0.0631281 sd:0.0288321\n",
            "\t1083: \"embedded_sentence3.151\" NUMERICAL mean:0.0196265 min:-0.0299462 max:0.0907169 sd:0.0281467\n",
            "\t1084: \"embedded_sentence3.152\" NUMERICAL mean:-0.048089 min:-0.0828123 max:0.0428273 sd:0.0218178\n",
            "\t1085: \"embedded_sentence3.153\" NUMERICAL mean:-0.0306837 min:-0.0717582 max:0.0780775 sd:0.0323535\n",
            "\t1086: \"embedded_sentence3.154\" NUMERICAL mean:-0.0266483 min:-0.0801085 max:0.0702634 sd:0.0315716\n",
            "\t1087: \"embedded_sentence3.155\" NUMERICAL mean:-0.0309507 min:-0.0714977 max:0.0634167 sd:0.0286361\n",
            "\t1088: \"embedded_sentence3.156\" NUMERICAL mean:0.00645449 min:-0.0755695 max:0.0781948 sd:0.0408778\n",
            "\t1089: \"embedded_sentence3.157\" NUMERICAL mean:-0.0331196 min:-0.0806103 max:0.0690033 sd:0.029721\n",
            "\t1090: \"embedded_sentence3.158\" NUMERICAL mean:-0.0264937 min:-0.0719229 max:0.0720413 sd:0.0319502\n",
            "\t1091: \"embedded_sentence3.159\" NUMERICAL mean:-0.0061064 min:-0.0789429 max:0.0780926 sd:0.0343346\n",
            "\t1092: \"embedded_sentence3.16\" NUMERICAL mean:-0.00977106 min:-0.0693144 max:0.0623407 sd:0.0251169\n",
            "\t1093: \"embedded_sentence3.160\" NUMERICAL mean:0.0191737 min:-0.0868888 max:0.0644001 sd:0.0433979\n",
            "\t1094: \"embedded_sentence3.161\" NUMERICAL mean:0.0233011 min:-0.075961 max:0.0816763 sd:0.0304426\n",
            "\t1095: \"embedded_sentence3.162\" NUMERICAL mean:-0.0537277 min:-0.0766149 max:0.0394428 sd:0.0298077\n",
            "\t1096: \"embedded_sentence3.163\" NUMERICAL mean:-0.0233371 min:-0.070381 max:0.0755633 sd:0.0527518\n",
            "\t1097: \"embedded_sentence3.164\" NUMERICAL mean:-0.0275959 min:-0.0628538 max:0.06125 sd:0.0407714\n",
            "\t1098: \"embedded_sentence3.165\" NUMERICAL mean:0.0313486 min:-0.0932416 max:0.0746608 sd:0.0377449\n",
            "\t1099: \"embedded_sentence3.166\" NUMERICAL mean:-0.0156116 min:-0.0652041 max:0.0552691 sd:0.0303378\n",
            "\t1100: \"embedded_sentence3.167\" NUMERICAL mean:-0.0203307 min:-0.0773795 max:0.0628112 sd:0.028087\n",
            "\t1101: \"embedded_sentence3.168\" NUMERICAL mean:0.0319833 min:-0.0874119 max:0.0665381 sd:0.0432204\n",
            "\t1102: \"embedded_sentence3.169\" NUMERICAL mean:-0.026563 min:-0.0805843 max:0.0608838 sd:0.0295899\n",
            "\t1103: \"embedded_sentence3.17\" NUMERICAL mean:0.0162 min:-0.0826033 max:0.0529727 sd:0.0449333\n",
            "\t1104: \"embedded_sentence3.170\" NUMERICAL mean:-0.0264169 min:-0.0764654 max:0.0628436 sd:0.0241222\n",
            "\t1105: \"embedded_sentence3.171\" NUMERICAL mean:-0.0271848 min:-0.0883627 max:0.0690471 sd:0.0654163\n",
            "\t1106: \"embedded_sentence3.172\" NUMERICAL mean:0.00597436 min:-0.0682252 max:0.0765509 sd:0.0246514\n",
            "\t1107: \"embedded_sentence3.173\" NUMERICAL mean:-0.00146286 min:-0.0624051 max:0.0690802 sd:0.0258078\n",
            "\t1108: \"embedded_sentence3.174\" NUMERICAL mean:-0.000200077 min:-0.0661317 max:0.0841813 sd:0.03822\n",
            "\t1109: \"embedded_sentence3.175\" NUMERICAL mean:0.0245799 min:-0.0399283 max:0.061752 sd:0.0211185\n",
            "\t1110: \"embedded_sentence3.176\" NUMERICAL mean:0.00245689 min:-0.0621148 max:0.0729005 sd:0.0334944\n",
            "\t1111: \"embedded_sentence3.177\" NUMERICAL mean:-0.0235245 min:-0.083431 max:0.0332402 sd:0.0241663\n",
            "\t1112: \"embedded_sentence3.178\" NUMERICAL mean:0.0138979 min:-0.0713834 max:0.0672491 sd:0.0315533\n",
            "\t1113: \"embedded_sentence3.179\" NUMERICAL mean:-0.00220143 min:-0.0647181 max:0.077855 sd:0.0308809\n",
            "\t1114: \"embedded_sentence3.18\" NUMERICAL mean:0.00811356 min:-0.0557763 max:0.0739673 sd:0.0231613\n",
            "\t1115: \"embedded_sentence3.180\" NUMERICAL mean:0.00563544 min:-0.07756 max:0.061568 sd:0.032303\n",
            "\t1116: \"embedded_sentence3.181\" NUMERICAL mean:-0.00864507 min:-0.0727504 max:0.0816136 sd:0.0477397\n",
            "\t1117: \"embedded_sentence3.182\" NUMERICAL mean:0.00200987 min:-0.0632115 max:0.0769727 sd:0.0244104\n",
            "\t1118: \"embedded_sentence3.183\" NUMERICAL mean:-0.0204034 min:-0.0762123 max:0.080142 sd:0.0327625\n",
            "\t1119: \"embedded_sentence3.184\" NUMERICAL mean:-0.00714043 min:-0.0659862 max:0.0807421 sd:0.0633295\n",
            "\t1120: \"embedded_sentence3.185\" NUMERICAL mean:-0.0203462 min:-0.0541824 max:0.0618157 sd:0.0373919\n",
            "\t1121: \"embedded_sentence3.186\" NUMERICAL mean:-0.00397802 min:-0.0819139 max:0.0394393 sd:0.04973\n",
            "\t1122: \"embedded_sentence3.187\" NUMERICAL mean:0.0111184 min:-0.0534394 max:0.063779 sd:0.022935\n",
            "\t1123: \"embedded_sentence3.188\" NUMERICAL mean:0.0246064 min:-0.0733957 max:0.0552307 sd:0.0292148\n",
            "\t1124: \"embedded_sentence3.189\" NUMERICAL mean:-0.0352372 min:-0.0667877 max:0.0625362 sd:0.0386079\n",
            "\t1125: \"embedded_sentence3.19\" NUMERICAL mean:-0.0151138 min:-0.0880161 max:0.0346771 sd:0.0499693\n",
            "\t1126: \"embedded_sentence3.190\" NUMERICAL mean:0.000871698 min:-0.0705999 max:0.0886965 sd:0.040698\n",
            "\t1127: \"embedded_sentence3.191\" NUMERICAL mean:0.0226847 min:-0.0727223 max:0.0699259 sd:0.0549595\n",
            "\t1128: \"embedded_sentence3.192\" NUMERICAL mean:0.0284986 min:-0.0597023 max:0.0833996 sd:0.0311008\n",
            "\t1129: \"embedded_sentence3.193\" NUMERICAL mean:0.00330763 min:-0.0499883 max:0.0524854 sd:0.023017\n",
            "\t1130: \"embedded_sentence3.194\" NUMERICAL mean:0.00847756 min:-0.0686319 max:0.0591855 sd:0.0322627\n",
            "\t1131: \"embedded_sentence3.195\" NUMERICAL mean:-0.0202871 min:-0.0829148 max:0.0883023 sd:0.0706223\n",
            "\t1132: \"embedded_sentence3.196\" NUMERICAL mean:0.0195509 min:-0.0365376 max:0.0746344 sd:0.0233542\n",
            "\t1133: \"embedded_sentence3.197\" NUMERICAL mean:0.00705037 min:-0.0669943 max:0.083406 sd:0.0301766\n",
            "\t1134: \"embedded_sentence3.198\" NUMERICAL mean:0.0192281 min:-0.0847793 max:0.0667887 sd:0.0358892\n",
            "\t1135: \"embedded_sentence3.199\" NUMERICAL mean:-0.00181369 min:-0.0576565 max:0.0464154 sd:0.0191639\n",
            "\t1136: \"embedded_sentence3.2\" NUMERICAL mean:-0.0221147 min:-0.0807812 max:0.0700141 sd:0.0274286\n",
            "\t1137: \"embedded_sentence3.20\" NUMERICAL mean:0.0351464 min:-0.0493305 max:0.0699727 sd:0.0283757\n",
            "\t1138: \"embedded_sentence3.200\" NUMERICAL mean:-0.034219 min:-0.0785245 max:0.0758014 sd:0.053321\n",
            "\t1139: \"embedded_sentence3.201\" NUMERICAL mean:0.0333309 min:-0.0533552 max:0.075051 sd:0.0248268\n",
            "\t1140: \"embedded_sentence3.202\" NUMERICAL mean:0.0276824 min:-0.0814134 max:0.0759799 sd:0.0375298\n",
            "\t1141: \"embedded_sentence3.203\" NUMERICAL mean:0.0399088 min:-0.0616169 max:0.0664322 sd:0.0344062\n",
            "\t1142: \"embedded_sentence3.204\" NUMERICAL mean:-0.0153759 min:-0.0539062 max:0.0646714 sd:0.0248702\n",
            "\t1143: \"embedded_sentence3.205\" NUMERICAL mean:-0.0396761 min:-0.0834971 max:0.0726581 sd:0.0326516\n",
            "\t1144: \"embedded_sentence3.206\" NUMERICAL mean:-0.0438973 min:-0.072213 max:0.0743341 sd:0.0297372\n",
            "\t1145: \"embedded_sentence3.207\" NUMERICAL mean:-0.0248883 min:-0.0651867 max:0.0806152 sd:0.0403991\n",
            "\t1146: \"embedded_sentence3.208\" NUMERICAL mean:-0.0143935 min:-0.0739182 max:0.0757147 sd:0.0229141\n",
            "\t1147: \"embedded_sentence3.209\" NUMERICAL mean:0.0290436 min:-0.0714202 max:0.0707387 sd:0.0301824\n",
            "\t1148: \"embedded_sentence3.21\" NUMERICAL mean:0.0134709 min:-0.0848024 max:0.0656815 sd:0.0436725\n",
            "\t1149: \"embedded_sentence3.210\" NUMERICAL mean:0.0239822 min:-0.062679 max:0.0533975 sd:0.037079\n",
            "\t1150: \"embedded_sentence3.211\" NUMERICAL mean:0.0606371 min:-0.0554747 max:0.0889047 sd:0.0237351\n",
            "\t1151: \"embedded_sentence3.212\" NUMERICAL mean:-0.0544454 min:-0.0757237 max:0.0484361 sd:0.0239157\n",
            "\t1152: \"embedded_sentence3.213\" NUMERICAL mean:-0.0173528 min:-0.0698305 max:0.0599612 sd:0.026907\n",
            "\t1153: \"embedded_sentence3.214\" NUMERICAL mean:-0.0439425 min:-0.0725141 max:0.0448692 sd:0.0261214\n",
            "\t1154: \"embedded_sentence3.215\" NUMERICAL mean:0.0157196 min:-0.0810342 max:0.0535408 sd:0.0477764\n",
            "\t1155: \"embedded_sentence3.216\" NUMERICAL mean:-0.0196871 min:-0.0793497 max:0.0589212 sd:0.0315051\n",
            "\t1156: \"embedded_sentence3.217\" NUMERICAL mean:0.0183941 min:-0.0183913 max:0.0753053 sd:0.0304321\n",
            "\t1157: \"embedded_sentence3.218\" NUMERICAL mean:0.0218871 min:-0.0817642 max:0.0754042 sd:0.0382194\n",
            "\t1158: \"embedded_sentence3.219\" NUMERICAL mean:0.0202622 min:-0.0393778 max:0.0732065 sd:0.0223991\n",
            "\t1159: \"embedded_sentence3.22\" NUMERICAL mean:-0.00123391 min:-0.0502291 max:0.0700542 sd:0.0264937\n",
            "\t1160: \"embedded_sentence3.220\" NUMERICAL mean:-0.0273771 min:-0.0722781 max:0.0694817 sd:0.0393408\n",
            "\t1161: \"embedded_sentence3.221\" NUMERICAL mean:0.020361 min:-0.0733804 max:0.0502467 sd:0.0368775\n",
            "\t1162: \"embedded_sentence3.222\" NUMERICAL mean:-0.0344692 min:-0.0793791 max:0.0654964 sd:0.02817\n",
            "\t1163: \"embedded_sentence3.223\" NUMERICAL mean:0.00919343 min:-0.0597875 max:0.0764142 sd:0.0300413\n",
            "\t1164: \"embedded_sentence3.224\" NUMERICAL mean:-0.00361057 min:-0.0539077 max:0.0712737 sd:0.035425\n",
            "\t1165: \"embedded_sentence3.225\" NUMERICAL mean:0.0167151 min:-0.0628147 max:0.0720999 sd:0.0256293\n",
            "\t1166: \"embedded_sentence3.226\" NUMERICAL mean:-0.0375182 min:-0.0773832 max:0.0379057 sd:0.0274694\n",
            "\t1167: \"embedded_sentence3.227\" NUMERICAL mean:-0.019351 min:-0.059271 max:0.0761987 sd:0.0450563\n",
            "\t1168: \"embedded_sentence3.228\" NUMERICAL mean:-0.0358774 min:-0.0724022 max:0.0695178 sd:0.0428032\n",
            "\t1169: \"embedded_sentence3.229\" NUMERICAL mean:0.0135378 min:-0.0903206 max:0.0764235 sd:0.0336321\n",
            "\t1170: \"embedded_sentence3.23\" NUMERICAL mean:0.0339636 min:-0.0456813 max:0.0686008 sd:0.0354829\n",
            "\t1171: \"embedded_sentence3.230\" NUMERICAL mean:0.0492803 min:-0.0508044 max:0.0839686 sd:0.0415383\n",
            "\t1172: \"embedded_sentence3.231\" NUMERICAL mean:0.0174988 min:-0.0805428 max:0.0754018 sd:0.0285764\n",
            "\t1173: \"embedded_sentence3.232\" NUMERICAL mean:0.0115483 min:-0.066371 max:0.0550889 sd:0.0359859\n",
            "\t1174: \"embedded_sentence3.233\" NUMERICAL mean:0.0747906 min:-0.0461394 max:0.0948178 sd:0.0323415\n",
            "\t1175: \"embedded_sentence3.234\" NUMERICAL mean:0.041994 min:-0.0779422 max:0.083092 sd:0.0330163\n",
            "\t1176: \"embedded_sentence3.235\" NUMERICAL mean:-0.0371343 min:-0.078944 max:0.0763775 sd:0.0516278\n",
            "\t1177: \"embedded_sentence3.236\" NUMERICAL mean:-0.0388952 min:-0.0860296 max:0.0779623 sd:0.0544533\n",
            "\t1178: \"embedded_sentence3.237\" NUMERICAL mean:0.0142852 min:-0.0609779 max:0.0925614 sd:0.0368893\n",
            "\t1179: \"embedded_sentence3.238\" NUMERICAL mean:-0.0273435 min:-0.078869 max:0.0677988 sd:0.0568546\n",
            "\t1180: \"embedded_sentence3.239\" NUMERICAL mean:0.0110343 min:-0.0279532 max:0.0854982 sd:0.0441719\n",
            "\t1181: \"embedded_sentence3.24\" NUMERICAL mean:-0.0010965 min:-0.0693852 max:0.0538731 sd:0.0219336\n",
            "\t1182: \"embedded_sentence3.240\" NUMERICAL mean:0.0304845 min:-0.0639428 max:0.0680161 sd:0.044581\n",
            "\t1183: \"embedded_sentence3.241\" NUMERICAL mean:0.0497812 min:-0.0696916 max:0.0783738 sd:0.0333964\n",
            "\t1184: \"embedded_sentence3.242\" NUMERICAL mean:-0.00456311 min:-0.0776944 max:0.0786479 sd:0.0394618\n",
            "\t1185: \"embedded_sentence3.243\" NUMERICAL mean:-0.00836419 min:-0.0458145 max:0.0627574 sd:0.0202619\n",
            "\t1186: \"embedded_sentence3.244\" NUMERICAL mean:0.00458104 min:-0.0649713 max:0.0806382 sd:0.0329592\n",
            "\t1187: \"embedded_sentence3.245\" NUMERICAL mean:0.0280468 min:-0.0649589 max:0.0725017 sd:0.0221396\n",
            "\t1188: \"embedded_sentence3.246\" NUMERICAL mean:-0.0304902 min:-0.0738776 max:0.0534596 sd:0.0389021\n",
            "\t1189: \"embedded_sentence3.247\" NUMERICAL mean:-0.000119872 min:-0.0777208 max:0.0695604 sd:0.0373707\n",
            "\t1190: \"embedded_sentence3.248\" NUMERICAL mean:0.0175247 min:-0.0630875 max:0.0585657 sd:0.0249996\n",
            "\t1191: \"embedded_sentence3.249\" NUMERICAL mean:0.00992459 min:-0.0383168 max:0.0775697 sd:0.0304479\n",
            "\t1192: \"embedded_sentence3.25\" NUMERICAL mean:0.0207924 min:-0.0714 max:0.0534594 sd:0.0326142\n",
            "\t1193: \"embedded_sentence3.250\" NUMERICAL mean:-0.00613852 min:-0.0833055 max:0.0535818 sd:0.0429236\n",
            "\t1194: \"embedded_sentence3.251\" NUMERICAL mean:0.00315507 min:-0.0882207 max:0.0457049 sd:0.03888\n",
            "\t1195: \"embedded_sentence3.252\" NUMERICAL mean:-0.0257564 min:-0.0740106 max:0.0648934 sd:0.0554478\n",
            "\t1196: \"embedded_sentence3.253\" NUMERICAL mean:-0.0193553 min:-0.0629444 max:0.0702087 sd:0.0490608\n",
            "\t1197: \"embedded_sentence3.254\" NUMERICAL mean:0.0191748 min:-0.0723762 max:0.0610206 sd:0.0489138\n",
            "\t1198: \"embedded_sentence3.255\" NUMERICAL mean:0.00613896 min:-0.0608649 max:0.0715793 sd:0.0326582\n",
            "\t1199: \"embedded_sentence3.256\" NUMERICAL mean:-0.00624081 min:-0.0517719 max:0.0744928 sd:0.0284504\n",
            "\t1200: \"embedded_sentence3.257\" NUMERICAL mean:-0.00837886 min:-0.0847686 max:0.0619114 sd:0.035942\n",
            "\t1201: \"embedded_sentence3.258\" NUMERICAL mean:-0.0551917 min:-0.0815477 max:0.0474405 sd:0.0359104\n",
            "\t1202: \"embedded_sentence3.259\" NUMERICAL mean:0.0272057 min:-0.0640142 max:0.0778881 sd:0.0338174\n",
            "\t1203: \"embedded_sentence3.26\" NUMERICAL mean:-0.00378051 min:-0.0871416 max:0.0637236 sd:0.0356512\n",
            "\t1204: \"embedded_sentence3.260\" NUMERICAL mean:-0.0343596 min:-0.0643839 max:0.064328 sd:0.0251358\n",
            "\t1205: \"embedded_sentence3.261\" NUMERICAL mean:-0.0192307 min:-0.0523383 max:0.0439834 sd:0.0245533\n",
            "\t1206: \"embedded_sentence3.262\" NUMERICAL mean:-0.0254472 min:-0.0744443 max:0.090931 sd:0.0561754\n",
            "\t1207: \"embedded_sentence3.263\" NUMERICAL mean:-0.0243143 min:-0.0818968 max:0.0823072 sd:0.0530515\n",
            "\t1208: \"embedded_sentence3.264\" NUMERICAL mean:0.0214309 min:-0.0351288 max:0.0839579 sd:0.0278664\n",
            "\t1209: \"embedded_sentence3.265\" NUMERICAL mean:0.0365955 min:-0.0818223 max:0.0783304 sd:0.0260855\n",
            "\t1210: \"embedded_sentence3.266\" NUMERICAL mean:-0.017577 min:-0.0608062 max:0.0840696 sd:0.0392791\n",
            "\t1211: \"embedded_sentence3.267\" NUMERICAL mean:-0.0258786 min:-0.0729727 max:0.0795937 sd:0.0423104\n",
            "\t1212: \"embedded_sentence3.268\" NUMERICAL mean:0.0294736 min:-0.0835014 max:0.0799839 sd:0.0582844\n",
            "\t1213: \"embedded_sentence3.269\" NUMERICAL mean:0.0437309 min:-0.068094 max:0.0637285 sd:0.0289082\n",
            "\t1214: \"embedded_sentence3.27\" NUMERICAL mean:-0.0237812 min:-0.0666589 max:0.0628145 sd:0.0294708\n",
            "\t1215: \"embedded_sentence3.270\" NUMERICAL mean:0.00352983 min:-0.0475396 max:0.0810878 sd:0.0299262\n",
            "\t1216: \"embedded_sentence3.271\" NUMERICAL mean:0.00328336 min:-0.0729063 max:0.0480975 sd:0.0475718\n",
            "\t1217: \"embedded_sentence3.272\" NUMERICAL mean:0.00392013 min:-0.0823341 max:0.0794208 sd:0.0434059\n",
            "\t1218: \"embedded_sentence3.273\" NUMERICAL mean:-0.0114444 min:-0.0717802 max:0.07602 sd:0.0308752\n",
            "\t1219: \"embedded_sentence3.274\" NUMERICAL mean:0.0293553 min:-0.0769349 max:0.0763469 sd:0.0574111\n",
            "\t1220: \"embedded_sentence3.275\" NUMERICAL mean:-0.0249151 min:-0.0733043 max:0.065831 sd:0.0300466\n",
            "\t1221: \"embedded_sentence3.276\" NUMERICAL mean:-0.015952 min:-0.0757028 max:0.0650129 sd:0.0284256\n",
            "\t1222: \"embedded_sentence3.277\" NUMERICAL mean:-0.0163624 min:-0.0742992 max:0.0768475 sd:0.0634379\n",
            "\t1223: \"embedded_sentence3.278\" NUMERICAL mean:0.0440231 min:0.00512635 max:0.081827 sd:0.020597\n",
            "\t1224: \"embedded_sentence3.279\" NUMERICAL mean:0.0441516 min:-0.0695371 max:0.0832499 sd:0.0488016\n",
            "\t1225: \"embedded_sentence3.28\" NUMERICAL mean:-0.00246633 min:-0.0610001 max:0.0500092 sd:0.021442\n",
            "\t1226: \"embedded_sentence3.280\" NUMERICAL mean:-0.0427414 min:-0.079514 max:0.0600231 sd:0.0397472\n",
            "\t1227: \"embedded_sentence3.281\" NUMERICAL mean:-0.0124972 min:-0.0717496 max:0.0629869 sd:0.0304481\n",
            "\t1228: \"embedded_sentence3.282\" NUMERICAL mean:0.0228285 min:-0.074786 max:0.0765971 sd:0.0587992\n",
            "\t1229: \"embedded_sentence3.283\" NUMERICAL mean:0.0266248 min:-0.0767775 max:0.0668231 sd:0.049839\n",
            "\t1230: \"embedded_sentence3.284\" NUMERICAL mean:-0.00720037 min:-0.0528166 max:0.083088 sd:0.0518714\n",
            "\t1231: \"embedded_sentence3.285\" NUMERICAL mean:0.0281426 min:-0.0464557 max:0.0666324 sd:0.0282625\n",
            "\t1232: \"embedded_sentence3.286\" NUMERICAL mean:-0.00229395 min:-0.0390988 max:0.0834797 sd:0.030504\n",
            "\t1233: \"embedded_sentence3.287\" NUMERICAL mean:-0.00122742 min:-0.0336864 max:0.0782704 sd:0.035554\n",
            "\t1234: \"embedded_sentence3.288\" NUMERICAL mean:0.0125793 min:-0.0751754 max:0.083586 sd:0.0446487\n",
            "\t1235: \"embedded_sentence3.289\" NUMERICAL mean:0.018738 min:-0.0819872 max:0.0795857 sd:0.0556617\n",
            "\t1236: \"embedded_sentence3.29\" NUMERICAL mean:0.0212009 min:-0.0608365 max:0.0718681 sd:0.0268793\n",
            "\t1237: \"embedded_sentence3.290\" NUMERICAL mean:-0.000519406 min:-0.0817434 max:0.061617 sd:0.0372015\n",
            "\t1238: \"embedded_sentence3.291\" NUMERICAL mean:-0.0502819 min:-0.0765706 max:0.065006 sd:0.0303566\n",
            "\t1239: \"embedded_sentence3.292\" NUMERICAL mean:0.0128548 min:-0.033836 max:0.0810175 sd:0.0467514\n",
            "\t1240: \"embedded_sentence3.293\" NUMERICAL mean:-0.0359929 min:-0.0754431 max:0.0639815 sd:0.0386838\n",
            "\t1241: \"embedded_sentence3.294\" NUMERICAL mean:0.00512195 min:-0.0680818 max:0.0832412 sd:0.0372135\n",
            "\t1242: \"embedded_sentence3.295\" NUMERICAL mean:-0.00728858 min:-0.0828053 max:0.0622882 sd:0.0223715\n",
            "\t1243: \"embedded_sentence3.296\" NUMERICAL mean:0.00293435 min:-0.0828574 max:0.0483144 sd:0.049766\n",
            "\t1244: \"embedded_sentence3.297\" NUMERICAL mean:0.00544075 min:-0.0818197 max:0.0643707 sd:0.0279928\n",
            "\t1245: \"embedded_sentence3.298\" NUMERICAL mean:0.0503216 min:-0.0815602 max:0.0796342 sd:0.0415271\n",
            "\t1246: \"embedded_sentence3.299\" NUMERICAL mean:-0.0175529 min:-0.058085 max:0.0747041 sd:0.0476961\n",
            "\t1247: \"embedded_sentence3.3\" NUMERICAL mean:-0.0267951 min:-0.065528 max:0.0634242 sd:0.0446596\n",
            "\t1248: \"embedded_sentence3.30\" NUMERICAL mean:-0.000676637 min:-0.0855154 max:0.0741753 sd:0.04519\n",
            "\t1249: \"embedded_sentence3.300\" NUMERICAL mean:-0.0186867 min:-0.0476555 max:0.0684674 sd:0.0369324\n",
            "\t1250: \"embedded_sentence3.301\" NUMERICAL mean:-0.0129498 min:-0.058127 max:0.0777458 sd:0.0398572\n",
            "\t1251: \"embedded_sentence3.302\" NUMERICAL mean:-0.00334572 min:-0.0594794 max:0.0749643 sd:0.0310068\n",
            "\t1252: \"embedded_sentence3.303\" NUMERICAL mean:0.00263261 min:-0.0789505 max:0.0401236 sd:0.0306487\n",
            "\t1253: \"embedded_sentence3.304\" NUMERICAL mean:-0.0262645 min:-0.0776698 max:0.0710525 sd:0.0320648\n",
            "\t1254: \"embedded_sentence3.305\" NUMERICAL mean:0.0106602 min:-0.0573874 max:0.0669379 sd:0.0249267\n",
            "\t1255: \"embedded_sentence3.306\" NUMERICAL mean:-0.00659433 min:-0.0691625 max:0.0794562 sd:0.0360812\n",
            "\t1256: \"embedded_sentence3.307\" NUMERICAL mean:-0.0131102 min:-0.0504185 max:0.0766909 sd:0.045448\n",
            "\t1257: \"embedded_sentence3.308\" NUMERICAL mean:0.0088663 min:-0.0761387 max:0.0639608 sd:0.0553947\n",
            "\t1258: \"embedded_sentence3.309\" NUMERICAL mean:-0.0189028 min:-0.074634 max:0.0817927 sd:0.0311258\n",
            "\t1259: \"embedded_sentence3.31\" NUMERICAL mean:0.0121742 min:-0.0543235 max:0.0758441 sd:0.0258043\n",
            "\t1260: \"embedded_sentence3.310\" NUMERICAL mean:0.013319 min:-0.0822606 max:0.0825022 sd:0.02974\n",
            "\t1261: \"embedded_sentence3.311\" NUMERICAL mean:0.0125121 min:-0.0530338 max:0.0560592 sd:0.0246151\n",
            "\t1262: \"embedded_sentence3.312\" NUMERICAL mean:0.0536967 min:-0.0578194 max:0.0850648 sd:0.0364389\n",
            "\t1263: \"embedded_sentence3.313\" NUMERICAL mean:0.0257513 min:-0.0879201 max:0.0831682 sd:0.033486\n",
            "\t1264: \"embedded_sentence3.314\" NUMERICAL mean:0.0264064 min:-0.0378706 max:0.0797568 sd:0.0258732\n",
            "\t1265: \"embedded_sentence3.315\" NUMERICAL mean:0.0141257 min:-0.0611595 max:0.081375 sd:0.0297029\n",
            "\t1266: \"embedded_sentence3.316\" NUMERICAL mean:0.00531093 min:-0.0754306 max:0.0803999 sd:0.0318586\n",
            "\t1267: \"embedded_sentence3.317\" NUMERICAL mean:0.000895698 min:-0.0390153 max:0.0726409 sd:0.0312738\n",
            "\t1268: \"embedded_sentence3.318\" NUMERICAL mean:-0.0256483 min:-0.0791531 max:0.0541358 sd:0.0234083\n",
            "\t1269: \"embedded_sentence3.319\" NUMERICAL mean:0.0296551 min:-0.0576551 max:0.0803788 sd:0.0396501\n",
            "\t1270: \"embedded_sentence3.32\" NUMERICAL mean:-0.0131201 min:-0.0725484 max:0.0781759 sd:0.0457273\n",
            "\t1271: \"embedded_sentence3.320\" NUMERICAL mean:0.00091299 min:-0.0777396 max:0.0797 sd:0.0311438\n",
            "\t1272: \"embedded_sentence3.321\" NUMERICAL mean:-0.0312017 min:-0.0696876 max:0.0716347 sd:0.0378926\n",
            "\t1273: \"embedded_sentence3.322\" NUMERICAL mean:0.00663401 min:-0.073386 max:0.0421851 sd:0.0419083\n",
            "\t1274: \"embedded_sentence3.323\" NUMERICAL mean:0.00806532 min:-0.0729968 max:0.0865289 sd:0.0403672\n",
            "\t1275: \"embedded_sentence3.324\" NUMERICAL mean:-0.0358044 min:-0.07726 max:0.0501329 sd:0.020901\n",
            "\t1276: \"embedded_sentence3.325\" NUMERICAL mean:0.0102836 min:-0.0875196 max:0.0800527 sd:0.0394066\n",
            "\t1277: \"embedded_sentence3.326\" NUMERICAL mean:0.00441837 min:-0.0584296 max:0.0651143 sd:0.0270001\n",
            "\t1278: \"embedded_sentence3.327\" NUMERICAL mean:0.0144084 min:-0.0597969 max:0.0605298 sd:0.0289088\n",
            "\t1279: \"embedded_sentence3.328\" NUMERICAL mean:-0.00396377 min:-0.0912402 max:0.0688335 sd:0.0370055\n",
            "\t1280: \"embedded_sentence3.329\" NUMERICAL mean:-0.00119773 min:-0.0611821 max:0.0774505 sd:0.0262882\n",
            "\t1281: \"embedded_sentence3.33\" NUMERICAL mean:-0.0177105 min:-0.0727631 max:0.0751384 sd:0.0457968\n",
            "\t1282: \"embedded_sentence3.330\" NUMERICAL mean:0.0252862 min:-0.05055 max:0.0747649 sd:0.0232847\n",
            "\t1283: \"embedded_sentence3.331\" NUMERICAL mean:0.0233605 min:-0.0689163 max:0.0764183 sd:0.0309358\n",
            "\t1284: \"embedded_sentence3.332\" NUMERICAL mean:0.0338066 min:-0.0783006 max:0.075682 sd:0.0516894\n",
            "\t1285: \"embedded_sentence3.333\" NUMERICAL mean:0.0642642 min:-0.0406998 max:0.0851896 sd:0.0209212\n",
            "\t1286: \"embedded_sentence3.334\" NUMERICAL mean:-0.0204893 min:-0.074411 max:0.0579942 sd:0.0298265\n",
            "\t1287: \"embedded_sentence3.335\" NUMERICAL mean:-0.0170079 min:-0.0529485 max:0.0772589 sd:0.0429778\n",
            "\t1288: \"embedded_sentence3.336\" NUMERICAL mean:0.0410038 min:-0.074601 max:0.0727793 sd:0.0305623\n",
            "\t1289: \"embedded_sentence3.337\" NUMERICAL mean:0.00267491 min:-0.0727389 max:0.080841 sd:0.0318331\n",
            "\t1290: \"embedded_sentence3.338\" NUMERICAL mean:-0.0141874 min:-0.0704849 max:0.0769953 sd:0.0379732\n",
            "\t1291: \"embedded_sentence3.339\" NUMERICAL mean:0.0219918 min:-0.0648219 max:0.07537 sd:0.0414875\n",
            "\t1292: \"embedded_sentence3.34\" NUMERICAL mean:-0.00374699 min:-0.0726754 max:0.0596102 sd:0.0284427\n",
            "\t1293: \"embedded_sentence3.340\" NUMERICAL mean:0.00989805 min:-0.0777207 max:0.06968 sd:0.0489939\n",
            "\t1294: \"embedded_sentence3.341\" NUMERICAL mean:-0.019911 min:-0.0647977 max:0.0649467 sd:0.0301724\n",
            "\t1295: \"embedded_sentence3.342\" NUMERICAL mean:0.033484 min:-0.0734037 max:0.0673328 sd:0.0379028\n",
            "\t1296: \"embedded_sentence3.343\" NUMERICAL mean:0.01276 min:-0.0608011 max:0.0450346 sd:0.0383139\n",
            "\t1297: \"embedded_sentence3.344\" NUMERICAL mean:-0.0268363 min:-0.0843014 max:0.046307 sd:0.0271497\n",
            "\t1298: \"embedded_sentence3.345\" NUMERICAL mean:0.00504472 min:-0.0748367 max:0.068814 sd:0.022947\n",
            "\t1299: \"embedded_sentence3.346\" NUMERICAL mean:0.0261939 min:-0.0443772 max:0.06869 sd:0.0248082\n",
            "\t1300: \"embedded_sentence3.347\" NUMERICAL mean:-0.0136098 min:-0.0758984 max:0.0566246 sd:0.0274851\n",
            "\t1301: \"embedded_sentence3.348\" NUMERICAL mean:0.00636427 min:-0.080464 max:0.0646156 sd:0.0431775\n",
            "\t1302: \"embedded_sentence3.349\" NUMERICAL mean:0.0080221 min:-0.0633454 max:0.0665805 sd:0.0253547\n",
            "\t1303: \"embedded_sentence3.35\" NUMERICAL mean:-0.0115067 min:-0.0674534 max:0.0798225 sd:0.037081\n",
            "\t1304: \"embedded_sentence3.350\" NUMERICAL mean:0.00012194 min:-0.0397716 max:0.0656043 sd:0.0310496\n",
            "\t1305: \"embedded_sentence3.351\" NUMERICAL mean:0.00320894 min:-0.0816412 max:0.0709854 sd:0.0336491\n",
            "\t1306: \"embedded_sentence3.352\" NUMERICAL mean:-0.00865276 min:-0.0567527 max:0.0742469 sd:0.0269127\n",
            "\t1307: \"embedded_sentence3.353\" NUMERICAL mean:0.0312533 min:-0.0806303 max:0.0750333 sd:0.0372041\n",
            "\t1308: \"embedded_sentence3.354\" NUMERICAL mean:-0.0199242 min:-0.0879273 max:0.05196 sd:0.033601\n",
            "\t1309: \"embedded_sentence3.355\" NUMERICAL mean:-0.0281304 min:-0.094516 max:0.0210155 sd:0.0515628\n",
            "\t1310: \"embedded_sentence3.356\" NUMERICAL mean:-0.081025 min:-0.084249 max:-0.0589936 sd:0.00410217\n",
            "\t1311: \"embedded_sentence3.357\" NUMERICAL mean:-0.00165307 min:-0.0796921 max:0.0735849 sd:0.0409373\n",
            "\t1312: \"embedded_sentence3.358\" NUMERICAL mean:0.0066532 min:-0.08176 max:0.0863906 sd:0.0437566\n",
            "\t1313: \"embedded_sentence3.359\" NUMERICAL mean:-0.00218897 min:-0.0668072 max:0.068214 sd:0.033164\n",
            "\t1314: \"embedded_sentence3.36\" NUMERICAL mean:0.00212496 min:-0.0911435 max:0.0747162 sd:0.0422662\n",
            "\t1315: \"embedded_sentence3.360\" NUMERICAL mean:0.0385552 min:-0.0740877 max:0.0829915 sd:0.0532575\n",
            "\t1316: \"embedded_sentence3.361\" NUMERICAL mean:-0.0463989 min:-0.0725975 max:0.0574085 sd:0.032902\n",
            "\t1317: \"embedded_sentence3.362\" NUMERICAL mean:0.0414069 min:-0.0515753 max:0.0780635 sd:0.0294425\n",
            "\t1318: \"embedded_sentence3.363\" NUMERICAL mean:6.84486e-05 min:-0.0641558 max:0.0701658 sd:0.0280773\n",
            "\t1319: \"embedded_sentence3.364\" NUMERICAL mean:0.0375601 min:-0.0800057 max:0.0713666 sd:0.0210925\n",
            "\t1320: \"embedded_sentence3.365\" NUMERICAL mean:-0.0101835 min:-0.0826946 max:0.0763638 sd:0.0330594\n",
            "\t1321: \"embedded_sentence3.366\" NUMERICAL mean:0.0446599 min:0.0084391 max:0.076907 sd:0.0126227\n",
            "\t1322: \"embedded_sentence3.367\" NUMERICAL mean:0.0049178 min:-0.0714383 max:0.0525292 sd:0.0283488\n",
            "\t1323: \"embedded_sentence3.368\" NUMERICAL mean:0.00452245 min:-0.078244 max:0.06541 sd:0.0516676\n",
            "\t1324: \"embedded_sentence3.369\" NUMERICAL mean:0.00549381 min:-0.0767869 max:0.0658507 sd:0.0271628\n",
            "\t1325: \"embedded_sentence3.37\" NUMERICAL mean:0.00922428 min:-0.0738279 max:0.078445 sd:0.0264688\n",
            "\t1326: \"embedded_sentence3.370\" NUMERICAL mean:-0.00567741 min:-0.0741829 max:0.0798559 sd:0.0287798\n",
            "\t1327: \"embedded_sentence3.371\" NUMERICAL mean:-0.0254579 min:-0.0692861 max:0.0757317 sd:0.0345058\n",
            "\t1328: \"embedded_sentence3.372\" NUMERICAL mean:0.0290731 min:-0.0397327 max:0.0804082 sd:0.0227506\n",
            "\t1329: \"embedded_sentence3.373\" NUMERICAL mean:-0.0303096 min:-0.0841554 max:0.0453341 sd:0.0304278\n",
            "\t1330: \"embedded_sentence3.374\" NUMERICAL mean:-0.0127623 min:-0.0770707 max:0.0771449 sd:0.0321668\n",
            "\t1331: \"embedded_sentence3.375\" NUMERICAL mean:-0.0456536 min:-0.0669434 max:0.048758 sd:0.0307051\n",
            "\t1332: \"embedded_sentence3.376\" NUMERICAL mean:0.0268137 min:-0.0717367 max:0.0613598 sd:0.0378308\n",
            "\t1333: \"embedded_sentence3.377\" NUMERICAL mean:0.0187253 min:-0.0761617 max:0.0580669 sd:0.0339336\n",
            "\t1334: \"embedded_sentence3.378\" NUMERICAL mean:-0.041648 min:-0.0694384 max:0.0623249 sd:0.0355843\n",
            "\t1335: \"embedded_sentence3.379\" NUMERICAL mean:-0.0293963 min:-0.0795726 max:0.0696508 sd:0.0347841\n",
            "\t1336: \"embedded_sentence3.38\" NUMERICAL mean:-0.0166738 min:-0.0701049 max:0.0717841 sd:0.0267391\n",
            "\t1337: \"embedded_sentence3.380\" NUMERICAL mean:-0.0145959 min:-0.0680231 max:0.049943 sd:0.0236649\n",
            "\t1338: \"embedded_sentence3.381\" NUMERICAL mean:0.0344352 min:-0.0641293 max:0.0828976 sd:0.0387329\n",
            "\t1339: \"embedded_sentence3.382\" NUMERICAL mean:0.00202954 min:-0.0462064 max:0.0577042 sd:0.0226239\n",
            "\t1340: \"embedded_sentence3.383\" NUMERICAL mean:0.0199292 min:-0.0715566 max:0.0663872 sd:0.0420674\n",
            "\t1341: \"embedded_sentence3.384\" NUMERICAL mean:0.0598181 min:-0.0506767 max:0.0949161 sd:0.0429465\n",
            "\t1342: \"embedded_sentence3.385\" NUMERICAL mean:-0.0300033 min:-0.077858 max:0.0601727 sd:0.0260078\n",
            "\t1343: \"embedded_sentence3.386\" NUMERICAL mean:-0.0135098 min:-0.0518875 max:0.0747062 sd:0.042014\n",
            "\t1344: \"embedded_sentence3.387\" NUMERICAL mean:0.0125809 min:-0.0820892 max:0.0719834 sd:0.0435592\n",
            "\t1345: \"embedded_sentence3.388\" NUMERICAL mean:-0.0132467 min:-0.0528269 max:0.0815705 sd:0.0368892\n",
            "\t1346: \"embedded_sentence3.389\" NUMERICAL mean:0.0292543 min:-0.0758855 max:0.0774961 sd:0.0547244\n",
            "\t1347: \"embedded_sentence3.39\" NUMERICAL mean:0.0103468 min:-0.0726907 max:0.0736936 sd:0.0275515\n",
            "\t1348: \"embedded_sentence3.390\" NUMERICAL mean:-0.0151593 min:-0.05138 max:0.0617805 sd:0.030079\n",
            "\t1349: \"embedded_sentence3.391\" NUMERICAL mean:-0.00173473 min:-0.0698626 max:0.0640947 sd:0.0260107\n",
            "\t1350: \"embedded_sentence3.392\" NUMERICAL mean:0.0313402 min:-0.0648027 max:0.0801807 sd:0.0367685\n",
            "\t1351: \"embedded_sentence3.393\" NUMERICAL mean:-0.025676 min:-0.0682552 max:0.0749345 sd:0.0391012\n",
            "\t1352: \"embedded_sentence3.394\" NUMERICAL mean:-0.0405607 min:-0.0761477 max:0.058964 sd:0.0464863\n",
            "\t1353: \"embedded_sentence3.395\" NUMERICAL mean:-0.00543442 min:-0.0495448 max:0.075774 sd:0.0485869\n",
            "\t1354: \"embedded_sentence3.396\" NUMERICAL mean:-0.0396088 min:-0.0850881 max:0.0586056 sd:0.0508791\n",
            "\t1355: \"embedded_sentence3.397\" NUMERICAL mean:0.0260641 min:-0.0761617 max:0.0760567 sd:0.0391382\n",
            "\t1356: \"embedded_sentence3.398\" NUMERICAL mean:0.00398629 min:-0.081803 max:0.0523383 sd:0.0540824\n",
            "\t1357: \"embedded_sentence3.399\" NUMERICAL mean:-0.0239174 min:-0.0578532 max:0.0578315 sd:0.0409811\n",
            "\t1358: \"embedded_sentence3.4\" NUMERICAL mean:0.00206555 min:-0.0826688 max:0.0403452 sd:0.0450239\n",
            "\t1359: \"embedded_sentence3.40\" NUMERICAL mean:-0.0008596 min:-0.0720918 max:0.080063 sd:0.0307519\n",
            "\t1360: \"embedded_sentence3.400\" NUMERICAL mean:-0.0156939 min:-0.0596512 max:0.0796448 sd:0.0497517\n",
            "\t1361: \"embedded_sentence3.401\" NUMERICAL mean:0.00948606 min:-0.0544883 max:0.0780741 sd:0.0377282\n",
            "\t1362: \"embedded_sentence3.402\" NUMERICAL mean:-0.0285845 min:-0.0707655 max:0.0662561 sd:0.0289637\n",
            "\t1363: \"embedded_sentence3.403\" NUMERICAL mean:0.0228287 min:-0.0383452 max:0.0806306 sd:0.0235348\n",
            "\t1364: \"embedded_sentence3.404\" NUMERICAL mean:0.037734 min:-0.0635051 max:0.0732546 sd:0.0320599\n",
            "\t1365: \"embedded_sentence3.405\" NUMERICAL mean:-0.0340684 min:-0.0759028 max:0.0718433 sd:0.036495\n",
            "\t1366: \"embedded_sentence3.406\" NUMERICAL mean:0.0148228 min:-0.0714188 max:0.0578314 sd:0.0244124\n",
            "\t1367: \"embedded_sentence3.407\" NUMERICAL mean:0.00510513 min:-0.0808604 max:0.0781514 sd:0.0444891\n",
            "\t1368: \"embedded_sentence3.408\" NUMERICAL mean:-0.00337142 min:-0.0651129 max:0.0563856 sd:0.0216007\n",
            "\t1369: \"embedded_sentence3.409\" NUMERICAL mean:-0.000703928 min:-0.0808093 max:0.0483754 sd:0.0527142\n",
            "\t1370: \"embedded_sentence3.41\" NUMERICAL mean:-0.00406031 min:-0.0683108 max:0.0704179 sd:0.0264015\n",
            "\t1371: \"embedded_sentence3.410\" NUMERICAL mean:-0.0381394 min:-0.0722293 max:0.0616376 sd:0.0401942\n",
            "\t1372: \"embedded_sentence3.411\" NUMERICAL mean:0.00792604 min:-0.0693642 max:0.0742184 sd:0.0291518\n",
            "\t1373: \"embedded_sentence3.412\" NUMERICAL mean:-0.0148876 min:-0.0493615 max:0.0627851 sd:0.0357348\n",
            "\t1374: \"embedded_sentence3.413\" NUMERICAL mean:-0.0400644 min:-0.0743211 max:0.0680783 sd:0.0365067\n",
            "\t1375: \"embedded_sentence3.414\" NUMERICAL mean:-0.0347592 min:-0.0719135 max:0.0470901 sd:0.03385\n",
            "\t1376: \"embedded_sentence3.415\" NUMERICAL mean:-0.0111772 min:-0.0817721 max:0.0643047 sd:0.047816\n",
            "\t1377: \"embedded_sentence3.416\" NUMERICAL mean:-0.0127944 min:-0.0516992 max:0.0638625 sd:0.03954\n",
            "\t1378: \"embedded_sentence3.417\" NUMERICAL mean:-0.0156748 min:-0.076132 max:0.0255063 sd:0.0320918\n",
            "\t1379: \"embedded_sentence3.418\" NUMERICAL mean:-0.0268228 min:-0.0792178 max:0.0708678 sd:0.0283613\n",
            "\t1380: \"embedded_sentence3.419\" NUMERICAL mean:-0.0242841 min:-0.0797443 max:0.0856896 sd:0.0632671\n",
            "\t1381: \"embedded_sentence3.42\" NUMERICAL mean:-0.0324141 min:-0.0686529 max:0.0612223 sd:0.0306569\n",
            "\t1382: \"embedded_sentence3.420\" NUMERICAL mean:0.0288436 min:-0.0699311 max:0.0801241 sd:0.0252645\n",
            "\t1383: \"embedded_sentence3.421\" NUMERICAL mean:0.0126917 min:-0.0873796 max:0.0707328 sd:0.0645953\n",
            "\t1384: \"embedded_sentence3.422\" NUMERICAL mean:-0.00363387 min:-0.0720619 max:0.0457224 sd:0.0248303\n",
            "\t1385: \"embedded_sentence3.423\" NUMERICAL mean:0.0352425 min:-0.0699106 max:0.0789243 sd:0.0522873\n",
            "\t1386: \"embedded_sentence3.424\" NUMERICAL mean:-0.00132893 min:-0.0431753 max:0.0743023 sd:0.0468886\n",
            "\t1387: \"embedded_sentence3.425\" NUMERICAL mean:-0.0239817 min:-0.0600141 max:0.0752179 sd:0.0433192\n",
            "\t1388: \"embedded_sentence3.426\" NUMERICAL mean:0.0134084 min:-0.0627518 max:0.0846686 sd:0.0302113\n",
            "\t1389: \"embedded_sentence3.427\" NUMERICAL mean:-0.00884439 min:-0.0644706 max:0.069764 sd:0.0284018\n",
            "\t1390: \"embedded_sentence3.428\" NUMERICAL mean:0.0327105 min:-0.0768751 max:0.0769983 sd:0.0299266\n",
            "\t1391: \"embedded_sentence3.429\" NUMERICAL mean:-0.0180219 min:-0.0844733 max:0.039158 sd:0.0348011\n",
            "\t1392: \"embedded_sentence3.43\" NUMERICAL mean:0.00262012 min:-0.0837717 max:0.059075 sd:0.0597488\n",
            "\t1393: \"embedded_sentence3.430\" NUMERICAL mean:0.00501415 min:-0.0793298 max:0.044145 sd:0.0448307\n",
            "\t1394: \"embedded_sentence3.431\" NUMERICAL mean:0.00136463 min:-0.0815358 max:0.0584127 sd:0.0362573\n",
            "\t1395: \"embedded_sentence3.432\" NUMERICAL mean:-8.47415e-05 min:-0.0663329 max:0.0783128 sd:0.0278472\n",
            "\t1396: \"embedded_sentence3.433\" NUMERICAL mean:-0.0323153 min:-0.0723287 max:0.0757583 sd:0.0281266\n",
            "\t1397: \"embedded_sentence3.434\" NUMERICAL mean:0.0426119 min:-0.0545291 max:0.0886348 sd:0.0304601\n",
            "\t1398: \"embedded_sentence3.435\" NUMERICAL mean:-0.0150762 min:-0.0704942 max:0.0230824 sd:0.0195766\n",
            "\t1399: \"embedded_sentence3.436\" NUMERICAL mean:-0.00690701 min:-0.0646634 max:0.0831111 sd:0.024437\n",
            "\t1400: \"embedded_sentence3.437\" NUMERICAL mean:-0.0353944 min:-0.0742889 max:0.0526147 sd:0.04541\n",
            "\t1401: \"embedded_sentence3.438\" NUMERICAL mean:-0.024804 min:-0.0672012 max:0.0591051 sd:0.0355301\n",
            "\t1402: \"embedded_sentence3.439\" NUMERICAL mean:-0.020342 min:-0.0779142 max:0.0757193 sd:0.0304129\n",
            "\t1403: \"embedded_sentence3.44\" NUMERICAL mean:0.014089 min:-0.0546712 max:0.0827941 sd:0.0338196\n",
            "\t1404: \"embedded_sentence3.440\" NUMERICAL mean:0.0163722 min:-0.0811553 max:0.0814073 sd:0.0383734\n",
            "\t1405: \"embedded_sentence3.441\" NUMERICAL mean:-0.0173354 min:-0.0677488 max:0.0768737 sd:0.0259453\n",
            "\t1406: \"embedded_sentence3.442\" NUMERICAL mean:0.0187118 min:-0.0771036 max:0.0687385 sd:0.0577693\n",
            "\t1407: \"embedded_sentence3.443\" NUMERICAL mean:0.0511456 min:-0.0408612 max:0.0720842 sd:0.0284516\n",
            "\t1408: \"embedded_sentence3.444\" NUMERICAL mean:-0.0268178 min:-0.0749946 max:0.0699958 sd:0.0294838\n",
            "\t1409: \"embedded_sentence3.445\" NUMERICAL mean:-0.00503713 min:-0.0760115 max:0.0777108 sd:0.048533\n",
            "\t1410: \"embedded_sentence3.446\" NUMERICAL mean:0.00343806 min:-0.0541832 max:0.0589042 sd:0.0224433\n",
            "\t1411: \"embedded_sentence3.447\" NUMERICAL mean:-0.0191286 min:-0.0806191 max:0.0558901 sd:0.0294432\n",
            "\t1412: \"embedded_sentence3.448\" NUMERICAL mean:0.00403197 min:-0.0636361 max:0.0637883 sd:0.0320362\n",
            "\t1413: \"embedded_sentence3.449\" NUMERICAL mean:-0.0129377 min:-0.0624336 max:0.0758334 sd:0.0403545\n",
            "\t1414: \"embedded_sentence3.45\" NUMERICAL mean:-0.00137705 min:-0.0770489 max:0.070751 sd:0.0412536\n",
            "\t1415: \"embedded_sentence3.450\" NUMERICAL mean:-0.0358686 min:-0.0755819 max:0.0613809 sd:0.0314439\n",
            "\t1416: \"embedded_sentence3.451\" NUMERICAL mean:-0.0239853 min:-0.0756135 max:0.058448 sd:0.0268117\n",
            "\t1417: \"embedded_sentence3.452\" NUMERICAL mean:0.0515197 min:-0.0442759 max:0.0806944 sd:0.0292268\n",
            "\t1418: \"embedded_sentence3.453\" NUMERICAL mean:0.0327618 min:-0.0619651 max:0.0694714 sd:0.0326028\n",
            "\t1419: \"embedded_sentence3.454\" NUMERICAL mean:0.0155331 min:-0.0797459 max:0.054784 sd:0.0324114\n",
            "\t1420: \"embedded_sentence3.455\" NUMERICAL mean:0.0443304 min:-0.0752843 max:0.0815135 sd:0.0309931\n",
            "\t1421: \"embedded_sentence3.456\" NUMERICAL mean:-0.0153134 min:-0.0595525 max:0.073895 sd:0.0499845\n",
            "\t1422: \"embedded_sentence3.457\" NUMERICAL mean:0.0024196 min:-0.08356 max:0.0668872 sd:0.0311768\n",
            "\t1423: \"embedded_sentence3.458\" NUMERICAL mean:-0.0334719 min:-0.0714094 max:0.0587174 sd:0.0373209\n",
            "\t1424: \"embedded_sentence3.459\" NUMERICAL mean:0.0621733 min:-0.0160645 max:0.0821247 sd:0.0262993\n",
            "\t1425: \"embedded_sentence3.46\" NUMERICAL mean:-0.0253278 min:-0.0540595 max:0.0506691 sd:0.0342618\n",
            "\t1426: \"embedded_sentence3.460\" NUMERICAL mean:-0.00181624 min:-0.081918 max:0.0895956 sd:0.0385355\n",
            "\t1427: \"embedded_sentence3.461\" NUMERICAL mean:0.0178514 min:-0.0288261 max:0.0727443 sd:0.0241763\n",
            "\t1428: \"embedded_sentence3.462\" NUMERICAL mean:0.0021312 min:-0.0600458 max:0.0840722 sd:0.0345444\n",
            "\t1429: \"embedded_sentence3.463\" NUMERICAL mean:-0.00910123 min:-0.0844688 max:0.0599229 sd:0.0314566\n",
            "\t1430: \"embedded_sentence3.464\" NUMERICAL mean:-0.00380528 min:-0.0718366 max:0.0608782 sd:0.0324143\n",
            "\t1431: \"embedded_sentence3.465\" NUMERICAL mean:-0.00697235 min:-0.0490612 max:0.0672978 sd:0.0360386\n",
            "\t1432: \"embedded_sentence3.466\" NUMERICAL mean:-0.012031 min:-0.0653739 max:0.0681739 sd:0.025723\n",
            "\t1433: \"embedded_sentence3.467\" NUMERICAL mean:0.00887091 min:-0.0388693 max:0.0824449 sd:0.0463588\n",
            "\t1434: \"embedded_sentence3.468\" NUMERICAL mean:0.0145499 min:-0.0673874 max:0.0709801 sd:0.024159\n",
            "\t1435: \"embedded_sentence3.469\" NUMERICAL mean:0.00157169 min:-0.0437122 max:0.0810632 sd:0.050903\n",
            "\t1436: \"embedded_sentence3.47\" NUMERICAL mean:0.0215696 min:-0.0632095 max:0.0734337 sd:0.026172\n",
            "\t1437: \"embedded_sentence3.470\" NUMERICAL mean:-0.0266299 min:-0.0616887 max:0.0672798 sd:0.0438468\n",
            "\t1438: \"embedded_sentence3.471\" NUMERICAL mean:-0.00746228 min:-0.0640092 max:0.0773541 sd:0.0375567\n",
            "\t1439: \"embedded_sentence3.472\" NUMERICAL mean:-0.0134837 min:-0.0697954 max:0.0815652 sd:0.0299986\n",
            "\t1440: \"embedded_sentence3.473\" NUMERICAL mean:-0.0010685 min:-0.0602376 max:0.0732314 sd:0.0322638\n",
            "\t1441: \"embedded_sentence3.474\" NUMERICAL mean:0.0127099 min:-0.0679038 max:0.0601144 sd:0.0514675\n",
            "\t1442: \"embedded_sentence3.475\" NUMERICAL mean:0.016557 min:-0.0633075 max:0.0841647 sd:0.0258649\n",
            "\t1443: \"embedded_sentence3.476\" NUMERICAL mean:-0.0485903 min:-0.0820514 max:0.0665312 sd:0.0436086\n",
            "\t1444: \"embedded_sentence3.477\" NUMERICAL mean:0.0186344 min:-0.0367964 max:0.0832224 sd:0.0243177\n",
            "\t1445: \"embedded_sentence3.478\" NUMERICAL mean:0.00708393 min:-0.0559775 max:0.0875913 sd:0.0327138\n",
            "\t1446: \"embedded_sentence3.479\" NUMERICAL mean:0.0572974 min:-0.0802863 max:0.088622 sd:0.0204402\n",
            "\t1447: \"embedded_sentence3.48\" NUMERICAL mean:-0.000571502 min:-0.0731084 max:0.0788422 sd:0.0278903\n",
            "\t1448: \"embedded_sentence3.480\" NUMERICAL mean:0.022834 min:-0.0684606 max:0.0780347 sd:0.0273385\n",
            "\t1449: \"embedded_sentence3.481\" NUMERICAL mean:-0.0179173 min:-0.0723426 max:0.0791076 sd:0.0612443\n",
            "\t1450: \"embedded_sentence3.482\" NUMERICAL mean:-0.00557771 min:-0.0849784 max:0.0527851 sd:0.0328728\n",
            "\t1451: \"embedded_sentence3.483\" NUMERICAL mean:-0.00197955 min:-0.0780524 max:0.0347647 sd:0.0383879\n",
            "\t1452: \"embedded_sentence3.484\" NUMERICAL mean:-0.0124724 min:-0.0706963 max:0.0745169 sd:0.0499825\n",
            "\t1453: \"embedded_sentence3.485\" NUMERICAL mean:-0.0339399 min:-0.0813488 max:0.0760566 sd:0.0550254\n",
            "\t1454: \"embedded_sentence3.486\" NUMERICAL mean:-0.00422475 min:-0.0455864 max:0.0858435 sd:0.045805\n",
            "\t1455: \"embedded_sentence3.487\" NUMERICAL mean:-0.00533193 min:-0.0684192 max:0.0553062 sd:0.0223465\n",
            "\t1456: \"embedded_sentence3.488\" NUMERICAL mean:0.0405063 min:-0.0746033 max:0.0793795 sd:0.0471998\n",
            "\t1457: \"embedded_sentence3.489\" NUMERICAL mean:0.0215706 min:-0.0803984 max:0.0860969 sd:0.0393213\n",
            "\t1458: \"embedded_sentence3.49\" NUMERICAL mean:0.0013341 min:-0.0572415 max:0.0663072 sd:0.0239046\n",
            "\t1459: \"embedded_sentence3.490\" NUMERICAL mean:-0.00321704 min:-0.0871797 max:0.0528668 sd:0.0310497\n",
            "\t1460: \"embedded_sentence3.491\" NUMERICAL mean:-0.0329892 min:-0.0698845 max:0.0571247 sd:0.030707\n",
            "\t1461: \"embedded_sentence3.492\" NUMERICAL mean:-0.0400395 min:-0.08148 max:0.05881 sd:0.033818\n",
            "\t1462: \"embedded_sentence3.493\" NUMERICAL mean:0.00587633 min:-0.0588583 max:0.0540728 sd:0.0308608\n",
            "\t1463: \"embedded_sentence3.494\" NUMERICAL mean:-0.0197213 min:-0.0667383 max:0.0493812 sd:0.0292318\n",
            "\t1464: \"embedded_sentence3.495\" NUMERICAL mean:0.000253261 min:-0.034682 max:0.0764059 sd:0.0394662\n",
            "\t1465: \"embedded_sentence3.496\" NUMERICAL mean:0.00200536 min:-0.0630068 max:0.0680289 sd:0.0294647\n",
            "\t1466: \"embedded_sentence3.497\" NUMERICAL mean:0.023007 min:-0.0739665 max:0.0538661 sd:0.0333921\n",
            "\t1467: \"embedded_sentence3.498\" NUMERICAL mean:0.00784191 min:-0.0805413 max:0.0400489 sd:0.0394714\n",
            "\t1468: \"embedded_sentence3.499\" NUMERICAL mean:-0.0204259 min:-0.0708008 max:0.0798466 sd:0.0515908\n",
            "\t1469: \"embedded_sentence3.5\" NUMERICAL mean:0.0142492 min:-0.0839193 max:0.0785371 sd:0.0308222\n",
            "\t1470: \"embedded_sentence3.50\" NUMERICAL mean:0.0313921 min:-0.0784559 max:0.0826472 sd:0.0585201\n",
            "\t1471: \"embedded_sentence3.500\" NUMERICAL mean:-0.0200955 min:-0.060677 max:0.0718398 sd:0.03722\n",
            "\t1472: \"embedded_sentence3.501\" NUMERICAL mean:-0.0276779 min:-0.0526434 max:0.0914455 sd:0.0360974\n",
            "\t1473: \"embedded_sentence3.502\" NUMERICAL mean:-0.0233521 min:-0.0537216 max:0.0817105 sd:0.0370482\n",
            "\t1474: \"embedded_sentence3.503\" NUMERICAL mean:-0.0757996 min:-0.0933685 max:0.0647007 sd:0.0319162\n",
            "\t1475: \"embedded_sentence3.504\" NUMERICAL mean:0.00877341 min:-0.0309947 max:0.0847963 sd:0.0386625\n",
            "\t1476: \"embedded_sentence3.505\" NUMERICAL mean:-0.0262417 min:-0.0713676 max:0.0503086 sd:0.027912\n",
            "\t1477: \"embedded_sentence3.506\" NUMERICAL mean:-0.0518112 min:-0.0862128 max:0.0607681 sd:0.0324077\n",
            "\t1478: \"embedded_sentence3.507\" NUMERICAL mean:0.0451834 min:-0.045448 max:0.0775817 sd:0.0258845\n",
            "\t1479: \"embedded_sentence3.508\" NUMERICAL mean:-0.0221214 min:-0.0529921 max:0.0696084 sd:0.0275163\n",
            "\t1480: \"embedded_sentence3.509\" NUMERICAL mean:-0.00933924 min:-0.0722007 max:0.0712658 sd:0.0396739\n",
            "\t1481: \"embedded_sentence3.51\" NUMERICAL mean:-0.0139512 min:-0.0531132 max:0.0849542 sd:0.0397892\n",
            "\t1482: \"embedded_sentence3.510\" NUMERICAL mean:-0.0158894 min:-0.0660641 max:0.0569943 sd:0.0230033\n",
            "\t1483: \"embedded_sentence3.511\" NUMERICAL mean:-0.0387215 min:-0.0726672 max:0.0627416 sd:0.0409815\n",
            "\t1484: \"embedded_sentence3.52\" NUMERICAL mean:0.048996 min:-0.0421113 max:0.0801815 sd:0.0295175\n",
            "\t1485: \"embedded_sentence3.53\" NUMERICAL mean:0.0328968 min:-0.0738688 max:0.0821537 sd:0.0577437\n",
            "\t1486: \"embedded_sentence3.54\" NUMERICAL mean:-0.0192133 min:-0.0560634 max:0.0620793 sd:0.0334326\n",
            "\t1487: \"embedded_sentence3.55\" NUMERICAL mean:-0.0334097 min:-0.078847 max:0.0585762 sd:0.0309748\n",
            "\t1488: \"embedded_sentence3.56\" NUMERICAL mean:0.0345105 min:-0.0525186 max:0.0722939 sd:0.0241575\n",
            "\t1489: \"embedded_sentence3.57\" NUMERICAL mean:-0.0116404 min:-0.0647658 max:0.0813637 sd:0.0618416\n",
            "\t1490: \"embedded_sentence3.58\" NUMERICAL mean:0.0346261 min:-0.00171332 max:0.0860555 sd:0.0256987\n",
            "\t1491: \"embedded_sentence3.59\" NUMERICAL mean:-0.0314526 min:-0.0710488 max:0.0630129 sd:0.0329632\n",
            "\t1492: \"embedded_sentence3.6\" NUMERICAL mean:-0.00814875 min:-0.0762702 max:0.0742184 sd:0.0323868\n",
            "\t1493: \"embedded_sentence3.60\" NUMERICAL mean:-0.033019 min:-0.0670701 max:0.0569201 sd:0.0279025\n",
            "\t1494: \"embedded_sentence3.61\" NUMERICAL mean:-0.0263342 min:-0.0743328 max:0.0702591 sd:0.0479052\n",
            "\t1495: \"embedded_sentence3.62\" NUMERICAL mean:-0.00503619 min:-0.0814913 max:0.0478965 sd:0.0436724\n",
            "\t1496: \"embedded_sentence3.63\" NUMERICAL mean:-0.0214066 min:-0.0594116 max:0.0571283 sd:0.0360424\n",
            "\t1497: \"embedded_sentence3.64\" NUMERICAL mean:-0.0186897 min:-0.0766797 max:0.0543773 sd:0.0271725\n",
            "\t1498: \"embedded_sentence3.65\" NUMERICAL mean:-0.00479814 min:-0.0676131 max:0.0688885 sd:0.0259207\n",
            "\t1499: \"embedded_sentence3.66\" NUMERICAL mean:-0.0355807 min:-0.0861867 max:0.0351667 sd:0.0254441\n",
            "\t1500: \"embedded_sentence3.67\" NUMERICAL mean:-0.0365846 min:-0.0767427 max:0.0589497 sd:0.0285873\n",
            "\t1501: \"embedded_sentence3.68\" NUMERICAL mean:-0.00395517 min:-0.0728564 max:0.069557 sd:0.0296875\n",
            "\t1502: \"embedded_sentence3.69\" NUMERICAL mean:0.0317468 min:-0.0562765 max:0.0687454 sd:0.0330161\n",
            "\t1503: \"embedded_sentence3.7\" NUMERICAL mean:-0.0198397 min:-0.0783891 max:0.0641274 sd:0.0237605\n",
            "\t1504: \"embedded_sentence3.70\" NUMERICAL mean:-0.0279274 min:-0.069866 max:0.0723173 sd:0.0436505\n",
            "\t1505: \"embedded_sentence3.71\" NUMERICAL mean:-0.0273313 min:-0.0857725 max:0.0411078 sd:0.03753\n",
            "\t1506: \"embedded_sentence3.72\" NUMERICAL mean:-0.0321216 min:-0.0855653 max:0.0401035 sd:0.0248079\n",
            "\t1507: \"embedded_sentence3.73\" NUMERICAL mean:0.00524771 min:-0.0758332 max:0.0924465 sd:0.0519238\n",
            "\t1508: \"embedded_sentence3.74\" NUMERICAL mean:0.00381049 min:-0.055617 max:0.0738722 sd:0.0275723\n",
            "\t1509: \"embedded_sentence3.75\" NUMERICAL mean:-0.0308354 min:-0.0905907 max:0.0147622 sd:0.0474408\n",
            "\t1510: \"embedded_sentence3.76\" NUMERICAL mean:-0.020062 min:-0.0626761 max:0.0799653 sd:0.034095\n",
            "\t1511: \"embedded_sentence3.77\" NUMERICAL mean:0.0205723 min:-0.0527876 max:0.0818827 sd:0.031737\n",
            "\t1512: \"embedded_sentence3.78\" NUMERICAL mean:-0.00337956 min:-0.0795487 max:0.0744171 sd:0.0307593\n",
            "\t1513: \"embedded_sentence3.79\" NUMERICAL mean:-0.0384959 min:-0.0645325 max:0.0609761 sd:0.0354802\n",
            "\t1514: \"embedded_sentence3.8\" NUMERICAL mean:-0.003347 min:-0.0445913 max:0.0860366 sd:0.0461866\n",
            "\t1515: \"embedded_sentence3.80\" NUMERICAL mean:0.0100041 min:-0.0715547 max:0.0859352 sd:0.0315964\n",
            "\t1516: \"embedded_sentence3.81\" NUMERICAL mean:0.0172538 min:-0.0482277 max:0.0470374 sd:0.0275103\n",
            "\t1517: \"embedded_sentence3.82\" NUMERICAL mean:-0.0199597 min:-0.0779405 max:0.0104306 sd:0.0333207\n",
            "\t1518: \"embedded_sentence3.83\" NUMERICAL mean:-0.00874887 min:-0.0684327 max:0.0666502 sd:0.0236922\n",
            "\t1519: \"embedded_sentence3.84\" NUMERICAL mean:-0.0290278 min:-0.0725168 max:0.0680009 sd:0.0240241\n",
            "\t1520: \"embedded_sentence3.85\" NUMERICAL mean:0.0161179 min:-0.0331527 max:0.0775859 sd:0.027319\n",
            "\t1521: \"embedded_sentence3.86\" NUMERICAL mean:0.0068166 min:-0.0816649 max:0.0559716 sd:0.0427266\n",
            "\t1522: \"embedded_sentence3.87\" NUMERICAL mean:0.00526578 min:-0.0639196 max:0.0725963 sd:0.025251\n",
            "\t1523: \"embedded_sentence3.88\" NUMERICAL mean:0.0421935 min:-0.0477329 max:0.0770415 sd:0.0185644\n",
            "\t1524: \"embedded_sentence3.89\" NUMERICAL mean:-0.0225692 min:-0.0834281 max:0.0430347 sd:0.0384645\n",
            "\t1525: \"embedded_sentence3.9\" NUMERICAL mean:-0.0167052 min:-0.0855858 max:0.0564415 sd:0.0456168\n",
            "\t1526: \"embedded_sentence3.90\" NUMERICAL mean:0.0326195 min:-0.0661249 max:0.0671625 sd:0.0427396\n",
            "\t1527: \"embedded_sentence3.91\" NUMERICAL mean:0.0281435 min:-0.0520937 max:0.0670802 sd:0.019677\n",
            "\t1528: \"embedded_sentence3.92\" NUMERICAL mean:0.0227395 min:-0.0491144 max:0.0463234 sd:0.0294779\n",
            "\t1529: \"embedded_sentence3.93\" NUMERICAL mean:0.0302083 min:-0.0811192 max:0.0635343 sd:0.029028\n",
            "\t1530: \"embedded_sentence3.94\" NUMERICAL mean:-0.0208146 min:-0.0601068 max:0.062304 sd:0.0209387\n",
            "\t1531: \"embedded_sentence3.95\" NUMERICAL mean:0.0248198 min:-0.0653286 max:0.0877287 sd:0.0310026\n",
            "\t1532: \"embedded_sentence3.96\" NUMERICAL mean:-0.0084528 min:-0.0652474 max:0.0633316 sd:0.022541\n",
            "\t1533: \"embedded_sentence3.97\" NUMERICAL mean:0.0228189 min:-0.0684263 max:0.074295 sd:0.0351941\n",
            "\t1534: \"embedded_sentence3.98\" NUMERICAL mean:-0.0175398 min:-0.0525978 max:0.0469174 sd:0.0219233\n",
            "\t1535: \"embedded_sentence3.99\" NUMERICAL mean:-0.015657 min:-0.079582 max:0.0299165 sd:0.0333315\n",
            "\n",
            "CATEGORICAL: 1 (0.0650618%)\n",
            "\t1536: \"__LABEL\" CATEGORICAL integerized vocab-size:70 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"embedded_sentence\\\\.0\"\n",
            "features: \"embedded_sentence\\\\.1\"\n",
            "features: \"embedded_sentence\\\\.10\"\n",
            "features: \"embedded_sentence\\\\.100\"\n",
            "features: \"embedded_sentence\\\\.101\"\n",
            "features: \"embedded_sentence\\\\.102\"\n",
            "features: \"embedded_sentence\\\\.103\"\n",
            "features: \"embedded_sentence\\\\.104\"\n",
            "features: \"embedded_sentence\\\\.105\"\n",
            "features: \"embedded_sentence\\\\.106\"\n",
            "features: \"embedded_sentence\\\\.107\"\n",
            "features: \"embedded_sentence\\\\.108\"\n",
            "features: \"embedded_sentence\\\\.109\"\n",
            "features: \"embedded_sentence\\\\.11\"\n",
            "features: \"embedded_sentence\\\\.110\"\n",
            "features: \"embedded_sentence\\\\.111\"\n",
            "features: \"embedded_sentence\\\\.112\"\n",
            "features: \"embedded_sentence\\\\.113\"\n",
            "features: \"embedded_sentence\\\\.114\"\n",
            "features: \"embedded_sentence\\\\.115\"\n",
            "features: \"embedded_sentence\\\\.116\"\n",
            "features: \"embedded_sentence\\\\.117\"\n",
            "features: \"embedded_sentence\\\\.118\"\n",
            "features: \"embedded_sentence\\\\.119\"\n",
            "features: \"embedded_sentence\\\\.12\"\n",
            "features: \"embedded_sentence\\\\.120\"\n",
            "features: \"embedded_sentence\\\\.121\"\n",
            "features: \"embedded_sentence\\\\.122\"\n",
            "features: \"embedded_sentence\\\\.123\"\n",
            "features: \"embedded_sentence\\\\.124\"\n",
            "features: \"embedded_sentence\\\\.125\"\n",
            "features: \"embedded_sentence\\\\.126\"\n",
            "features: \"embedded_sentence\\\\.127\"\n",
            "features: \"embedded_sentence\\\\.128\"\n",
            "features: \"embedded_sentence\\\\.129\"\n",
            "features: \"embedded_sentence\\\\.13\"\n",
            "features: \"embedded_sentence\\\\.130\"\n",
            "features: \"embedded_sentence\\\\.131\"\n",
            "features: \"embedded_sentence\\\\.132\"\n",
            "features: \"embedded_sentence\\\\.133\"\n",
            "features: \"embedded_sentence\\\\.134\"\n",
            "features: \"embedded_sentence\\\\.135\"\n",
            "features: \"embedded_sentence\\\\.136\"\n",
            "features: \"embedded_sentence\\\\.137\"\n",
            "features: \"embedded_sentence\\\\.138\"\n",
            "features: \"embedded_sentence\\\\.139\"\n",
            "features: \"embedded_sentence\\\\.14\"\n",
            "features: \"embedded_sentence\\\\.140\"\n",
            "features: \"embedded_sentence\\\\.141\"\n",
            "features: \"embedded_sentence\\\\.142\"\n",
            "features: \"embedded_sentence\\\\.143\"\n",
            "features: \"embedded_sentence\\\\.144\"\n",
            "features: \"embedded_sentence\\\\.145\"\n",
            "features: \"embedded_sentence\\\\.146\"\n",
            "features: \"embedded_sentence\\\\.147\"\n",
            "features: \"embedded_sentence\\\\.148\"\n",
            "features: \"embedded_sentence\\\\.149\"\n",
            "features: \"embedded_sentence\\\\.15\"\n",
            "features: \"embedded_sentence\\\\.150\"\n",
            "features: \"embedded_sentence\\\\.151\"\n",
            "features: \"embedded_sentence\\\\.152\"\n",
            "features: \"embedded_sentence\\\\.153\"\n",
            "features: \"embedded_sentence\\\\.154\"\n",
            "features: \"embedded_sentence\\\\.155\"\n",
            "features: \"embedded_sentence\\\\.156\"\n",
            "features: \"embedded_sentence\\\\.157\"\n",
            "features: \"embedded_sentence\\\\.158\"\n",
            "features: \"embedded_sentence\\\\.159\"\n",
            "features: \"embedded_sentence\\\\.16\"\n",
            "features: \"embedded_sentence\\\\.160\"\n",
            "features: \"embedded_sentence\\\\.161\"\n",
            "features: \"embedded_sentence\\\\.162\"\n",
            "features: \"embedded_sentence\\\\.163\"\n",
            "features: \"embedded_sentence\\\\.164\"\n",
            "features: \"embedded_sentence\\\\.165\"\n",
            "features: \"embedded_sentence\\\\.166\"\n",
            "features: \"embedded_sentence\\\\.167\"\n",
            "features: \"embedded_sentence\\\\.168\"\n",
            "features: \"embedded_sentence\\\\.169\"\n",
            "features: \"embedded_sentence\\\\.17\"\n",
            "features: \"embedded_sentence\\\\.170\"\n",
            "features: \"embedded_sentence\\\\.171\"\n",
            "features: \"embedded_sentence\\\\.172\"\n",
            "features: \"embedded_sentence\\\\.173\"\n",
            "features: \"embedded_sentence\\\\.174\"\n",
            "features: \"embedded_sentence\\\\.175\"\n",
            "features: \"embedded_sentence\\\\.176\"\n",
            "features: \"embedded_sentence\\\\.177\"\n",
            "features: \"embedded_sentence\\\\.178\"\n",
            "features: \"embedded_sentence\\\\.179\"\n",
            "features: \"embedded_sentence\\\\.18\"\n",
            "features: \"embedded_sentence\\\\.180\"\n",
            "features: \"embedded_sentence\\\\.181\"\n",
            "features: \"embedded_sentence\\\\.182\"\n",
            "features: \"embedded_sentence\\\\.183\"\n",
            "features: \"embedded_sentence\\\\.184\"\n",
            "features: \"embedded_sentence\\\\.185\"\n",
            "features: \"embedded_sentence\\\\.186\"\n",
            "features: \"embedded_sentence\\\\.187\"\n",
            "features: \"embedded_sentence\\\\.188\"\n",
            "features: \"embedded_sentence\\\\.189\"\n",
            "features: \"embedded_sentence\\\\.19\"\n",
            "features: \"embedded_sentence\\\\.190\"\n",
            "features: \"embedded_sentence\\\\.191\"\n",
            "features: \"embedded_sentence\\\\.192\"\n",
            "features: \"embedded_sentence\\\\.193\"\n",
            "features: \"embedded_sentence\\\\.194\"\n",
            "features: \"embedded_sentence\\\\.195\"\n",
            "features: \"embedded_sentence\\\\.196\"\n",
            "features: \"embedded_sentence\\\\.197\"\n",
            "features: \"embedded_sentence\\\\.198\"\n",
            "features: \"embedded_sentence\\\\.199\"\n",
            "features: \"embedded_sentence\\\\.2\"\n",
            "features: \"embedded_sentence\\\\.20\"\n",
            "features: \"embedded_sentence\\\\.200\"\n",
            "features: \"embedded_sentence\\\\.201\"\n",
            "features: \"embedded_sentence\\\\.202\"\n",
            "features: \"embedded_sentence\\\\.203\"\n",
            "features: \"embedded_sentence\\\\.204\"\n",
            "features: \"embedded_sentence\\\\.205\"\n",
            "features: \"embedded_sentence\\\\.206\"\n",
            "features: \"embedded_sentence\\\\.207\"\n",
            "features: \"embedded_sentence\\\\.208\"\n",
            "features: \"embedded_sentence\\\\.209\"\n",
            "features: \"embedded_sentence\\\\.21\"\n",
            "features: \"embedded_sentence\\\\.210\"\n",
            "features: \"embedded_sentence\\\\.211\"\n",
            "features: \"embedded_sentence\\\\.212\"\n",
            "features: \"embedded_sentence\\\\.213\"\n",
            "features: \"embedded_sentence\\\\.214\"\n",
            "features: \"embedded_sentence\\\\.215\"\n",
            "features: \"embedded_sentence\\\\.216\"\n",
            "features: \"embedded_sentence\\\\.217\"\n",
            "features: \"embedded_sentence\\\\.218\"\n",
            "features: \"embedded_sentence\\\\.219\"\n",
            "features: \"embedded_sentence\\\\.22\"\n",
            "features: \"embedded_sentence\\\\.220\"\n",
            "features: \"embedded_sentence\\\\.221\"\n",
            "features: \"embedded_sentence\\\\.222\"\n",
            "features: \"embedded_sentence\\\\.223\"\n",
            "features: \"embedded_sentence\\\\.224\"\n",
            "features: \"embedded_sentence\\\\.225\"\n",
            "features: \"embedded_sentence\\\\.226\"\n",
            "features: \"embedded_sentence\\\\.227\"\n",
            "features: \"embedded_sentence\\\\.228\"\n",
            "features: \"embedded_sentence\\\\.229\"\n",
            "features: \"embedded_sentence\\\\.23\"\n",
            "features: \"embedded_sentence\\\\.230\"\n",
            "features: \"embedded_sentence\\\\.231\"\n",
            "features: \"embedded_sentence\\\\.232\"\n",
            "features: \"embedded_sentence\\\\.233\"\n",
            "features: \"embedded_sentence\\\\.234\"\n",
            "features: \"embedded_sentence\\\\.235\"\n",
            "features: \"embedded_sentence\\\\.236\"\n",
            "features: \"embedded_sentence\\\\.237\"\n",
            "features: \"embedded_sentence\\\\.238\"\n",
            "features: \"embedded_sentence\\\\.239\"\n",
            "features: \"embedded_sentence\\\\.24\"\n",
            "features: \"embedded_sentence\\\\.240\"\n",
            "features: \"embedded_sentence\\\\.241\"\n",
            "features: \"embedded_sentence\\\\.242\"\n",
            "features: \"embedded_sentence\\\\.243\"\n",
            "features: \"embedded_sentence\\\\.244\"\n",
            "features: \"embedded_sentence\\\\.245\"\n",
            "features: \"embedded_sentence\\\\.246\"\n",
            "features: \"embedded_sentence\\\\.247\"\n",
            "features: \"embedded_sentence\\\\.248\"\n",
            "features: \"embedded_sentence\\\\.249\"\n",
            "features: \"embedded_sentence\\\\.25\"\n",
            "features: \"embedded_sentence\\\\.250\"\n",
            "features: \"embedded_sentence\\\\.251\"\n",
            "features: \"embedded_sentence\\\\.252\"\n",
            "features: \"embedded_sentence\\\\.253\"\n",
            "features: \"embedded_sentence\\\\.254\"\n",
            "features: \"embedded_sentence\\\\.255\"\n",
            "features: \"embedded_sentence\\\\.256\"\n",
            "features: \"embedded_sentence\\\\.257\"\n",
            "features: \"embedded_sentence\\\\.258\"\n",
            "features: \"embedded_sentence\\\\.259\"\n",
            "features: \"embedded_sentence\\\\.26\"\n",
            "features: \"embedded_sentence\\\\.260\"\n",
            "features: \"embedded_sentence\\\\.261\"\n",
            "features: \"embedded_sentence\\\\.262\"\n",
            "features: \"embedded_sentence\\\\.263\"\n",
            "features: \"embedded_sentence\\\\.264\"\n",
            "features: \"embedded_sentence\\\\.265\"\n",
            "features: \"embedded_sentence\\\\.266\"\n",
            "features: \"embedded_sentence\\\\.267\"\n",
            "features: \"embedded_sentence\\\\.268\"\n",
            "features: \"embedded_sentence\\\\.269\"\n",
            "features: \"embedded_sentence\\\\.27\"\n",
            "features: \"embedded_sentence\\\\.270\"\n",
            "features: \"embedded_sentence\\\\.271\"\n",
            "features: \"embedded_sentence\\\\.272\"\n",
            "features: \"embedded_sentence\\\\.273\"\n",
            "features: \"embedded_sentence\\\\.274\"\n",
            "features: \"embedded_sentence\\\\.275\"\n",
            "features: \"embedded_sentence\\\\.276\"\n",
            "features: \"embedded_sentence\\\\.277\"\n",
            "features: \"embedded_sentence\\\\.278\"\n",
            "features: \"embedded_sentence\\\\.279\"\n",
            "features: \"embedded_sentence\\\\.28\"\n",
            "features: \"embedded_sentence\\\\.280\"\n",
            "features: \"embedded_sentence\\\\.281\"\n",
            "features: \"embedded_sentence\\\\.282\"\n",
            "features: \"embedded_sentence\\\\.283\"\n",
            "features: \"embedded_sentence\\\\.284\"\n",
            "features: \"embedded_sentence\\\\.285\"\n",
            "features: \"embedded_sentence\\\\.286\"\n",
            "features: \"embedded_sentence\\\\.287\"\n",
            "features: \"embedded_sentence\\\\.288\"\n",
            "features: \"embedded_sentence\\\\.289\"\n",
            "features: \"embedded_sentence\\\\.29\"\n",
            "features: \"embedded_sentence\\\\.290\"\n",
            "features: \"embedded_sentence\\\\.291\"\n",
            "features: \"embedded_sentence\\\\.292\"\n",
            "features: \"embedded_sentence\\\\.293\"\n",
            "features: \"embedded_sentence\\\\.294\"\n",
            "features: \"embedded_sentence\\\\.295\"\n",
            "features: \"embedded_sentence\\\\.296\"\n",
            "features: \"embedded_sentence\\\\.297\"\n",
            "features: \"embedded_sentence\\\\.298\"\n",
            "features: \"embedded_sentence\\\\.299\"\n",
            "features: \"embedded_sentence\\\\.3\"\n",
            "features: \"embedded_sentence\\\\.30\"\n",
            "features: \"embedded_sentence\\\\.300\"\n",
            "features: \"embedded_sentence\\\\.301\"\n",
            "features: \"embedded_sentence\\\\.302\"\n",
            "features: \"embedded_sentence\\\\.303\"\n",
            "features: \"embedded_sentence\\\\.304\"\n",
            "features: \"embedded_sentence\\\\.305\"\n",
            "features: \"embedded_sentence\\\\.306\"\n",
            "features: \"embedded_sentence\\\\.307\"\n",
            "features: \"embedded_sentence\\\\.308\"\n",
            "features: \"embedded_sentence\\\\.309\"\n",
            "features: \"embedded_sentence\\\\.31\"\n",
            "features: \"embedded_sentence\\\\.310\"\n",
            "features: \"embedded_sentence\\\\.311\"\n",
            "features: \"embedded_sentence\\\\.312\"\n",
            "features: \"embedded_sentence\\\\.313\"\n",
            "features: \"embedded_sentence\\\\.314\"\n",
            "features: \"embedded_sentence\\\\.315\"\n",
            "features: \"embedded_sentence\\\\.316\"\n",
            "features: \"embedded_sentence\\\\.317\"\n",
            "features: \"embedded_sentence\\\\.318\"\n",
            "features: \"embedded_sentence\\\\.319\"\n",
            "features: \"embedded_sentence\\\\.32\"\n",
            "features: \"embedded_sentence\\\\.320\"\n",
            "features: \"embedded_sentence\\\\.321\"\n",
            "features: \"embedded_sentence\\\\.322\"\n",
            "features: \"embedded_sentence\\\\.323\"\n",
            "features: \"embedded_sentence\\\\.324\"\n",
            "features: \"embedded_sentence\\\\.325\"\n",
            "features: \"embedded_sentence\\\\.326\"\n",
            "features: \"embedded_sentence\\\\.327\"\n",
            "features: \"embedded_sentence\\\\.328\"\n",
            "features: \"embedded_sentence\\\\.329\"\n",
            "features: \"embedded_sentence\\\\.33\"\n",
            "features: \"embedded_sentence\\\\.330\"\n",
            "features: \"embedded_sentence\\\\.331\"\n",
            "features: \"embedded_sentence\\\\.332\"\n",
            "features: \"embedded_sentence\\\\.333\"\n",
            "features: \"embedded_sentence\\\\.334\"\n",
            "features: \"embedded_sentence\\\\.335\"\n",
            "features: \"embedded_sentence\\\\.336\"\n",
            "features: \"embedded_sentence\\\\.337\"\n",
            "features: \"embedded_sentence\\\\.338\"\n",
            "features: \"embedded_sentence\\\\.339\"\n",
            "features: \"embedded_sentence\\\\.34\"\n",
            "features: \"embedded_sentence\\\\.340\"\n",
            "features: \"embedded_sentence\\\\.341\"\n",
            "features: \"embedded_sentence\\\\.342\"\n",
            "features: \"embedded_sentence\\\\.343\"\n",
            "features: \"embedded_sentence\\\\.344\"\n",
            "features: \"embedded_sentence\\\\.345\"\n",
            "features: \"embedded_sentence\\\\.346\"\n",
            "features: \"embedded_sentence\\\\.347\"\n",
            "features: \"embedded_sentence\\\\.348\"\n",
            "features: \"embedded_sentence\\\\.349\"\n",
            "features: \"embedded_sentence\\\\.35\"\n",
            "features: \"embedded_sentence\\\\.350\"\n",
            "features: \"embedded_sentence\\\\.351\"\n",
            "features: \"embedded_sentence\\\\.352\"\n",
            "features: \"embedded_sentence\\\\.353\"\n",
            "features: \"embedded_sentence\\\\.354\"\n",
            "features: \"embedded_sentence\\\\.355\"\n",
            "features: \"embedded_sentence\\\\.356\"\n",
            "features: \"embedded_sentence\\\\.357\"\n",
            "features: \"embedded_sentence\\\\.358\"\n",
            "features: \"embedded_sentence\\\\.359\"\n",
            "features: \"embedded_sentence\\\\.36\"\n",
            "features: \"embedded_sentence\\\\.360\"\n",
            "features: \"embedded_sentence\\\\.361\"\n",
            "features: \"embedded_sentence\\\\.362\"\n",
            "features: \"embedded_sentence\\\\.363\"\n",
            "features: \"embedded_sentence\\\\.364\"\n",
            "features: \"embedded_sentence\\\\.365\"\n",
            "features: \"embedded_sentence\\\\.366\"\n",
            "features: \"embedded_sentence\\\\.367\"\n",
            "features: \"embedded_sentence\\\\.368\"\n",
            "features: \"embedded_sentence\\\\.369\"\n",
            "features: \"embedded_sentence\\\\.37\"\n",
            "features: \"embedded_sentence\\\\.370\"\n",
            "features: \"embedded_sentence\\\\.371\"\n",
            "features: \"embedded_sentence\\\\.372\"\n",
            "features: \"embedded_sentence\\\\.373\"\n",
            "features: \"embedded_sentence\\\\.374\"\n",
            "features: \"embedded_sentence\\\\.375\"\n",
            "features: \"embedded_sentence\\\\.376\"\n",
            "features: \"embedded_sentence\\\\.377\"\n",
            "features: \"embedded_sentence\\\\.378\"\n",
            "features: \"embedded_sentence\\\\.379\"\n",
            "features: \"embedded_sentence\\\\.38\"\n",
            "features: \"embedded_sentence\\\\.380\"\n",
            "features: \"embedded_sentence\\\\.381\"\n",
            "features: \"embedded_sentence\\\\.382\"\n",
            "features: \"embedded_sentence\\\\.383\"\n",
            "features: \"embedded_sentence\\\\.384\"\n",
            "features: \"embedded_sentence\\\\.385\"\n",
            "features: \"embedded_sentence\\\\.386\"\n",
            "features: \"embedded_sentence\\\\.387\"\n",
            "features: \"embedded_sentence\\\\.388\"\n",
            "features: \"embedded_sentence\\\\.389\"\n",
            "features: \"embedded_sentence\\\\.39\"\n",
            "features: \"embedded_sentence\\\\.390\"\n",
            "features: \"embedded_sentence\\\\.391\"\n",
            "features: \"embedded_sentence\\\\.392\"\n",
            "features: \"embedded_sentence\\\\.393\"\n",
            "features: \"embedded_sentence\\\\.394\"\n",
            "features: \"embedded_sentence\\\\.395\"\n",
            "features: \"embedded_sentence\\\\.396\"\n",
            "features: \"embedded_sentence\\\\.397\"\n",
            "features: \"embedded_sentence\\\\.398\"\n",
            "features: \"embedded_sentence\\\\.399\"\n",
            "features: \"embedded_sentence\\\\.4\"\n",
            "features: \"embedded_sentence\\\\.40\"\n",
            "features: \"embedded_sentence\\\\.400\"\n",
            "features: \"embedded_sentence\\\\.401\"\n",
            "features: \"embedded_sentence\\\\.402\"\n",
            "features: \"embedded_sentence\\\\.403\"\n",
            "features: \"embedded_sentence\\\\.404\"\n",
            "features: \"embedded_sentence\\\\.405\"\n",
            "features: \"embedded_sentence\\\\.406\"\n",
            "features: \"embedded_sentence\\\\.407\"\n",
            "features: \"embedded_sentence\\\\.408\"\n",
            "features: \"embedded_sentence\\\\.409\"\n",
            "features: \"embedded_sentence\\\\.41\"\n",
            "features: \"embedded_sentence\\\\.410\"\n",
            "features: \"embedded_sentence\\\\.411\"\n",
            "features: \"embedded_sentence\\\\.412\"\n",
            "features: \"embedded_sentence\\\\.413\"\n",
            "features: \"embedded_sentence\\\\.414\"\n",
            "features: \"embedded_sentence\\\\.415\"\n",
            "features: \"embedded_sentence\\\\.416\"\n",
            "features: \"embedded_sentence\\\\.417\"\n",
            "features: \"embedded_sentence\\\\.418\"\n",
            "features: \"embedded_sentence\\\\.419\"\n",
            "features: \"embedded_sentence\\\\.42\"\n",
            "features: \"embedded_sentence\\\\.420\"\n",
            "features: \"embedded_sentence\\\\.421\"\n",
            "features: \"embedded_sentence\\\\.422\"\n",
            "features: \"embedded_sentence\\\\.423\"\n",
            "features: \"embedded_sentence\\\\.424\"\n",
            "features: \"embedded_sentence\\\\.425\"\n",
            "features: \"embedded_sentence\\\\.426\"\n",
            "features: \"embedded_sentence\\\\.427\"\n",
            "features: \"embedded_sentence\\\\.428\"\n",
            "features: \"embedded_sentence\\\\.429\"\n",
            "features: \"embedded_sentence\\\\.43\"\n",
            "features: \"embedded_sentence\\\\.430\"\n",
            "features: \"embedded_sentence\\\\.431\"\n",
            "features: \"embedded_sentence\\\\.432\"\n",
            "features: \"embedded_sentence\\\\.433\"\n",
            "features: \"embedded_sentence\\\\.434\"\n",
            "features: \"embedded_sentence\\\\.435\"\n",
            "features: \"embedded_sentence\\\\.436\"\n",
            "features: \"embedded_sentence\\\\.437\"\n",
            "features: \"embedded_sentence\\\\.438\"\n",
            "features: \"embedded_sentence\\\\.439\"\n",
            "features: \"embedded_sentence\\\\.44\"\n",
            "features: \"embedded_sentence\\\\.440\"\n",
            "features: \"embedded_sentence\\\\.441\"\n",
            "features: \"embedded_sentence\\\\.442\"\n",
            "features: \"embedded_sentence\\\\.443\"\n",
            "features: \"embedded_sentence\\\\.444\"\n",
            "features: \"embedded_sentence\\\\.445\"\n",
            "features: \"embedded_sentence\\\\.446\"\n",
            "features: \"embedded_sentence\\\\.447\"\n",
            "features: \"embedded_sentence\\\\.448\"\n",
            "features: \"embedded_sentence\\\\.449\"\n",
            "features: \"embedded_sentence\\\\.45\"\n",
            "features: \"embedded_sentence\\\\.450\"\n",
            "features: \"embedded_sentence\\\\.451\"\n",
            "features: \"embedded_sentence\\\\.452\"\n",
            "features: \"embedded_sentence\\\\.453\"\n",
            "features: \"embedded_sentence\\\\.454\"\n",
            "features: \"embedded_sentence\\\\.455\"\n",
            "features: \"embedded_sentence\\\\.456\"\n",
            "features: \"embedded_sentence\\\\.457\"\n",
            "features: \"embedded_sentence\\\\.458\"\n",
            "features: \"embedded_sentence\\\\.459\"\n",
            "features: \"embedded_sentence\\\\.46\"\n",
            "features: \"embedded_sentence\\\\.460\"\n",
            "features: \"embedded_sentence\\\\.461\"\n",
            "features: \"embedded_sentence\\\\.462\"\n",
            "features: \"embedded_sentence\\\\.463\"\n",
            "features: \"embedded_sentence\\\\.464\"\n",
            "features: \"embedded_sentence\\\\.465\"\n",
            "features: \"embedded_sentence\\\\.466\"\n",
            "features: \"embedded_sentence\\\\.467\"\n",
            "features: \"embedded_sentence\\\\.468\"\n",
            "features: \"embedded_sentence\\\\.469\"\n",
            "features: \"embedded_sentence\\\\.47\"\n",
            "features: \"embedded_sentence\\\\.470\"\n",
            "features: \"embedded_sentence\\\\.471\"\n",
            "features: \"embedded_sentence\\\\.472\"\n",
            "features: \"embedded_sentence\\\\.473\"\n",
            "features: \"embedded_sentence\\\\.474\"\n",
            "features: \"embedded_sentence\\\\.475\"\n",
            "features: \"embedded_sentence\\\\.476\"\n",
            "features: \"embedded_sentence\\\\.477\"\n",
            "features: \"embedded_sentence\\\\.478\"\n",
            "features: \"embedded_sentence\\\\.479\"\n",
            "features: \"embedded_sentence\\\\.48\"\n",
            "features: \"embedded_sentence\\\\.480\"\n",
            "features: \"embedded_sentence\\\\.481\"\n",
            "features: \"embedded_sentence\\\\.482\"\n",
            "features: \"embedded_sentence\\\\.483\"\n",
            "features: \"embedded_sentence\\\\.484\"\n",
            "features: \"embedded_sentence\\\\.485\"\n",
            "features: \"embedded_sentence\\\\.486\"\n",
            "features: \"embedded_sentence\\\\.487\"\n",
            "features: \"embedded_sentence\\\\.488\"\n",
            "features: \"embedded_sentence\\\\.489\"\n",
            "features: \"embedded_sentence\\\\.49\"\n",
            "features: \"embedded_sentence\\\\.490\"\n",
            "features: \"embedded_sentence\\\\.491\"\n",
            "features: \"embedded_sentence\\\\.492\"\n",
            "features: \"embedded_sentence\\\\.493\"\n",
            "features: \"embedded_sentence\\\\.494\"\n",
            "features: \"embedded_sentence\\\\.495\"\n",
            "features: \"embedded_sentence\\\\.496\"\n",
            "features: \"embedded_sentence\\\\.497\"\n",
            "features: \"embedded_sentence\\\\.498\"\n",
            "features: \"embedded_sentence\\\\.499\"\n",
            "features: \"embedded_sentence\\\\.5\"\n",
            "features: \"embedded_sentence\\\\.50\"\n",
            "features: \"embedded_sentence\\\\.500\"\n",
            "features: \"embedded_sentence\\\\.501\"\n",
            "features: \"embedded_sentence\\\\.502\"\n",
            "features: \"embedded_sentence\\\\.503\"\n",
            "features: \"embedded_sentence\\\\.504\"\n",
            "features: \"embedded_sentence\\\\.505\"\n",
            "features: \"embedded_sentence\\\\.506\"\n",
            "features: \"embedded_sentence\\\\.507\"\n",
            "features: \"embedded_sentence\\\\.508\"\n",
            "features: \"embedded_sentence\\\\.509\"\n",
            "features: \"embedded_sentence\\\\.51\"\n",
            "features: \"embedded_sentence\\\\.510\"\n",
            "features: \"embedded_sentence\\\\.511\"\n",
            "features: \"embedded_sentence\\\\.52\"\n",
            "features: \"embedded_sentence\\\\.53\"\n",
            "features: \"embedded_sentence\\\\.54\"\n",
            "features: \"embedded_sentence\\\\.55\"\n",
            "features: \"embedded_sentence\\\\.56\"\n",
            "features: \"embedded_sentence\\\\.57\"\n",
            "features: \"embedded_sentence\\\\.58\"\n",
            "features: \"embedded_sentence\\\\.59\"\n",
            "features: \"embedded_sentence\\\\.6\"\n",
            "features: \"embedded_sentence\\\\.60\"\n",
            "features: \"embedded_sentence\\\\.61\"\n",
            "features: \"embedded_sentence\\\\.62\"\n",
            "features: \"embedded_sentence\\\\.63\"\n",
            "features: \"embedded_sentence\\\\.64\"\n",
            "features: \"embedded_sentence\\\\.65\"\n",
            "features: \"embedded_sentence\\\\.66\"\n",
            "features: \"embedded_sentence\\\\.67\"\n",
            "features: \"embedded_sentence\\\\.68\"\n",
            "features: \"embedded_sentence\\\\.69\"\n",
            "features: \"embedded_sentence\\\\.7\"\n",
            "features: \"embedded_sentence\\\\.70\"\n",
            "features: \"embedded_sentence\\\\.71\"\n",
            "features: \"embedded_sentence\\\\.72\"\n",
            "features: \"embedded_sentence\\\\.73\"\n",
            "features: \"embedded_sentence\\\\.74\"\n",
            "features: \"embedded_sentence\\\\.75\"\n",
            "features: \"embedded_sentence\\\\.76\"\n",
            "features: \"embedded_sentence\\\\.77\"\n",
            "features: \"embedded_sentence\\\\.78\"\n",
            "features: \"embedded_sentence\\\\.79\"\n",
            "features: \"embedded_sentence\\\\.8\"\n",
            "features: \"embedded_sentence\\\\.80\"\n",
            "features: \"embedded_sentence\\\\.81\"\n",
            "features: \"embedded_sentence\\\\.82\"\n",
            "features: \"embedded_sentence\\\\.83\"\n",
            "features: \"embedded_sentence\\\\.84\"\n",
            "features: \"embedded_sentence\\\\.85\"\n",
            "features: \"embedded_sentence\\\\.86\"\n",
            "features: \"embedded_sentence\\\\.87\"\n",
            "features: \"embedded_sentence\\\\.88\"\n",
            "features: \"embedded_sentence\\\\.89\"\n",
            "features: \"embedded_sentence\\\\.9\"\n",
            "features: \"embedded_sentence\\\\.90\"\n",
            "features: \"embedded_sentence\\\\.91\"\n",
            "features: \"embedded_sentence\\\\.92\"\n",
            "features: \"embedded_sentence\\\\.93\"\n",
            "features: \"embedded_sentence\\\\.94\"\n",
            "features: \"embedded_sentence\\\\.95\"\n",
            "features: \"embedded_sentence\\\\.96\"\n",
            "features: \"embedded_sentence\\\\.97\"\n",
            "features: \"embedded_sentence\\\\.98\"\n",
            "features: \"embedded_sentence\\\\.99\"\n",
            "features: \"embedded_sentence2\\\\.0\"\n",
            "features: \"embedded_sentence2\\\\.1\"\n",
            "features: \"embedded_sentence2\\\\.10\"\n",
            "features: \"embedded_sentence2\\\\.100\"\n",
            "features: \"embedded_sentence2\\\\.101\"\n",
            "features: \"embedded_sentence2\\\\.102\"\n",
            "features: \"embedded_sentence2\\\\.103\"\n",
            "features: \"embedded_sentence2\\\\.104\"\n",
            "features: \"embedded_sentence2\\\\.105\"\n",
            "features: \"embedded_sentence2\\\\.106\"\n",
            "features: \"embedded_sentence2\\\\.107\"\n",
            "features: \"embedded_sentence2\\\\.108\"\n",
            "features: \"embedded_sentence2\\\\.109\"\n",
            "features: \"embedded_sentence2\\\\.11\"\n",
            "features: \"embedded_sentence2\\\\.110\"\n",
            "features: \"embedded_sentence2\\\\.111\"\n",
            "features: \"embedded_sentence2\\\\.112\"\n",
            "features: \"embedded_sentence2\\\\.113\"\n",
            "features: \"embedded_sentence2\\\\.114\"\n",
            "features: \"embedded_sentence2\\\\.115\"\n",
            "features: \"embedded_sentence2\\\\.116\"\n",
            "features: \"embedded_sentence2\\\\.117\"\n",
            "features: \"embedded_sentence2\\\\.118\"\n",
            "features: \"embedded_sentence2\\\\.119\"\n",
            "features: \"embedded_sentence2\\\\.12\"\n",
            "features: \"embedded_sentence2\\\\.120\"\n",
            "features: \"embedded_sentence2\\\\.121\"\n",
            "features: \"embedded_sentence2\\\\.122\"\n",
            "features: \"embedded_sentence2\\\\.123\"\n",
            "features: \"embedded_sentence2\\\\.124\"\n",
            "features: \"embedded_sentence2\\\\.125\"\n",
            "features: \"embedded_sentence2\\\\.126\"\n",
            "features: \"embedded_sentence2\\\\.127\"\n",
            "features: \"embedded_sentence2\\\\.128\"\n",
            "features: \"embedded_sentence2\\\\.129\"\n",
            "features: \"embedded_sentence2\\\\.13\"\n",
            "features: \"embedded_sentence2\\\\.130\"\n",
            "features: \"embedded_sentence2\\\\.131\"\n",
            "features: \"embedded_sentence2\\\\.132\"\n",
            "features: \"embedded_sentence2\\\\.133\"\n",
            "features: \"embedded_sentence2\\\\.134\"\n",
            "features: \"embedded_sentence2\\\\.135\"\n",
            "features: \"embedded_sentence2\\\\.136\"\n",
            "features: \"embedded_sentence2\\\\.137\"\n",
            "features: \"embedded_sentence2\\\\.138\"\n",
            "features: \"embedded_sentence2\\\\.139\"\n",
            "features: \"embedded_sentence2\\\\.14\"\n",
            "features: \"embedded_sentence2\\\\.140\"\n",
            "features: \"embedded_sentence2\\\\.141\"\n",
            "features: \"embedded_sentence2\\\\.142\"\n",
            "features: \"embedded_sentence2\\\\.143\"\n",
            "features: \"embedded_sentence2\\\\.144\"\n",
            "features: \"embedded_sentence2\\\\.145\"\n",
            "features: \"embedded_sentence2\\\\.146\"\n",
            "features: \"embedded_sentence2\\\\.147\"\n",
            "features: \"embedded_sentence2\\\\.148\"\n",
            "features: \"embedded_sentence2\\\\.149\"\n",
            "features: \"embedded_sentence2\\\\.15\"\n",
            "features: \"embedded_sentence2\\\\.150\"\n",
            "features: \"embedded_sentence2\\\\.151\"\n",
            "features: \"embedded_sentence2\\\\.152\"\n",
            "features: \"embedded_sentence2\\\\.153\"\n",
            "features: \"embedded_sentence2\\\\.154\"\n",
            "features: \"embedded_sentence2\\\\.155\"\n",
            "features: \"embedded_sentence2\\\\.156\"\n",
            "features: \"embedded_sentence2\\\\.157\"\n",
            "features: \"embedded_sentence2\\\\.158\"\n",
            "features: \"embedded_sentence2\\\\.159\"\n",
            "features: \"embedded_sentence2\\\\.16\"\n",
            "features: \"embedded_sentence2\\\\.160\"\n",
            "features: \"embedded_sentence2\\\\.161\"\n",
            "features: \"embedded_sentence2\\\\.162\"\n",
            "features: \"embedded_sentence2\\\\.163\"\n",
            "features: \"embedded_sentence2\\\\.164\"\n",
            "features: \"embedded_sentence2\\\\.165\"\n",
            "features: \"embedded_sentence2\\\\.166\"\n",
            "features: \"embedded_sentence2\\\\.167\"\n",
            "features: \"embedded_sentence2\\\\.168\"\n",
            "features: \"embedded_sentence2\\\\.169\"\n",
            "features: \"embedded_sentence2\\\\.17\"\n",
            "features: \"embedded_sentence2\\\\.170\"\n",
            "features: \"embedded_sentence2\\\\.171\"\n",
            "features: \"embedded_sentence2\\\\.172\"\n",
            "features: \"embedded_sentence2\\\\.173\"\n",
            "features: \"embedded_sentence2\\\\.174\"\n",
            "features: \"embedded_sentence2\\\\.175\"\n",
            "features: \"embedded_sentence2\\\\.176\"\n",
            "features: \"embedded_sentence2\\\\.177\"\n",
            "features: \"embedded_sentence2\\\\.178\"\n",
            "features: \"embedded_sentence2\\\\.179\"\n",
            "features: \"embedded_sentence2\\\\.18\"\n",
            "features: \"embedded_sentence2\\\\.180\"\n",
            "features: \"embedded_sentence2\\\\.181\"\n",
            "features: \"embedded_sentence2\\\\.182\"\n",
            "features: \"embedded_sentence2\\\\.183\"\n",
            "features: \"embedded_sentence2\\\\.184\"\n",
            "features: \"embedded_sentence2\\\\.185\"\n",
            "features: \"embedded_sentence2\\\\.186\"\n",
            "features: \"embedded_sentence2\\\\.187\"\n",
            "features: \"embedded_sentence2\\\\.188\"\n",
            "features: \"embedded_sentence2\\\\.189\"\n",
            "features: \"embedded_sentence2\\\\.19\"\n",
            "features: \"embedded_sentence2\\\\.190\"\n",
            "features: \"embedded_sentence2\\\\.191\"\n",
            "features: \"embedded_sentence2\\\\.192\"\n",
            "features: \"embedded_sentence2\\\\.193\"\n",
            "features: \"embedded_sentence2\\\\.194\"\n",
            "features: \"embedded_sentence2\\\\.195\"\n",
            "features: \"embedded_sentence2\\\\.196\"\n",
            "features: \"embedded_sentence2\\\\.197\"\n",
            "features: \"embedded_sentence2\\\\.198\"\n",
            "features: \"embedded_sentence2\\\\.199\"\n",
            "features: \"embedded_sentence2\\\\.2\"\n",
            "features: \"embedded_sentence2\\\\.20\"\n",
            "features: \"embedded_sentence2\\\\.200\"\n",
            "features: \"embedded_sentence2\\\\.201\"\n",
            "features: \"embedded_sentence2\\\\.202\"\n",
            "features: \"embedded_sentence2\\\\.203\"\n",
            "features: \"embedded_sentence2\\\\.204\"\n",
            "features: \"embedded_sentence2\\\\.205\"\n",
            "features: \"embedded_sentence2\\\\.206\"\n",
            "features: \"embedded_sentence2\\\\.207\"\n",
            "features: \"embedded_sentence2\\\\.208\"\n",
            "features: \"embedded_sentence2\\\\.209\"\n",
            "features: \"embedded_sentence2\\\\.21\"\n",
            "features: \"embedded_sentence2\\\\.210\"\n",
            "features: \"embedded_sentence2\\\\.211\"\n",
            "features: \"embedded_sentence2\\\\.212\"\n",
            "features: \"embedded_sentence2\\\\.213\"\n",
            "features: \"embedded_sentence2\\\\.214\"\n",
            "features: \"embedded_sentence2\\\\.215\"\n",
            "features: \"embedded_sentence2\\\\.216\"\n",
            "features: \"embedded_sentence2\\\\.217\"\n",
            "features: \"embedded_sentence2\\\\.218\"\n",
            "features: \"embedded_sentence2\\\\.219\"\n",
            "features: \"embedded_sentence2\\\\.22\"\n",
            "features: \"embedded_sentence2\\\\.220\"\n",
            "features: \"embedded_sentence2\\\\.221\"\n",
            "features: \"embedded_sentence2\\\\.222\"\n",
            "features: \"embedded_sentence2\\\\.223\"\n",
            "features: \"embedded_sentence2\\\\.224\"\n",
            "features: \"embedded_sentence2\\\\.225\"\n",
            "features: \"embedded_sentence2\\\\.226\"\n",
            "features: \"embedded_sentence2\\\\.227\"\n",
            "features: \"embedded_sentence2\\\\.228\"\n",
            "features: \"embedded_sentence2\\\\.229\"\n",
            "features: \"embedded_sentence2\\\\.23\"\n",
            "features: \"embedded_sentence2\\\\.230\"\n",
            "features: \"embedded_sentence2\\\\.231\"\n",
            "features: \"embedded_sentence2\\\\.232\"\n",
            "features: \"embedded_sentence2\\\\.233\"\n",
            "features: \"embedded_sentence2\\\\.234\"\n",
            "features: \"embedded_sentence2\\\\.235\"\n",
            "features: \"embedded_sentence2\\\\.236\"\n",
            "features: \"embedded_sentence2\\\\.237\"\n",
            "features: \"embedded_sentence2\\\\.238\"\n",
            "features: \"embedded_sentence2\\\\.239\"\n",
            "features: \"embedded_sentence2\\\\.24\"\n",
            "features: \"embedded_sentence2\\\\.240\"\n",
            "features: \"embedded_sentence2\\\\.241\"\n",
            "features: \"embedded_sentence2\\\\.242\"\n",
            "features: \"embedded_sentence2\\\\.243\"\n",
            "features: \"embedded_sentence2\\\\.244\"\n",
            "features: \"embedded_sentence2\\\\.245\"\n",
            "features: \"embedded_sentence2\\\\.246\"\n",
            "features: \"embedded_sentence2\\\\.247\"\n",
            "features: \"embedded_sentence2\\\\.248\"\n",
            "features: \"embedded_sentence2\\\\.249\"\n",
            "features: \"embedded_sentence2\\\\.25\"\n",
            "features: \"embedded_sentence2\\\\.250\"\n",
            "features: \"embedded_sentence2\\\\.251\"\n",
            "features: \"embedded_sentence2\\\\.252\"\n",
            "features: \"embedded_sentence2\\\\.253\"\n",
            "features: \"embedded_sentence2\\\\.254\"\n",
            "features: \"embedded_sentence2\\\\.255\"\n",
            "features: \"embedded_sentence2\\\\.256\"\n",
            "features: \"embedded_sentence2\\\\.257\"\n",
            "features: \"embedded_sentence2\\\\.258\"\n",
            "features: \"embedded_sentence2\\\\.259\"\n",
            "features: \"embedded_sentence2\\\\.26\"\n",
            "features: \"embedded_sentence2\\\\.260\"\n",
            "features: \"embedded_sentence2\\\\.261\"\n",
            "features: \"embedded_sentence2\\\\.262\"\n",
            "features: \"embedded_sentence2\\\\.263\"\n",
            "features: \"embedded_sentence2\\\\.264\"\n",
            "features: \"embedded_sentence2\\\\.265\"\n",
            "features: \"embedded_sentence2\\\\.266\"\n",
            "features: \"embedded_sentence2\\\\.267\"\n",
            "features: \"embedded_sentence2\\\\.268\"\n",
            "features: \"embedded_sentence2\\\\.269\"\n",
            "features: \"embedded_sentence2\\\\.27\"\n",
            "features: \"embedded_sentence2\\\\.270\"\n",
            "features: \"embedded_sentence2\\\\.271\"\n",
            "features: \"embedded_sentence2\\\\.272\"\n",
            "features: \"embedded_sentence2\\\\.273\"\n",
            "features: \"embedded_sentence2\\\\.274\"\n",
            "features: \"embedded_sentence2\\\\.275\"\n",
            "features: \"embedded_sentence2\\\\.276\"\n",
            "features: \"embedded_sentence2\\\\.277\"\n",
            "features: \"embedded_sentence2\\\\.278\"\n",
            "features: \"embedded_sentence2\\\\.279\"\n",
            "features: \"embedded_sentence2\\\\.28\"\n",
            "features: \"embedded_sentence2\\\\.280\"\n",
            "features: \"embedded_sentence2\\\\.281\"\n",
            "features: \"embedded_sentence2\\\\.282\"\n",
            "features: \"embedded_sentence2\\\\.283\"\n",
            "features: \"embedded_sentence2\\\\.284\"\n",
            "features: \"embedded_sentence2\\\\.285\"\n",
            "features: \"embedded_sentence2\\\\.286\"\n",
            "features: \"embedded_sentence2\\\\.287\"\n",
            "features: \"embedded_sentence2\\\\.288\"\n",
            "features: \"embedded_sentence2\\\\.289\"\n",
            "features: \"embedded_sentence2\\\\.29\"\n",
            "features: \"embedded_sentence2\\\\.290\"\n",
            "features: \"embedded_sentence2\\\\.291\"\n",
            "features: \"embedded_sentence2\\\\.292\"\n",
            "features: \"embedded_sentence2\\\\.293\"\n",
            "features: \"embedded_sentence2\\\\.294\"\n",
            "features: \"embedded_sentence2\\\\.295\"\n",
            "features: \"embedded_sentence2\\\\.296\"\n",
            "features: \"embedded_sentence2\\\\.297\"\n",
            "features: \"embedded_sentence2\\\\.298\"\n",
            "features: \"embedded_sentence2\\\\.299\"\n",
            "features: \"embedded_sentence2\\\\.3\"\n",
            "features: \"embedded_sentence2\\\\.30\"\n",
            "features: \"embedded_sentence2\\\\.300\"\n",
            "features: \"embedded_sentence2\\\\.301\"\n",
            "features: \"embedded_sentence2\\\\.302\"\n",
            "features: \"embedded_sentence2\\\\.303\"\n",
            "features: \"embedded_sentence2\\\\.304\"\n",
            "features: \"embedded_sentence2\\\\.305\"\n",
            "features: \"embedded_sentence2\\\\.306\"\n",
            "features: \"embedded_sentence2\\\\.307\"\n",
            "features: \"embedded_sentence2\\\\.308\"\n",
            "features: \"embedded_sentence2\\\\.309\"\n",
            "features: \"embedded_sentence2\\\\.31\"\n",
            "features: \"embedded_sentence2\\\\.310\"\n",
            "features: \"embedded_sentence2\\\\.311\"\n",
            "features: \"embedded_sentence2\\\\.312\"\n",
            "features: \"embedded_sentence2\\\\.313\"\n",
            "features: \"embedded_sentence2\\\\.314\"\n",
            "features: \"embedded_sentence2\\\\.315\"\n",
            "features: \"embedded_sentence2\\\\.316\"\n",
            "features: \"embedded_sentence2\\\\.317\"\n",
            "features: \"embedded_sentence2\\\\.318\"\n",
            "features: \"embedded_sentence2\\\\.319\"\n",
            "features: \"embedded_sentence2\\\\.32\"\n",
            "features: \"embedded_sentence2\\\\.320\"\n",
            "features: \"embedded_sentence2\\\\.321\"\n",
            "features: \"embedded_sentence2\\\\.322\"\n",
            "features: \"embedded_sentence2\\\\.323\"\n",
            "features: \"embedded_sentence2\\\\.324\"\n",
            "features: \"embedded_sentence2\\\\.325\"\n",
            "features: \"embedded_sentence2\\\\.326\"\n",
            "features: \"embedded_sentence2\\\\.327\"\n",
            "features: \"embedded_sentence2\\\\.328\"\n",
            "features: \"embedded_sentence2\\\\.329\"\n",
            "features: \"embedded_sentence2\\\\.33\"\n",
            "features: \"embedded_sentence2\\\\.330\"\n",
            "features: \"embedded_sentence2\\\\.331\"\n",
            "features: \"embedded_sentence2\\\\.332\"\n",
            "features: \"embedded_sentence2\\\\.333\"\n",
            "features: \"embedded_sentence2\\\\.334\"\n",
            "features: \"embedded_sentence2\\\\.335\"\n",
            "features: \"embedded_sentence2\\\\.336\"\n",
            "features: \"embedded_sentence2\\\\.337\"\n",
            "features: \"embedded_sentence2\\\\.338\"\n",
            "features: \"embedded_sentence2\\\\.339\"\n",
            "features: \"embedded_sentence2\\\\.34\"\n",
            "features: \"embedded_sentence2\\\\.340\"\n",
            "features: \"embedded_sentence2\\\\.341\"\n",
            "features: \"embedded_sentence2\\\\.342\"\n",
            "features: \"embedded_sentence2\\\\.343\"\n",
            "features: \"embedded_sentence2\\\\.344\"\n",
            "features: \"embedded_sentence2\\\\.345\"\n",
            "features: \"embedded_sentence2\\\\.346\"\n",
            "features: \"embedded_sentence2\\\\.347\"\n",
            "features: \"embedded_sentence2\\\\.348\"\n",
            "features: \"embedded_sentence2\\\\.349\"\n",
            "features: \"embedded_sentence2\\\\.35\"\n",
            "features: \"embedded_sentence2\\\\.350\"\n",
            "features: \"embedded_sentence2\\\\.351\"\n",
            "features: \"embedded_sentence2\\\\.352\"\n",
            "features: \"embedded_sentence2\\\\.353\"\n",
            "features: \"embedded_sentence2\\\\.354\"\n",
            "features: \"embedded_sentence2\\\\.355\"\n",
            "features: \"embedded_sentence2\\\\.356\"\n",
            "features: \"embedded_sentence2\\\\.357\"\n",
            "features: \"embedded_sentence2\\\\.358\"\n",
            "features: \"embedded_sentence2\\\\.359\"\n",
            "features: \"embedded_sentence2\\\\.36\"\n",
            "features: \"embedded_sentence2\\\\.360\"\n",
            "features: \"embedded_sentence2\\\\.361\"\n",
            "features: \"embedded_sentence2\\\\.362\"\n",
            "features: \"embedded_sentence2\\\\.363\"\n",
            "features: \"embedded_sentence2\\\\.364\"\n",
            "features: \"embedded_sentence2\\\\.365\"\n",
            "features: \"embedded_sentence2\\\\.366\"\n",
            "features: \"embedded_sentence2\\\\.367\"\n",
            "features: \"embedded_sentence2\\\\.368\"\n",
            "features: \"embedded_sentence2\\\\.369\"\n",
            "features: \"embedded_sentence2\\\\.37\"\n",
            "features: \"embedded_sentence2\\\\.370\"\n",
            "features: \"embedded_sentence2\\\\.371\"\n",
            "features: \"embedded_sentence2\\\\.372\"\n",
            "features: \"embedded_sentence2\\\\.373\"\n",
            "features: \"embedded_sentence2\\\\.374\"\n",
            "features: \"embedded_sentence2\\\\.375\"\n",
            "features: \"embedded_sentence2\\\\.376\"\n",
            "features: \"embedded_sentence2\\\\.377\"\n",
            "features: \"embedded_sentence2\\\\.378\"\n",
            "features: \"embedded_sentence2\\\\.379\"\n",
            "features: \"embedded_sentence2\\\\.38\"\n",
            "features: \"embedded_sentence2\\\\.380\"\n",
            "features: \"embedded_sentence2\\\\.381\"\n",
            "features: \"embedded_sentence2\\\\.382\"\n",
            "features: \"embedded_sentence2\\\\.383\"\n",
            "features: \"embedded_sentence2\\\\.384\"\n",
            "features: \"embedded_sentence2\\\\.385\"\n",
            "features: \"embedded_sentence2\\\\.386\"\n",
            "features: \"embedded_sentence2\\\\.387\"\n",
            "features: \"embedded_sentence2\\\\.388\"\n",
            "features: \"embedded_sentence2\\\\.389\"\n",
            "features: \"embedded_sentence2\\\\.39\"\n",
            "features: \"embedded_sentence2\\\\.390\"\n",
            "features: \"embedded_sentence2\\\\.391\"\n",
            "features: \"embedded_sentence2\\\\.392\"\n",
            "features: \"embedded_sentence2\\\\.393\"\n",
            "features: \"embedded_sentence2\\\\.394\"\n",
            "features: \"embedded_sentence2\\\\.395\"\n",
            "features: \"embedded_sentence2\\\\.396\"\n",
            "features: \"embedded_sentence2\\\\.397\"\n",
            "features: \"embedded_sentence2\\\\.398\"\n",
            "features: \"embedded_sentence2\\\\.399\"\n",
            "features: \"embedded_sentence2\\\\.4\"\n",
            "features: \"embedded_sentence2\\\\.40\"\n",
            "features: \"embedded_sentence2\\\\.400\"\n",
            "features: \"embedded_sentence2\\\\.401\"\n",
            "features: \"embedded_sentence2\\\\.402\"\n",
            "features: \"embedded_sentence2\\\\.403\"\n",
            "features: \"embedded_sentence2\\\\.404\"\n",
            "features: \"embedded_sentence2\\\\.405\"\n",
            "features: \"embedded_sentence2\\\\.406\"\n",
            "features: \"embedded_sentence2\\\\.407\"\n",
            "features: \"embedded_sentence2\\\\.408\"\n",
            "features: \"embedded_sentence2\\\\.409\"\n",
            "features: \"embedded_sentence2\\\\.41\"\n",
            "features: \"embedded_sentence2\\\\.410\"\n",
            "features: \"embedded_sentence2\\\\.411\"\n",
            "features: \"embedded_sentence2\\\\.412\"\n",
            "features: \"embedded_sentence2\\\\.413\"\n",
            "features: \"embedded_sentence2\\\\.414\"\n",
            "features: \"embedded_sentence2\\\\.415\"\n",
            "features: \"embedded_sentence2\\\\.416\"\n",
            "features: \"embedded_sentence2\\\\.417\"\n",
            "features: \"embedded_sentence2\\\\.418\"\n",
            "features: \"embedded_sentence2\\\\.419\"\n",
            "features: \"embedded_sentence2\\\\.42\"\n",
            "features: \"embedded_sentence2\\\\.420\"\n",
            "features: \"embedded_sentence2\\\\.421\"\n",
            "features: \"embedded_sentence2\\\\.422\"\n",
            "features: \"embedded_sentence2\\\\.423\"\n",
            "features: \"embedded_sentence2\\\\.424\"\n",
            "features: \"embedded_sentence2\\\\.425\"\n",
            "features: \"embedded_sentence2\\\\.426\"\n",
            "features: \"embedded_sentence2\\\\.427\"\n",
            "features: \"embedded_sentence2\\\\.428\"\n",
            "features: \"embedded_sentence2\\\\.429\"\n",
            "features: \"embedded_sentence2\\\\.43\"\n",
            "features: \"embedded_sentence2\\\\.430\"\n",
            "features: \"embedded_sentence2\\\\.431\"\n",
            "features: \"embedded_sentence2\\\\.432\"\n",
            "features: \"embedded_sentence2\\\\.433\"\n",
            "features: \"embedded_sentence2\\\\.434\"\n",
            "features: \"embedded_sentence2\\\\.435\"\n",
            "features: \"embedded_sentence2\\\\.436\"\n",
            "features: \"embedded_sentence2\\\\.437\"\n",
            "features: \"embedded_sentence2\\\\.438\"\n",
            "features: \"embedded_sentence2\\\\.439\"\n",
            "features: \"embedded_sentence2\\\\.44\"\n",
            "features: \"embedded_sentence2\\\\.440\"\n",
            "features: \"embedded_sentence2\\\\.441\"\n",
            "features: \"embedded_sentence2\\\\.442\"\n",
            "features: \"embedded_sentence2\\\\.443\"\n",
            "features: \"embedded_sentence2\\\\.444\"\n",
            "features: \"embedded_sentence2\\\\.445\"\n",
            "features: \"embedded_sentence2\\\\.446\"\n",
            "features: \"embedded_sentence2\\\\.447\"\n",
            "features: \"embedded_sentence2\\\\.448\"\n",
            "features: \"embedded_sentence2\\\\.449\"\n",
            "features: \"embedded_sentence2\\\\.45\"\n",
            "features: \"embedded_sentence2\\\\.450\"\n",
            "features: \"embedded_sentence2\\\\.451\"\n",
            "features: \"embedded_sentence2\\\\.452\"\n",
            "features: \"embedded_sentence2\\\\.453\"\n",
            "features: \"embedded_sentence2\\\\.454\"\n",
            "features: \"embedded_sentence2\\\\.455\"\n",
            "features: \"embedded_sentence2\\\\.456\"\n",
            "features: \"embedded_sentence2\\\\.457\"\n",
            "features: \"embedded_sentence2\\\\.458\"\n",
            "features: \"embedded_sentence2\\\\.459\"\n",
            "features: \"embedded_sentence2\\\\.46\"\n",
            "features: \"embedded_sentence2\\\\.460\"\n",
            "features: \"embedded_sentence2\\\\.461\"\n",
            "features: \"embedded_sentence2\\\\.462\"\n",
            "features: \"embedded_sentence2\\\\.463\"\n",
            "features: \"embedded_sentence2\\\\.464\"\n",
            "features: \"embedded_sentence2\\\\.465\"\n",
            "features: \"embedded_sentence2\\\\.466\"\n",
            "features: \"embedded_sentence2\\\\.467\"\n",
            "features: \"embedded_sentence2\\\\.468\"\n",
            "features: \"embedded_sentence2\\\\.469\"\n",
            "features: \"embedded_sentence2\\\\.47\"\n",
            "features: \"embedded_sentence2\\\\.470\"\n",
            "features: \"embedded_sentence2\\\\.471\"\n",
            "features: \"embedded_sentence2\\\\.472\"\n",
            "features: \"embedded_sentence2\\\\.473\"\n",
            "features: \"embedded_sentence2\\\\.474\"\n",
            "features: \"embedded_sentence2\\\\.475\"\n",
            "features: \"embedded_sentence2\\\\.476\"\n",
            "features: \"embedded_sentence2\\\\.477\"\n",
            "features: \"embedded_sentence2\\\\.478\"\n",
            "features: \"embedded_sentence2\\\\.479\"\n",
            "features: \"embedded_sentence2\\\\.48\"\n",
            "features: \"embedded_sentence2\\\\.480\"\n",
            "features: \"embedded_sentence2\\\\.481\"\n",
            "features: \"embedded_sentence2\\\\.482\"\n",
            "features: \"embedded_sentence2\\\\.483\"\n",
            "features: \"embedded_sentence2\\\\.484\"\n",
            "features: \"embedded_sentence2\\\\.485\"\n",
            "features: \"embedded_sentence2\\\\.486\"\n",
            "features: \"embedded_sentence2\\\\.487\"\n",
            "features: \"embedded_sentence2\\\\.488\"\n",
            "features: \"embedded_sentence2\\\\.489\"\n",
            "features: \"embedded_sentence2\\\\.49\"\n",
            "features: \"embedded_sentence2\\\\.490\"\n",
            "features: \"embedded_sentence2\\\\.491\"\n",
            "features: \"embedded_sentence2\\\\.492\"\n",
            "features: \"embedded_sentence2\\\\.493\"\n",
            "features: \"embedded_sentence2\\\\.494\"\n",
            "features: \"embedded_sentence2\\\\.495\"\n",
            "features: \"embedded_sentence2\\\\.496\"\n",
            "features: \"embedded_sentence2\\\\.497\"\n",
            "features: \"embedded_sentence2\\\\.498\"\n",
            "features: \"embedded_sentence2\\\\.499\"\n",
            "features: \"embedded_sentence2\\\\.5\"\n",
            "features: \"embedded_sentence2\\\\.50\"\n",
            "features: \"embedded_sentence2\\\\.500\"\n",
            "features: \"embedded_sentence2\\\\.501\"\n",
            "features: \"embedded_sentence2\\\\.502\"\n",
            "features: \"embedded_sentence2\\\\.503\"\n",
            "features: \"embedded_sentence2\\\\.504\"\n",
            "features: \"embedded_sentence2\\\\.505\"\n",
            "features: \"embedded_sentence2\\\\.506\"\n",
            "features: \"embedded_sentence2\\\\.507\"\n",
            "features: \"embedded_sentence2\\\\.508\"\n",
            "features: \"embedded_sentence2\\\\.509\"\n",
            "features: \"embedded_sentence2\\\\.51\"\n",
            "features: \"embedded_sentence2\\\\.510\"\n",
            "features: \"embedded_sentence2\\\\.511\"\n",
            "features: \"embedded_sentence2\\\\.52\"\n",
            "features: \"embedded_sentence2\\\\.53\"\n",
            "features: \"embedded_sentence2\\\\.54\"\n",
            "features: \"embedded_sentence2\\\\.55\"\n",
            "features: \"embedded_sentence2\\\\.56\"\n",
            "features: \"embedded_sentence2\\\\.57\"\n",
            "features: \"embedded_sentence2\\\\.58\"\n",
            "features: \"embedded_sentence2\\\\.59\"\n",
            "features: \"embedded_sentence2\\\\.6\"\n",
            "features: \"embedded_sentence2\\\\.60\"\n",
            "features: \"embedded_sentence2\\\\.61\"\n",
            "features: \"embedded_sentence2\\\\.62\"\n",
            "features: \"embedded_sentence2\\\\.63\"\n",
            "features: \"embedded_sentence2\\\\.64\"\n",
            "features: \"embedded_sentence2\\\\.65\"\n",
            "features: \"embedded_sentence2\\\\.66\"\n",
            "features: \"embedded_sentence2\\\\.67\"\n",
            "features: \"embedded_sentence2\\\\.68\"\n",
            "features: \"embedded_sentence2\\\\.69\"\n",
            "features: \"embedded_sentence2\\\\.7\"\n",
            "features: \"embedded_sentence2\\\\.70\"\n",
            "features: \"embedded_sentence2\\\\.71\"\n",
            "features: \"embedded_sentence2\\\\.72\"\n",
            "features: \"embedded_sentence2\\\\.73\"\n",
            "features: \"embedded_sentence2\\\\.74\"\n",
            "features: \"embedded_sentence2\\\\.75\"\n",
            "features: \"embedded_sentence2\\\\.76\"\n",
            "features: \"embedded_sentence2\\\\.77\"\n",
            "features: \"embedded_sentence2\\\\.78\"\n",
            "features: \"embedded_sentence2\\\\.79\"\n",
            "features: \"embedded_sentence2\\\\.8\"\n",
            "features: \"embedded_sentence2\\\\.80\"\n",
            "features: \"embedded_sentence2\\\\.81\"\n",
            "features: \"embedded_sentence2\\\\.82\"\n",
            "features: \"embedded_sentence2\\\\.83\"\n",
            "features: \"embedded_sentence2\\\\.84\"\n",
            "features: \"embedded_sentence2\\\\.85\"\n",
            "features: \"embedded_sentence2\\\\.86\"\n",
            "features: \"embedded_sentence2\\\\.87\"\n",
            "features: \"embedded_sentence2\\\\.88\"\n",
            "features: \"embedded_sentence2\\\\.89\"\n",
            "features: \"embedded_sentence2\\\\.9\"\n",
            "features: \"embedded_sentence2\\\\.90\"\n",
            "features: \"embedded_sentence2\\\\.91\"\n",
            "features: \"embedded_sentence2\\\\.92\"\n",
            "features: \"embedded_sentence2\\\\.93\"\n",
            "features: \"embedded_sentence2\\\\.94\"\n",
            "features: \"embedded_sentence2\\\\.95\"\n",
            "features: \"embedded_sentence2\\\\.96\"\n",
            "features: \"embedded_sentence2\\\\.97\"\n",
            "features: \"embedded_sentence2\\\\.98\"\n",
            "features: \"embedded_sentence2\\\\.99\"\n",
            "features: \"embedded_sentence3\\\\.0\"\n",
            "features: \"embedded_sentence3\\\\.1\"\n",
            "features: \"embedded_sentence3\\\\.10\"\n",
            "features: \"embedded_sentence3\\\\.100\"\n",
            "features: \"embedded_sentence3\\\\.101\"\n",
            "features: \"embedded_sentence3\\\\.102\"\n",
            "features: \"embedded_sentence3\\\\.103\"\n",
            "features: \"embedded_sentence3\\\\.104\"\n",
            "features: \"embedded_sentence3\\\\.105\"\n",
            "features: \"embedded_sentence3\\\\.106\"\n",
            "features: \"embedded_sentence3\\\\.107\"\n",
            "features: \"embedded_sentence3\\\\.108\"\n",
            "features: \"embedded_sentence3\\\\.109\"\n",
            "features: \"embedded_sentence3\\\\.11\"\n",
            "features: \"embedded_sentence3\\\\.110\"\n",
            "features: \"embedded_sentence3\\\\.111\"\n",
            "features: \"embedded_sentence3\\\\.112\"\n",
            "features: \"embedded_sentence3\\\\.113\"\n",
            "features: \"embedded_sentence3\\\\.114\"\n",
            "features: \"embedded_sentence3\\\\.115\"\n",
            "features: \"embedded_sentence3\\\\.116\"\n",
            "features: \"embedded_sentence3\\\\.117\"\n",
            "features: \"embedded_sentence3\\\\.118\"\n",
            "features: \"embedded_sentence3\\\\.119\"\n",
            "features: \"embedded_sentence3\\\\.12\"\n",
            "features: \"embedded_sentence3\\\\.120\"\n",
            "features: \"embedded_sentence3\\\\.121\"\n",
            "features: \"embedded_sentence3\\\\.122\"\n",
            "features: \"embedded_sentence3\\\\.123\"\n",
            "features: \"embedded_sentence3\\\\.124\"\n",
            "features: \"embedded_sentence3\\\\.125\"\n",
            "features: \"embedded_sentence3\\\\.126\"\n",
            "features: \"embedded_sentence3\\\\.127\"\n",
            "features: \"embedded_sentence3\\\\.128\"\n",
            "features: \"embedded_sentence3\\\\.129\"\n",
            "features: \"embedded_sentence3\\\\.13\"\n",
            "features: \"embedded_sentence3\\\\.130\"\n",
            "features: \"embedded_sentence3\\\\.131\"\n",
            "features: \"embedded_sentence3\\\\.132\"\n",
            "features: \"embedded_sentence3\\\\.133\"\n",
            "features: \"embedded_sentence3\\\\.134\"\n",
            "features: \"embedded_sentence3\\\\.135\"\n",
            "features: \"embedded_sentence3\\\\.136\"\n",
            "features: \"embedded_sentence3\\\\.137\"\n",
            "features: \"embedded_sentence3\\\\.138\"\n",
            "features: \"embedded_sentence3\\\\.139\"\n",
            "features: \"embedded_sentence3\\\\.14\"\n",
            "features: \"embedded_sentence3\\\\.140\"\n",
            "features: \"embedded_sentence3\\\\.141\"\n",
            "features: \"embedded_sentence3\\\\.142\"\n",
            "features: \"embedded_sentence3\\\\.143\"\n",
            "features: \"embedded_sentence3\\\\.144\"\n",
            "features: \"embedded_sentence3\\\\.145\"\n",
            "features: \"embedded_sentence3\\\\.146\"\n",
            "features: \"embedded_sentence3\\\\.147\"\n",
            "features: \"embedded_sentence3\\\\.148\"\n",
            "features: \"embedded_sentence3\\\\.149\"\n",
            "features: \"embedded_sentence3\\\\.15\"\n",
            "features: \"embedded_sentence3\\\\.150\"\n",
            "features: \"embedded_sentence3\\\\.151\"\n",
            "features: \"embedded_sentence3\\\\.152\"\n",
            "features: \"embedded_sentence3\\\\.153\"\n",
            "features: \"embedded_sentence3\\\\.154\"\n",
            "features: \"embedded_sentence3\\\\.155\"\n",
            "features: \"embedded_sentence3\\\\.156\"\n",
            "features: \"embedded_sentence3\\\\.157\"\n",
            "features: \"embedded_sentence3\\\\.158\"\n",
            "features: \"embedded_sentence3\\\\.159\"\n",
            "features: \"embedded_sentence3\\\\.16\"\n",
            "features: \"embedded_sentence3\\\\.160\"\n",
            "features: \"embedded_sentence3\\\\.161\"\n",
            "features: \"embedded_sentence3\\\\.162\"\n",
            "features: \"embedded_sentence3\\\\.163\"\n",
            "features: \"embedded_sentence3\\\\.164\"\n",
            "features: \"embedded_sentence3\\\\.165\"\n",
            "features: \"embedded_sentence3\\\\.166\"\n",
            "features: \"embedded_sentence3\\\\.167\"\n",
            "features: \"embedded_sentence3\\\\.168\"\n",
            "features: \"embedded_sentence3\\\\.169\"\n",
            "features: \"embedded_sentence3\\\\.17\"\n",
            "features: \"embedded_sentence3\\\\.170\"\n",
            "features: \"embedded_sentence3\\\\.171\"\n",
            "features: \"embedded_sentence3\\\\.172\"\n",
            "features: \"embedded_sentence3\\\\.173\"\n",
            "features: \"embedded_sentence3\\\\.174\"\n",
            "features: \"embedded_sentence3\\\\.175\"\n",
            "features: \"embedded_sentence3\\\\.176\"\n",
            "features: \"embedded_sentence3\\\\.177\"\n",
            "features: \"embedded_sentence3\\\\.178\"\n",
            "features: \"embedded_sentence3\\\\.179\"\n",
            "features: \"embedded_sentence3\\\\.18\"\n",
            "features: \"embedded_sentence3\\\\.180\"\n",
            "features: \"embedded_sentence3\\\\.181\"\n",
            "features: \"embedded_sentence3\\\\.182\"\n",
            "features: \"embedded_sentence3\\\\.183\"\n",
            "features: \"embedded_sentence3\\\\.184\"\n",
            "features: \"embedded_sentence3\\\\.185\"\n",
            "features: \"embedded_sentence3\\\\.186\"\n",
            "features: \"embedded_sentence3\\\\.187\"\n",
            "features: \"embedded_sentence3\\\\.188\"\n",
            "features: \"embedded_sentence3\\\\.189\"\n",
            "features: \"embedded_sentence3\\\\.19\"\n",
            "features: \"embedded_sentence3\\\\.190\"\n",
            "features: \"embedded_sentence3\\\\.191\"\n",
            "features: \"embedded_sentence3\\\\.192\"\n",
            "features: \"embedded_sentence3\\\\.193\"\n",
            "features: \"embedded_sentence3\\\\.194\"\n",
            "features: \"embedded_sentence3\\\\.195\"\n",
            "features: \"embedded_sentence3\\\\.196\"\n",
            "features: \"embedded_sentence3\\\\.197\"\n",
            "features: \"embedded_sentence3\\\\.198\"\n",
            "features: \"embedded_sentence3\\\\.199\"\n",
            "features: \"embedded_sentence3\\\\.2\"\n",
            "features: \"embedded_sentence3\\\\.20\"\n",
            "features: \"embedded_sentence3\\\\.200\"\n",
            "features: \"embedded_sentence3\\\\.201\"\n",
            "features: \"embedded_sentence3\\\\.202\"\n",
            "features: \"embedded_sentence3\\\\.203\"\n",
            "features: \"embedded_sentence3\\\\.204\"\n",
            "features: \"embedded_sentence3\\\\.205\"\n",
            "features: \"embedded_sentence3\\\\.206\"\n",
            "features: \"embedded_sentence3\\\\.207\"\n",
            "features: \"embedded_sentence3\\\\.208\"\n",
            "features: \"embedded_sentence3\\\\.209\"\n",
            "features: \"embedded_sentence3\\\\.21\"\n",
            "features: \"embedded_sentence3\\\\.210\"\n",
            "features: \"embedded_sentence3\\\\.211\"\n",
            "features: \"embedded_sentence3\\\\.212\"\n",
            "features: \"embedded_sentence3\\\\.213\"\n",
            "features: \"embedded_sentence3\\\\.214\"\n",
            "features: \"embedded_sentence3\\\\.215\"\n",
            "features: \"embedded_sentence3\\\\.216\"\n",
            "features: \"embedded_sentence3\\\\.217\"\n",
            "features: \"embedded_sentence3\\\\.218\"\n",
            "features: \"embedded_sentence3\\\\.219\"\n",
            "features: \"embedded_sentence3\\\\.22\"\n",
            "features: \"embedded_sentence3\\\\.220\"\n",
            "features: \"embedded_sentence3\\\\.221\"\n",
            "features: \"embedded_sentence3\\\\.222\"\n",
            "features: \"embedded_sentence3\\\\.223\"\n",
            "features: \"embedded_sentence3\\\\.224\"\n",
            "features: \"embedded_sentence3\\\\.225\"\n",
            "features: \"embedded_sentence3\\\\.226\"\n",
            "features: \"embedded_sentence3\\\\.227\"\n",
            "features: \"embedded_sentence3\\\\.228\"\n",
            "features: \"embedded_sentence3\\\\.229\"\n",
            "features: \"embedded_sentence3\\\\.23\"\n",
            "features: \"embedded_sentence3\\\\.230\"\n",
            "features: \"embedded_sentence3\\\\.231\"\n",
            "features: \"embedded_sentence3\\\\.232\"\n",
            "features: \"embedded_sentence3\\\\.233\"\n",
            "features: \"embedded_sentence3\\\\.234\"\n",
            "features: \"embedded_sentence3\\\\.235\"\n",
            "features: \"embedded_sentence3\\\\.236\"\n",
            "features: \"embedded_sentence3\\\\.237\"\n",
            "features: \"embedded_sentence3\\\\.238\"\n",
            "features: \"embedded_sentence3\\\\.239\"\n",
            "features: \"embedded_sentence3\\\\.24\"\n",
            "features: \"embedded_sentence3\\\\.240\"\n",
            "features: \"embedded_sentence3\\\\.241\"\n",
            "features: \"embedded_sentence3\\\\.242\"\n",
            "features: \"embedded_sentence3\\\\.243\"\n",
            "features: \"embedded_sentence3\\\\.244\"\n",
            "features: \"embedded_sentence3\\\\.245\"\n",
            "features: \"embedded_sentence3\\\\.246\"\n",
            "features: \"embedded_sentence3\\\\.247\"\n",
            "features: \"embedded_sentence3\\\\.248\"\n",
            "features: \"embedded_sentence3\\\\.249\"\n",
            "features: \"embedded_sentence3\\\\.25\"\n",
            "features: \"embedded_sentence3\\\\.250\"\n",
            "features: \"embedded_sentence3\\\\.251\"\n",
            "features: \"embedded_sentence3\\\\.252\"\n",
            "features: \"embedded_sentence3\\\\.253\"\n",
            "features: \"embedded_sentence3\\\\.254\"\n",
            "features: \"embedded_sentence3\\\\.255\"\n",
            "features: \"embedded_sentence3\\\\.256\"\n",
            "features: \"embedded_sentence3\\\\.257\"\n",
            "features: \"embedded_sentence3\\\\.258\"\n",
            "features: \"embedded_sentence3\\\\.259\"\n",
            "features: \"embedded_sentence3\\\\.26\"\n",
            "features: \"embedded_sentence3\\\\.260\"\n",
            "features: \"embedded_sentence3\\\\.261\"\n",
            "features: \"embedded_sentence3\\\\.262\"\n",
            "features: \"embedded_sentence3\\\\.263\"\n",
            "features: \"embedded_sentence3\\\\.264\"\n",
            "features: \"embedded_sentence3\\\\.265\"\n",
            "features: \"embedded_sentence3\\\\.266\"\n",
            "features: \"embedded_sentence3\\\\.267\"\n",
            "features: \"embedded_sentence3\\\\.268\"\n",
            "features: \"embedded_sentence3\\\\.269\"\n",
            "features: \"embedded_sentence3\\\\.27\"\n",
            "features: \"embedded_sentence3\\\\.270\"\n",
            "features: \"embedded_sentence3\\\\.271\"\n",
            "features: \"embedded_sentence3\\\\.272\"\n",
            "features: \"embedded_sentence3\\\\.273\"\n",
            "features: \"embedded_sentence3\\\\.274\"\n",
            "features: \"embedded_sentence3\\\\.275\"\n",
            "features: \"embedded_sentence3\\\\.276\"\n",
            "features: \"embedded_sentence3\\\\.277\"\n",
            "features: \"embedded_sentence3\\\\.278\"\n",
            "features: \"embedded_sentence3\\\\.279\"\n",
            "features: \"embedded_sentence3\\\\.28\"\n",
            "features: \"embedded_sentence3\\\\.280\"\n",
            "features: \"embedded_sentence3\\\\.281\"\n",
            "features: \"embedded_sentence3\\\\.282\"\n",
            "features: \"embedded_sentence3\\\\.283\"\n",
            "features: \"embedded_sentence3\\\\.284\"\n",
            "features: \"embedded_sentence3\\\\.285\"\n",
            "features: \"embedded_sentence3\\\\.286\"\n",
            "features: \"embedded_sentence3\\\\.287\"\n",
            "features: \"embedded_sentence3\\\\.288\"\n",
            "features: \"embedded_sentence3\\\\.289\"\n",
            "features: \"embedded_sentence3\\\\.29\"\n",
            "features: \"embedded_sentence3\\\\.290\"\n",
            "features: \"embedded_sentence3\\\\.291\"\n",
            "features: \"embedded_sentence3\\\\.292\"\n",
            "features: \"embedded_sentence3\\\\.293\"\n",
            "features: \"embedded_sentence3\\\\.294\"\n",
            "features: \"embedded_sentence3\\\\.295\"\n",
            "features: \"embedded_sentence3\\\\.296\"\n",
            "features: \"embedded_sentence3\\\\.297\"\n",
            "features: \"embedded_sentence3\\\\.298\"\n",
            "features: \"embedded_sentence3\\\\.299\"\n",
            "features: \"embedded_sentence3\\\\.3\"\n",
            "features: \"embedded_sentence3\\\\.30\"\n",
            "features: \"embedded_sentence3\\\\.300\"\n",
            "features: \"embedded_sentence3\\\\.301\"\n",
            "features: \"embedded_sentence3\\\\.302\"\n",
            "features: \"embedded_sentence3\\\\.303\"\n",
            "features: \"embedded_sentence3\\\\.304\"\n",
            "features: \"embedded_sentence3\\\\.305\"\n",
            "features: \"embedded_sentence3\\\\.306\"\n",
            "features: \"embedded_sentence3\\\\.307\"\n",
            "features: \"embedded_sentence3\\\\.308\"\n",
            "features: \"embedded_sentence3\\\\.309\"\n",
            "features: \"embedded_sentence3\\\\.31\"\n",
            "features: \"embedded_sentence3\\\\.310\"\n",
            "features: \"embedded_sentence3\\\\.311\"\n",
            "features: \"embedded_sentence3\\\\.312\"\n",
            "features: \"embedded_sentence3\\\\.313\"\n",
            "features: \"embedded_sentence3\\\\.314\"\n",
            "features: \"embedded_sentence3\\\\.315\"\n",
            "features: \"embedded_sentence3\\\\.316\"\n",
            "features: \"embedded_sentence3\\\\.317\"\n",
            "features: \"embedded_sentence3\\\\.318\"\n",
            "features: \"embedded_sentence3\\\\.319\"\n",
            "features: \"embedded_sentence3\\\\.32\"\n",
            "features: \"embedded_sentence3\\\\.320\"\n",
            "features: \"embedded_sentence3\\\\.321\"\n",
            "features: \"embedded_sentence3\\\\.322\"\n",
            "features: \"embedded_sentence3\\\\.323\"\n",
            "features: \"embedded_sentence3\\\\.324\"\n",
            "features: \"embedded_sentence3\\\\.325\"\n",
            "features: \"embedded_sentence3\\\\.326\"\n",
            "features: \"embedded_sentence3\\\\.327\"\n",
            "features: \"embedded_sentence3\\\\.328\"\n",
            "features: \"embedded_sentence3\\\\.329\"\n",
            "features: \"embedded_sentence3\\\\.33\"\n",
            "features: \"embedded_sentence3\\\\.330\"\n",
            "features: \"embedded_sentence3\\\\.331\"\n",
            "features: \"embedded_sentence3\\\\.332\"\n",
            "features: \"embedded_sentence3\\\\.333\"\n",
            "features: \"embedded_sentence3\\\\.334\"\n",
            "features: \"embedded_sentence3\\\\.335\"\n",
            "features: \"embedded_sentence3\\\\.336\"\n",
            "features: \"embedded_sentence3\\\\.337\"\n",
            "features: \"embedded_sentence3\\\\.338\"\n",
            "features: \"embedded_sentence3\\\\.339\"\n",
            "features: \"embedded_sentence3\\\\.34\"\n",
            "features: \"embedded_sentence3\\\\.340\"\n",
            "features: \"embedded_sentence3\\\\.341\"\n",
            "features: \"embedded_sentence3\\\\.342\"\n",
            "features: \"embedded_sentence3\\\\.343\"\n",
            "features: \"embedded_sentence3\\\\.344\"\n",
            "features: \"embedded_sentence3\\\\.345\"\n",
            "features: \"embedded_sentence3\\\\.346\"\n",
            "features: \"embedded_sentence3\\\\.347\"\n",
            "features: \"embedded_sentence3\\\\.348\"\n",
            "features: \"embedded_sentence3\\\\.349\"\n",
            "features: \"embedded_sentence3\\\\.35\"\n",
            "features: \"embedded_sentence3\\\\.350\"\n",
            "features: \"embedded_sentence3\\\\.351\"\n",
            "features: \"embedded_sentence3\\\\.352\"\n",
            "features: \"embedded_sentence3\\\\.353\"\n",
            "features: \"embedded_sentence3\\\\.354\"\n",
            "features: \"embedded_sentence3\\\\.355\"\n",
            "features: \"embedded_sentence3\\\\.356\"\n",
            "features: \"embedded_sentence3\\\\.357\"\n",
            "features: \"embedded_sentence3\\\\.358\"\n",
            "features: \"embedded_sentence3\\\\.359\"\n",
            "features: \"embedded_sentence3\\\\.36\"\n",
            "features: \"embedded_sentence3\\\\.360\"\n",
            "features: \"embedded_sentence3\\\\.361\"\n",
            "features: \"embedded_sentence3\\\\.362\"\n",
            "features: \"embedded_sentence3\\\\.363\"\n",
            "features: \"embedded_sentence3\\\\.364\"\n",
            "features: \"embedded_sentence3\\\\.365\"\n",
            "features: \"embedded_sentence3\\\\.366\"\n",
            "features: \"embedded_sentence3\\\\.367\"\n",
            "features: \"embedded_sentence3\\\\.368\"\n",
            "features: \"embedded_sentence3\\\\.369\"\n",
            "features: \"embedded_sentence3\\\\.37\"\n",
            "features: \"embedded_sentence3\\\\.370\"\n",
            "features: \"embedded_sentence3\\\\.371\"\n",
            "features: \"embedded_sentence3\\\\.372\"\n",
            "features: \"embedded_sentence3\\\\.373\"\n",
            "features: \"embedded_sentence3\\\\.374\"\n",
            "features: \"embedded_sentence3\\\\.375\"\n",
            "features: \"embedded_sentence3\\\\.376\"\n",
            "features: \"embedded_sentence3\\\\.377\"\n",
            "features: \"embedded_sentence3\\\\.378\"\n",
            "features: \"embedded_sentence3\\\\.379\"\n",
            "features: \"embedded_sentence3\\\\.38\"\n",
            "features: \"embedded_sentence3\\\\.380\"\n",
            "features: \"embedded_sentence3\\\\.381\"\n",
            "features: \"embedded_sentence3\\\\.382\"\n",
            "features: \"embedded_sentence3\\\\.383\"\n",
            "features: \"embedded_sentence3\\\\.384\"\n",
            "features: \"embedded_sentence3\\\\.385\"\n",
            "features: \"embedded_sentence3\\\\.386\"\n",
            "features: \"embedded_sentence3\\\\.387\"\n",
            "features: \"embedded_sentence3\\\\.388\"\n",
            "features: \"embedded_sentence3\\\\.389\"\n",
            "features: \"embedded_sentence3\\\\.39\"\n",
            "features: \"embedded_sentence3\\\\.390\"\n",
            "features: \"embedded_sentence3\\\\.391\"\n",
            "features: \"embedded_sentence3\\\\.392\"\n",
            "features: \"embedded_sentence3\\\\.393\"\n",
            "features: \"embedded_sentence3\\\\.394\"\n",
            "features: \"embedded_sentence3\\\\.395\"\n",
            "features: \"embedded_sentence3\\\\.396\"\n",
            "features: \"embedded_sentence3\\\\.397\"\n",
            "features: \"embedded_sentence3\\\\.398\"\n",
            "features: \"embedded_sentence3\\\\.399\"\n",
            "features: \"embedded_sentence3\\\\.4\"\n",
            "features: \"embedded_sentence3\\\\.40\"\n",
            "features: \"embedded_sentence3\\\\.400\"\n",
            "features: \"embedded_sentence3\\\\.401\"\n",
            "features: \"embedded_sentence3\\\\.402\"\n",
            "features: \"embedded_sentence3\\\\.403\"\n",
            "features: \"embedded_sentence3\\\\.404\"\n",
            "features: \"embedded_sentence3\\\\.405\"\n",
            "features: \"embedded_sentence3\\\\.406\"\n",
            "features: \"embedded_sentence3\\\\.407\"\n",
            "features: \"embedded_sentence3\\\\.408\"\n",
            "features: \"embedded_sentence3\\\\.409\"\n",
            "features: \"embedded_sentence3\\\\.41\"\n",
            "features: \"embedded_sentence3\\\\.410\"\n",
            "features: \"embedded_sentence3\\\\.411\"\n",
            "features: \"embedded_sentence3\\\\.412\"\n",
            "features: \"embedded_sentence3\\\\.413\"\n",
            "features: \"embedded_sentence3\\\\.414\"\n",
            "features: \"embedded_sentence3\\\\.415\"\n",
            "features: \"embedded_sentence3\\\\.416\"\n",
            "features: \"embedded_sentence3\\\\.417\"\n",
            "features: \"embedded_sentence3\\\\.418\"\n",
            "features: \"embedded_sentence3\\\\.419\"\n",
            "features: \"embedded_sentence3\\\\.42\"\n",
            "features: \"embedded_sentence3\\\\.420\"\n",
            "features: \"embedded_sentence3\\\\.421\"\n",
            "features: \"embedded_sentence3\\\\.422\"\n",
            "features: \"embedded_sentence3\\\\.423\"\n",
            "features: \"embedded_sentence3\\\\.424\"\n",
            "features: \"embedded_sentence3\\\\.425\"\n",
            "features: \"embedded_sentence3\\\\.426\"\n",
            "features: \"embedded_sentence3\\\\.427\"\n",
            "features: \"embedded_sentence3\\\\.428\"\n",
            "features: \"embedded_sentence3\\\\.429\"\n",
            "features: \"embedded_sentence3\\\\.43\"\n",
            "features: \"embedded_sentence3\\\\.430\"\n",
            "features: \"embedded_sentence3\\\\.431\"\n",
            "features: \"embedded_sentence3\\\\.432\"\n",
            "features: \"embedded_sentence3\\\\.433\"\n",
            "features: \"embedded_sentence3\\\\.434\"\n",
            "features: \"embedded_sentence3\\\\.435\"\n",
            "features: \"embedded_sentence3\\\\.436\"\n",
            "features: \"embedded_sentence3\\\\.437\"\n",
            "features: \"embedded_sentence3\\\\.438\"\n",
            "features: \"embedded_sentence3\\\\.439\"\n",
            "features: \"embedded_sentence3\\\\.44\"\n",
            "features: \"embedded_sentence3\\\\.440\"\n",
            "features: \"embedded_sentence3\\\\.441\"\n",
            "features: \"embedded_sentence3\\\\.442\"\n",
            "features: \"embedded_sentence3\\\\.443\"\n",
            "features: \"embedded_sentence3\\\\.444\"\n",
            "features: \"embedded_sentence3\\\\.445\"\n",
            "features: \"embedded_sentence3\\\\.446\"\n",
            "features: \"embedded_sentence3\\\\.447\"\n",
            "features: \"embedded_sentence3\\\\.448\"\n",
            "features: \"embedded_sentence3\\\\.449\"\n",
            "features: \"embedded_sentence3\\\\.45\"\n",
            "features: \"embedded_sentence3\\\\.450\"\n",
            "features: \"embedded_sentence3\\\\.451\"\n",
            "features: \"embedded_sentence3\\\\.452\"\n",
            "features: \"embedded_sentence3\\\\.453\"\n",
            "features: \"embedded_sentence3\\\\.454\"\n",
            "features: \"embedded_sentence3\\\\.455\"\n",
            "features: \"embedded_sentence3\\\\.456\"\n",
            "features: \"embedded_sentence3\\\\.457\"\n",
            "features: \"embedded_sentence3\\\\.458\"\n",
            "features: \"embedded_sentence3\\\\.459\"\n",
            "features: \"embedded_sentence3\\\\.46\"\n",
            "features: \"embedded_sentence3\\\\.460\"\n",
            "features: \"embedded_sentence3\\\\.461\"\n",
            "features: \"embedded_sentence3\\\\.462\"\n",
            "features: \"embedded_sentence3\\\\.463\"\n",
            "features: \"embedded_sentence3\\\\.464\"\n",
            "features: \"embedded_sentence3\\\\.465\"\n",
            "features: \"embedded_sentence3\\\\.466\"\n",
            "features: \"embedded_sentence3\\\\.467\"\n",
            "features: \"embedded_sentence3\\\\.468\"\n",
            "features: \"embedded_sentence3\\\\.469\"\n",
            "features: \"embedded_sentence3\\\\.47\"\n",
            "features: \"embedded_sentence3\\\\.470\"\n",
            "features: \"embedded_sentence3\\\\.471\"\n",
            "features: \"embedded_sentence3\\\\.472\"\n",
            "features: \"embedded_sentence3\\\\.473\"\n",
            "features: \"embedded_sentence3\\\\.474\"\n",
            "features: \"embedded_sentence3\\\\.475\"\n",
            "features: \"embedded_sentence3\\\\.476\"\n",
            "features: \"embedded_sentence3\\\\.477\"\n",
            "features: \"embedded_sentence3\\\\.478\"\n",
            "features: \"embedded_sentence3\\\\.479\"\n",
            "features: \"embedded_sentence3\\\\.48\"\n",
            "features: \"embedded_sentence3\\\\.480\"\n",
            "features: \"embedded_sentence3\\\\.481\"\n",
            "features: \"embedded_sentence3\\\\.482\"\n",
            "features: \"embedded_sentence3\\\\.483\"\n",
            "features: \"embedded_sentence3\\\\.484\"\n",
            "features: \"embedded_sentence3\\\\.485\"\n",
            "features: \"embedded_sentence3\\\\.486\"\n",
            "features: \"embedded_sentence3\\\\.487\"\n",
            "features: \"embedded_sentence3\\\\.488\"\n",
            "features: \"embedded_sentence3\\\\.489\"\n",
            "features: \"embedded_sentence3\\\\.49\"\n",
            "features: \"embedded_sentence3\\\\.490\"\n",
            "features: \"embedded_sentence3\\\\.491\"\n",
            "features: \"embedded_sentence3\\\\.492\"\n",
            "features: \"embedded_sentence3\\\\.493\"\n",
            "features: \"embedded_sentence3\\\\.494\"\n",
            "features: \"embedded_sentence3\\\\.495\"\n",
            "features: \"embedded_sentence3\\\\.496\"\n",
            "features: \"embedded_sentence3\\\\.497\"\n",
            "features: \"embedded_sentence3\\\\.498\"\n",
            "features: \"embedded_sentence3\\\\.499\"\n",
            "features: \"embedded_sentence3\\\\.5\"\n",
            "features: \"embedded_sentence3\\\\.50\"\n",
            "features: \"embedded_sentence3\\\\.500\"\n",
            "features: \"embedded_sentence3\\\\.501\"\n",
            "features: \"embedded_sentence3\\\\.502\"\n",
            "features: \"embedded_sentence3\\\\.503\"\n",
            "features: \"embedded_sentence3\\\\.504\"\n",
            "features: \"embedded_sentence3\\\\.505\"\n",
            "features: \"embedded_sentence3\\\\.506\"\n",
            "features: \"embedded_sentence3\\\\.507\"\n",
            "features: \"embedded_sentence3\\\\.508\"\n",
            "features: \"embedded_sentence3\\\\.509\"\n",
            "features: \"embedded_sentence3\\\\.51\"\n",
            "features: \"embedded_sentence3\\\\.510\"\n",
            "features: \"embedded_sentence3\\\\.511\"\n",
            "features: \"embedded_sentence3\\\\.52\"\n",
            "features: \"embedded_sentence3\\\\.53\"\n",
            "features: \"embedded_sentence3\\\\.54\"\n",
            "features: \"embedded_sentence3\\\\.55\"\n",
            "features: \"embedded_sentence3\\\\.56\"\n",
            "features: \"embedded_sentence3\\\\.57\"\n",
            "features: \"embedded_sentence3\\\\.58\"\n",
            "features: \"embedded_sentence3\\\\.59\"\n",
            "features: \"embedded_sentence3\\\\.6\"\n",
            "features: \"embedded_sentence3\\\\.60\"\n",
            "features: \"embedded_sentence3\\\\.61\"\n",
            "features: \"embedded_sentence3\\\\.62\"\n",
            "features: \"embedded_sentence3\\\\.63\"\n",
            "features: \"embedded_sentence3\\\\.64\"\n",
            "features: \"embedded_sentence3\\\\.65\"\n",
            "features: \"embedded_sentence3\\\\.66\"\n",
            "features: \"embedded_sentence3\\\\.67\"\n",
            "features: \"embedded_sentence3\\\\.68\"\n",
            "features: \"embedded_sentence3\\\\.69\"\n",
            "features: \"embedded_sentence3\\\\.7\"\n",
            "features: \"embedded_sentence3\\\\.70\"\n",
            "features: \"embedded_sentence3\\\\.71\"\n",
            "features: \"embedded_sentence3\\\\.72\"\n",
            "features: \"embedded_sentence3\\\\.73\"\n",
            "features: \"embedded_sentence3\\\\.74\"\n",
            "features: \"embedded_sentence3\\\\.75\"\n",
            "features: \"embedded_sentence3\\\\.76\"\n",
            "features: \"embedded_sentence3\\\\.77\"\n",
            "features: \"embedded_sentence3\\\\.78\"\n",
            "features: \"embedded_sentence3\\\\.79\"\n",
            "features: \"embedded_sentence3\\\\.8\"\n",
            "features: \"embedded_sentence3\\\\.80\"\n",
            "features: \"embedded_sentence3\\\\.81\"\n",
            "features: \"embedded_sentence3\\\\.82\"\n",
            "features: \"embedded_sentence3\\\\.83\"\n",
            "features: \"embedded_sentence3\\\\.84\"\n",
            "features: \"embedded_sentence3\\\\.85\"\n",
            "features: \"embedded_sentence3\\\\.86\"\n",
            "features: \"embedded_sentence3\\\\.87\"\n",
            "features: \"embedded_sentence3\\\\.88\"\n",
            "features: \"embedded_sentence3\\\\.89\"\n",
            "features: \"embedded_sentence3\\\\.9\"\n",
            "features: \"embedded_sentence3\\\\.90\"\n",
            "features: \"embedded_sentence3\\\\.91\"\n",
            "features: \"embedded_sentence3\\\\.92\"\n",
            "features: \"embedded_sentence3\\\\.93\"\n",
            "features: \"embedded_sentence3\\\\.94\"\n",
            "features: \"embedded_sentence3\\\\.95\"\n",
            "features: \"embedded_sentence3\\\\.96\"\n",
            "features: \"embedded_sentence3\\\\.97\"\n",
            "features: \"embedded_sentence3\\\\.98\"\n",
            "features: \"embedded_sentence3\\\\.99\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 100\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 70 example(s) and 1536 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/100 (tree index:1) done accuracy:0.0769231 logloss:33.2711\n",
            "[INFO random_forest.cc:578] Training of tree  11/100 (tree index:15) done accuracy:0.0714286 logloss:33.0564\n",
            "[INFO random_forest.cc:578] Training of tree  21/100 (tree index:22) done accuracy:0.1 logloss:31.5943\n",
            "[INFO random_forest.cc:578] Training of tree  31/100 (tree index:30) done accuracy:0.1 logloss:30.1446\n",
            "[INFO random_forest.cc:578] Training of tree  41/100 (tree index:38) done accuracy:0.1 logloss:29.684\n",
            "[INFO random_forest.cc:578] Training of tree  51/100 (tree index:50) done accuracy:0.128571 logloss:29.6973\n",
            "[INFO random_forest.cc:578] Training of tree  61/100 (tree index:59) done accuracy:0.128571 logloss:29.2494\n",
            "[INFO random_forest.cc:578] Training of tree  71/100 (tree index:70) done accuracy:0.128571 logloss:29.2695\n",
            "[INFO random_forest.cc:578] Training of tree  81/100 (tree index:79) done accuracy:0.128571 logloss:28.8048\n",
            "[INFO random_forest.cc:578] Training of tree  91/100 (tree index:91) done accuracy:0.128571 logloss:28.8046\n",
            "[INFO random_forest.cc:578] Training of tree  100/100 (tree index:97) done accuracy:0.114286 logloss:28.3413\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.114286 logloss:28.3413\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp30jxzgif\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 100 root(s), 1898 node(s), and 616 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gs3fWW5ACqJ",
        "outputId": "c1b05aaf-0ebb-43ad-9431-be8e4145ded0"
      },
      "source": [
        "evaluation = model_2.evaluate(test_ds_use)\n",
        "\n",
        "print(f\"CategoricalCrossentropyloss: {evaluation[0]}\")\n",
        "print(f\"Accuracy: {evaluation[1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:591: UserWarning: Input dict contained keys ['sentence'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 14s 14s/step - loss: 0.0000e+00 - accuracy: 0.5588\n",
            "CategoricalCrossentropyloss: 0.0\n",
            "Accuracy: 0.5588235259056091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37AGJamzboZQ"
      },
      "source": [
        "## Train a decision tree and neural network together\n",
        "\n",
        "The previous example used a pre-trained Neural Network (NN) to \n",
        "process the text features before passing them to the Random Forest. This example will train both the Neural Network and the Random Forest from scratch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJIxGwwzMkFl"
      },
      "source": [
        "TF-DF's Decision Forests do not back-propagate gradients ([although this is the subject of ongoing research](https://arxiv.org/abs/2007.14761)). Therefore, the training happens in two stages:\n",
        "\n",
        "1. Train the neural-network as a standard classification task:\n",
        "\n",
        "```\n",
        "example → [Normalize] → [Neural Network*] → [classification head] → prediction\n",
        "*: Training.\n",
        "```\n",
        "\n",
        "2. Replace the Neural Network's head (the last layer and the soft-max) with a Random Forest. Train the Random Forest as usual:\n",
        "\n",
        "```\n",
        "example → [Normalize] → [Neural Network] → [Random Forest*] → prediction\n",
        "*: Training.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSIvuAhzbjWO"
      },
      "source": [
        "### Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtyi8UoqtzhM"
      },
      "source": [
        "label = \"CurrentJobTitle\"\n",
        "\n",
        "# Replaces numerical NaN (representing missing values in Pandas Dataframe) with 0s.\n",
        "# ...Neural Nets don't work well with numerical NaNs.\n",
        "for col in dataset_df.columns:\n",
        "  if dataset_df[col].dtype not in [str, object]:\n",
        "    dataset_df[col] = dataset_df[col].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKrW5Yfjso0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eede89c-e571-4bc5-863f-e44acb11a3b4"
      },
      "source": [
        "# Split the dataset into a training and testing dataset.\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Convert the datasets into tensorflow datasets\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70 examples in training, 29 examples for testing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ore7f6tgcOMh"
      },
      "source": [
        "### Build the models\n",
        "\n",
        "Next create the neural network model using [Keras' functional style](https://www.tensorflow.org/guide/keras/functional). \n",
        "\n",
        "To keep the example simple this model only uses two inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Jfe4YteBqY"
      },
      "source": [
        "input_1 = tf.keras.Input(shape=(1,), name=\"Past1\", dtype=\"string\")\n",
        "input_2 = tf.keras.Input(shape=(1,), name=\"Past2\", dtype=\"string\")\n",
        "input_3 = tf.keras.Input(shape=(1,), name=\"Past3\", dtype=\"string\")\n",
        "\n",
        "nn_raw_inputs = [input_1, input_2, input_3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjlvAUNGeDM8"
      },
      "source": [
        "Use [`experimental.preprocessing` layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) to convert the raw inputs to inputs apropriate for the neural netrwork. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q09Nkp6ei21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373389f9-88c3-4763-8349-bedd4a8ba683"
      },
      "source": [
        "# Normalization.\n",
        "Normalization = tf.keras.layers.experimental.preprocessing.Normalization\n",
        "CategoryEncoding = tf.keras.layers.experimental.preprocessing.CategoryEncoding\n",
        "StringLookup = tf.keras.layers.experimental.preprocessing.StringLookup\n",
        "\n",
        "values = train_ds_pd[\"Past1\"].values\n",
        "input_1_indexer = StringLookup(max_tokens=32)\n",
        "input_1_indexer.adapt(values)\n",
        "\n",
        "values = train_ds_pd[\"Past2\"].values\n",
        "input_2_indexer = StringLookup(max_tokens=32)\n",
        "input_2_indexer.adapt(values)\n",
        "\n",
        "values = train_ds_pd[\"Past3\"].values\n",
        "input_3_indexer = StringLookup(max_tokens=32)\n",
        "input_3_indexer.adapt(values)\n",
        "\n",
        "input_1_onehot = CategoryEncoding(output_mode=\"binary\", max_tokens=32)\n",
        "input_2_onehot = CategoryEncoding(output_mode=\"binary\", max_tokens=32)\n",
        "input_3_onehot = CategoryEncoding(output_mode=\"binary\", max_tokens=32)\n",
        "\n",
        "normalized_input_1 = input_1_onehot(input_1_indexer(input_1))\n",
        "normalized_input_2 = input_2_onehot(input_2_indexer(input_2))\n",
        "normalized_input_3 = input_3_onehot(input_3_indexer(input_3))\n",
        "\n",
        "nn_processed_inputs = [normalized_input_1, normalized_input_2, normalized_input_3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n",
            "WARNING:tensorflow:max_tokens is deprecated, please use num_tokens instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCoQljyhelau"
      },
      "source": [
        "Build the body of the neural network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNIE8EgQrP-l",
        "outputId": "8a1d1a42-08e0-4ce5-ce67-979345be1fbf"
      },
      "source": [
        "len(dataset_df[\"CurrentJobTitle\"].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzocgbYNsH6y"
      },
      "source": [
        "y = tf.keras.layers.Concatenate()(nn_processed_inputs)\n",
        "y = tf.keras.layers.Dense(16, activation=tf.nn.relu6)(y)\n",
        "last_layer = tf.keras.layers.Dense(8, activation=tf.nn.relu, name=\"last\")(y)\n",
        "\n",
        "# \"3\" for the three label classes. If it were a binary classification, the\n",
        "# output dim would be 1.\n",
        "classification_output = tf.keras.layers.Dense(69)(y)\n",
        "\n",
        "nn_model = tf.keras.models.Model(nn_raw_inputs, classification_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPbRKf1CfIrj"
      },
      "source": [
        "This `nn_model` directly produces classification logits. \n",
        "\n",
        "Next create a decision forest model. This will operate on the high level features that the neural network extracts in the last layer before that classification head."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fnpGNyTuXvH"
      },
      "source": [
        "# To reduce the risk of mistakes, group both the decision forest and the\n",
        "# neural network in a single keras model.\n",
        "nn_without_head = tf.keras.models.Model(inputs=nn_model.inputs, outputs=last_layer)\n",
        "df_and_nn_model = tfdf.keras.RandomForestModel(preprocessing=nn_without_head)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trq07lvMudlz"
      },
      "source": [
        "### Train and evaluate the models\n",
        "\n",
        "The model will be trained in two stages. First train the neural network with its own classification head:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4OyUWKiupuF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d91ce2cc-f07a-4863-c741-6b72285493d3"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "nn_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=[\"accuracy\"])\n",
        "\n",
        "nn_model.fit(x=train_ds, validation_data=test_ds, epochs=10)    # try increasing epochs\n",
        "nn_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 4.2406 - accuracy: 0.0000e+00 - val_loss: 4.2436 - val_accuracy: 0.0345\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.2337 - accuracy: 0.0000e+00 - val_loss: 4.2443 - val_accuracy: 0.0345\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.2280 - accuracy: 0.0143 - val_loss: 4.2449 - val_accuracy: 0.0345\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 4.2224 - accuracy: 0.0286 - val_loss: 4.2456 - val_accuracy: 0.0345\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 4.2170 - accuracy: 0.0286 - val_loss: 4.2463 - val_accuracy: 0.0345\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 4.2116 - accuracy: 0.0286 - val_loss: 4.2470 - val_accuracy: 0.0345\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 4.2062 - accuracy: 0.0286 - val_loss: 4.2477 - val_accuracy: 0.0345\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.2009 - accuracy: 0.0286 - val_loss: 4.2484 - val_accuracy: 0.0345\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.1955 - accuracy: 0.0429 - val_loss: 4.2491 - val_accuracy: 0.0345\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 4.1901 - accuracy: 0.0571 - val_loss: 4.2498 - val_accuracy: 0.0345\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Past1 (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Past2 (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Past3 (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "string_lookup_3 (StringLookup)  (None, 1)            0           Past1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "string_lookup_4 (StringLookup)  (None, 1)            0           Past2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "string_lookup_5 (StringLookup)  (None, 1)            0           Past3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "category_encoding_1 (CategoryEn (None, 32)           0           string_lookup_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "category_encoding_2 (CategoryEn (None, 32)           0           string_lookup_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "category_encoding_3 (CategoryEn (None, 32)           0           string_lookup_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 96)           0           category_encoding_1[0][0]        \n",
            "                                                                 category_encoding_2[0][0]        \n",
            "                                                                 category_encoding_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           1552        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 69)           1173        dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,725\n",
            "Trainable params: 2,725\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2mgMZOpgMQp"
      },
      "source": [
        "The neural network layers are shared between the two models. So now that the neural network is trained the decision forest model will be fit to the trained output of the neural network layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAc9niXqud7V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "13c76385-d815-4cde-f5bf-65341c6516f2"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "df_and_nn_model.compile(metrics=[\"accuracy\"])\n",
        "with sys_pipes():\n",
        "  df_and_nn_model.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 2\n",
            "[INFO kernel.cc:393] Number of examples: 70\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 70\n",
            "Number of columns: 9\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 8 (88.8889%)\n",
            "\tCATEGORICAL: 1 (11.1111%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 8 (88.8889%)\n",
            "\t0: \"model_3/last/Relu:0.0\" NUMERICAL mean:0.00648971 min:0 max:0.183022 sd:0.0272402\n",
            "\t1: \"model_3/last/Relu:0.1\" NUMERICAL mean:0.0783595 min:0 max:0.437831 sd:0.0960629\n",
            "\t2: \"model_3/last/Relu:0.2\" NUMERICAL mean:0.0288945 min:0 max:0.163663 sd:0.0429092\n",
            "\t3: \"model_3/last/Relu:0.3\" NUMERICAL mean:0.0426394 min:0 max:0.249902 sd:0.0629774\n",
            "\t4: \"model_3/last/Relu:0.4\" NUMERICAL mean:0.0729621 min:0 max:0.411454 sd:0.108103\n",
            "\t5: \"model_3/last/Relu:0.5\" NUMERICAL mean:0.0623533 min:0 max:0.314376 sd:0.0894591\n",
            "\t6: \"model_3/last/Relu:0.6\" NUMERICAL mean:0.098208 min:0 max:0.322431 sd:0.0933162\n",
            "\t7: \"model_3/last/Relu:0.7\" NUMERICAL mean:0.0412567 min:0 max:0.338207 sd:0.0685565\n",
            "\n",
            "CATEGORICAL: 1 (11.1111%)\n",
            "\t8: \"__LABEL\" CATEGORICAL integerized vocab-size:70 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"model_3/last/Relu:0\\\\.0\"\n",
            "features: \"model_3/last/Relu:0\\\\.1\"\n",
            "features: \"model_3/last/Relu:0\\\\.2\"\n",
            "features: \"model_3/last/Relu:0\\\\.3\"\n",
            "features: \"model_3/last/Relu:0\\\\.4\"\n",
            "features: \"model_3/last/Relu:0\\\\.5\"\n",
            "features: \"model_3/last/Relu:0\\\\.6\"\n",
            "features: \"model_3/last/Relu:0\\\\.7\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 70 example(s) and 8 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:0) done accuracy:0 logloss:36.0437\n",
            "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:15) done accuracy:0.0144928 logloss:34.0385\n",
            "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:2) done accuracy:0.0428571 logloss:32.6105\n",
            "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:35) done accuracy:0.0142857 logloss:31.6843\n",
            "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:44) done accuracy:0.0142857 logloss:31.2339\n",
            "[INFO random_forest.cc:578] Training of tree  51/300 (tree index:53) done accuracy:0.0285714 logloss:30.7714\n",
            "[INFO random_forest.cc:578] Training of tree  61/300 (tree index:65) done accuracy:0.0428571 logloss:29.8067\n",
            "[INFO random_forest.cc:578] Training of tree  71/300 (tree index:74) done accuracy:0.0428571 logloss:29.3253\n",
            "[INFO random_forest.cc:578] Training of tree  81/300 (tree index:83) done accuracy:0.0428571 logloss:29.335\n",
            "[INFO random_forest.cc:578] Training of tree  91/300 (tree index:94) done accuracy:0.0428571 logloss:29.3357\n",
            "[INFO random_forest.cc:578] Training of tree  101/300 (tree index:104) done accuracy:0.0428571 logloss:29.3321\n",
            "[INFO random_forest.cc:578] Training of tree  111/300 (tree index:115) done accuracy:0.0571429 logloss:29.3333\n",
            "[INFO random_forest.cc:578] Training of tree  121/300 (tree index:102) done accuracy:0.0571429 logloss:29.3449\n",
            "[INFO random_forest.cc:578] Training of tree  131/300 (tree index:112) done accuracy:0.0571429 logloss:29.3439\n",
            "[INFO random_forest.cc:578] Training of tree  141/300 (tree index:144) done accuracy:0.0571429 logloss:28.8953\n",
            "[INFO random_forest.cc:578] Training of tree  151/300 (tree index:154) done accuracy:0.0571429 logloss:28.8951\n",
            "[INFO random_forest.cc:578] Training of tree  161/300 (tree index:162) done accuracy:0.0571429 logloss:28.8894\n",
            "[INFO random_forest.cc:578] Training of tree  171/300 (tree index:172) done accuracy:0.0571429 logloss:28.8935\n",
            "[INFO random_forest.cc:578] Training of tree  181/300 (tree index:163) done accuracy:0.0571429 logloss:28.9033\n",
            "[INFO random_forest.cc:578] Training of tree  191/300 (tree index:194) done accuracy:0.0571429 logloss:28.9061\n",
            "[INFO random_forest.cc:578] Training of tree  201/300 (tree index:204) done accuracy:0.0571429 logloss:28.9152\n",
            "[INFO random_forest.cc:578] Training of tree  211/300 (tree index:210) done accuracy:0.0571429 logloss:28.9195\n",
            "[INFO random_forest.cc:578] Training of tree  221/300 (tree index:224) done accuracy:0.0571429 logloss:28.9195\n",
            "[INFO random_forest.cc:578] Training of tree  231/300 (tree index:232) done accuracy:0.0571429 logloss:28.9208\n",
            "[INFO random_forest.cc:578] Training of tree  241/300 (tree index:245) done accuracy:0.0571429 logloss:28.9183\n",
            "[INFO random_forest.cc:578] Training of tree  251/300 (tree index:253) done accuracy:0.0571429 logloss:28.47\n",
            "[INFO random_forest.cc:578] Training of tree  261/300 (tree index:247) done accuracy:0.0571429 logloss:28.4769\n",
            "[INFO random_forest.cc:578] Training of tree  271/300 (tree index:273) done accuracy:0.0571429 logloss:28.4806\n",
            "[INFO random_forest.cc:578] Training of tree  281/300 (tree index:283) done accuracy:0.0571429 logloss:28.4869\n",
            "[INFO random_forest.cc:578] Training of tree  291/300 (tree index:293) done accuracy:0.0571429 logloss:28.4901\n",
            "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:297) done accuracy:0.0571429 logloss:28.4908\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.0571429 logloss:28.4908\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmphrhf56nv\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 5788 node(s), and 8 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF8Ru2HSv1a5"
      },
      "source": [
        "Now evaluate the composed model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPMlcObzuw89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66229b31-f4fc-4766-d9e8-4c88affa6158"
      },
      "source": [
        "print(\"Evaluation:\", df_and_nn_model.evaluate(test_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0000e+00 - accuracy: 0.1379\n",
            "Evaluation: [0.0, 0.13793103396892548]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awiHEznlv5sI"
      },
      "source": [
        "Compare it to the Neural Network alone:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--ompWYTvxM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1228ddb-dea7-452e-f0cd-963f1d1961df"
      },
      "source": [
        "print(\"Evaluation :\", nn_model.evaluate(test_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 35ms/step - loss: 4.2498 - accuracy: 0.0345\n",
            "Evaluation : [4.249757766723633, 0.03448275849223137]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPsD3LyaMLHm"
      },
      "source": [
        "Note that categorical sets represent text differently from a dense embedding, so it may be useful to use both strategies jointly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHBFtUeElRYz"
      },
      "source": [
        "## Prepare this model for TensorFlow Serving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbC4lmgfr5Sm"
      },
      "source": [
        "Export the model to the SavedModel format for later re-use e.g.\n",
        "[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08YWGr9U2fza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cf0b93-142d-4a70-aec7-3799cae762af"
      },
      "source": [
        "model_1.save(\"/tmp/my_saved_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Past1, Past2, Past3 with unsupported characters which will be renamed to past1, past2, past3 in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/my_saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/my_saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-8R02_SXpbq"
      },
      "source": [
        "## Plot the model\n",
        "\n",
        "Plotting a decision tree and following the first branches helps learning about decision forests. In some cases, plotting a model can even be used for debugging.\n",
        "\n",
        "Because of the difference in the way they are trained, some models are more interresting to plan than others. Because of the noise injected during training and the depth of the trees, plotting Random Forest is less informative than plotting a CART or the first tree of a Gradient Boosted Tree.\n",
        "\n",
        "Never the less, let's plot the first tree of our Random Forest model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUIxf8N6Yjl0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8091428c-c2c2-4c12-8a34-f0fd8b2cf2f8"
      },
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n",
              "<div id=\"tree_plot_4d4799ad89f94ea7b152b22d55a272e2\"></div>\n",
              "<script>\n",
              "/*\n",
              " * Copyright 2021 Google LLC.\n",
              " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              " * you may not use this file except in compliance with the License.\n",
              " * You may obtain a copy of the License at\n",
              " *\n",
              " *     https://www.apache.org/licenses/LICENSE-2.0\n",
              " *\n",
              " * Unless required by applicable law or agreed to in writing, software\n",
              " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              " * See the License for the specific language governing permissions and\n",
              " * limitations under the License.\n",
              " */\n",
              "\n",
              "/**\n",
              " *  Plotting of decision trees generated by TF-DF.\n",
              " *\n",
              " *  A tree is a recursive structure of node objects.\n",
              " *  A node contains one or more of the following components:\n",
              " *\n",
              " *    - A value: Representing the output of the node. If the node is not a leaf,\n",
              " *      the value is only present for analysis i.e. it is not used for\n",
              " *      predictions.\n",
              " *\n",
              " *    - A condition : For non-leaf nodes, the condition (also known as split)\n",
              " *      defines a binary test to branch to the positive or negative child.\n",
              " *\n",
              " *    - An explanation: Generally a plot showing the relation between the label\n",
              " *      and the condition to give insights about the effect of the condition.\n",
              " *\n",
              " *    - Two children : For non-leaf nodes, the children nodes. The first\n",
              " *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n",
              " *      red). The second children is the positive one (drawn in green).\n",
              " *\n",
              " */\n",
              "\n",
              "/**\n",
              " * Plots a single decision tree into a DOM element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!tree} raw_tree Recursive tree structure.\n",
              " * @param {string} canvas_id Id of the output dom element.\n",
              " */\n",
              "function display_tree(options, raw_tree, canvas_id) {\n",
              "  console.log(options);\n",
              "\n",
              "  // Determine the node placement.\n",
              "  const tree_struct = d3.tree().nodeSize(\n",
              "      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n",
              "\n",
              "  // Boundaries of the node placement.\n",
              "  let x_min = Infinity;\n",
              "  let x_max = -x_min;\n",
              "  let y_min = Infinity;\n",
              "  let y_max = -x_min;\n",
              "\n",
              "  tree_struct.each(d => {\n",
              "    if (d.x > x_max) x_max = d.x;\n",
              "    if (d.x < x_min) x_min = d.x;\n",
              "    if (d.y > y_max) y_max = d.y;\n",
              "    if (d.y < y_min) y_min = d.y;\n",
              "  });\n",
              "\n",
              "  // Size of the plot.\n",
              "  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n",
              "  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n",
              "      options.node_y_offset - options.node_y_size;\n",
              "\n",
              "  const plot = d3.select(canvas_id);\n",
              "\n",
              "  // Tool tip\n",
              "  options.tooltip = plot.append('div')\n",
              "                        .attr('width', 100)\n",
              "                        .attr('height', 100)\n",
              "                        .style('padding', '4px')\n",
              "                        .style('background', '#fff')\n",
              "                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n",
              "                        .style('border', '1px solid black')\n",
              "                        .style('font-family', 'sans-serif')\n",
              "                        .style('font-size', options.font_size)\n",
              "                        .style('position', 'absolute')\n",
              "                        .style('z-index', '10')\n",
              "                        .attr('pointer-events', 'none')\n",
              "                        .style('display', 'none');\n",
              "\n",
              "  // Create canvas\n",
              "  const svg = plot.append('svg').attr('width', width).attr('height', height);\n",
              "  const graph =\n",
              "      svg.style('overflow', 'visible')\n",
              "          .append('g')\n",
              "          .attr('font-family', 'sans-serif')\n",
              "          .attr('font-size', options.font_size)\n",
              "          .attr(\n",
              "              'transform',\n",
              "              () => `translate(${options.margin},${\n",
              "                  - x_min + options.node_y_offset / 2 + options.margin})`);\n",
              "\n",
              "  // Plot bounding box.\n",
              "  if (options.show_plot_bounding_box) {\n",
              "    svg.append('rect')\n",
              "        .attr('width', width)\n",
              "        .attr('height', height)\n",
              "        .attr('fill', 'none')\n",
              "        .attr('stroke-width', 1.0)\n",
              "        .attr('stroke', 'black');\n",
              "  }\n",
              "\n",
              "  // Draw the edges.\n",
              "  display_edges(options, graph, tree_struct);\n",
              "\n",
              "  // Draw the nodes.\n",
              "  display_nodes(options, graph, tree_struct);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Draw the nodes of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_nodes(options, graph, tree_struct) {\n",
              "  const nodes = graph.append('g')\n",
              "                    .selectAll('g')\n",
              "                    .data(tree_struct.descendants())\n",
              "                    .join('g')\n",
              "                    .attr('transform', d => `translate(${d.y},${d.x})`);\n",
              "\n",
              "  nodes.append('rect')\n",
              "      .attr('x', 0.5)\n",
              "      .attr('y', 0.5)\n",
              "      .attr('width', options.node_x_size)\n",
              "      .attr('height', options.node_y_size)\n",
              "      .attr('stroke', 'lightgrey')\n",
              "      .attr('stroke-width', 1)\n",
              "      .attr('fill', 'white')\n",
              "      .attr('y', -options.node_y_size / 2);\n",
              "\n",
              "  // Brackets on the right of condition nodes without children.\n",
              "  non_leaf_node_without_children =\n",
              "      nodes.filter(node => node.data.condition != null && node.children == null)\n",
              "          .append('g')\n",
              "          .attr('transform', `translate(${options.node_x_size},0)`);\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#F00');\n",
              "\n",
              "  non_leaf_node_without_children.append('path')\n",
              "      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.0)\n",
              "      .attr('stroke', '#0F0');\n",
              "\n",
              "  const node_content = nodes.append('g').attr(\n",
              "      'transform',\n",
              "      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n",
              "\n",
              "  node_content.append(node => create_node_element(options, node));\n",
              "}\n",
              "\n",
              "/**\n",
              " * Creates the D3 content for a single node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!node} node Node to draw.\n",
              " * @return {!d3} D3 content.\n",
              " */\n",
              "function create_node_element(options, node) {\n",
              "  // Output accumulator.\n",
              "  let output = {\n",
              "    // Content to draw.\n",
              "    content: d3.create('svg:g'),\n",
              "    // Vertical offset to the next element to draw.\n",
              "    vertical_offset: 0\n",
              "  };\n",
              "\n",
              "  // Conditions.\n",
              "  if (node.data.condition != null) {\n",
              "    display_condition(options, node.data.condition, output);\n",
              "  }\n",
              "\n",
              "  // Values.\n",
              "  if (node.data.value != null) {\n",
              "    display_value(options, node.data.value, output);\n",
              "  }\n",
              "\n",
              "  // Explanations.\n",
              "  if (node.data.explanation != null) {\n",
              "    display_explanation(options, node.data.explanation, output);\n",
              "  }\n",
              "\n",
              "  return output.content.node();\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text(options, text, output) {\n",
              "  output.content.append('text')\n",
              "      .attr('x', options.node_padding)\n",
              "      .attr('y', output.vertical_offset)\n",
              "      .attr('alignment-baseline', 'hanging')\n",
              "      .text(text);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a single line of text inside of a node with a tooltip.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {string} text Text to display.\n",
              " * @param {string} tooltip Text in the Tooltip.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_node_text_with_tooltip(options, text, tooltip, output) {\n",
              "  const item = output.content.append('text')\n",
              "                   .attr('x', options.node_padding)\n",
              "                   .attr('alignment-baseline', 'hanging')\n",
              "                   .text(text);\n",
              "\n",
              "  add_tooltip(options, item, () => tooltip);\n",
              "  output.vertical_offset += 10;\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a tooltip to a dom element.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!dom} target Dom element to equip with a tooltip.\n",
              " * @param {!func} get_content Generates the html content of the tooltip.\n",
              " */\n",
              "function add_tooltip(options, target, get_content) {\n",
              "  function show(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.html(get_content());\n",
              "  }\n",
              "\n",
              "  function hide(d) {\n",
              "    options.tooltip.style('display', 'none');\n",
              "  }\n",
              "\n",
              "  function move(d) {\n",
              "    options.tooltip.style('display', 'block');\n",
              "    options.tooltip.style('left', (d.pageX + 5) + 'px');\n",
              "    options.tooltip.style('top', d.pageY + 'px');\n",
              "  }\n",
              "\n",
              "  target.on('mouseover', show);\n",
              "  target.on('mouseout', hide);\n",
              "  target.on('mousemove', move);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a condition inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!condition} condition Condition to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_condition(options, condition, output) {\n",
              "  threshold_format = d3.format('r');\n",
              "\n",
              "  if (condition.type === 'IS_MISSING') {\n",
              "    display_node_text(options, `${condition.attribute} is missing`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'IS_TRUE') {\n",
              "    display_node_text(options, `${condition.attribute} is true`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n",
              "    format = d3.format('r');\n",
              "    display_node_text(\n",
              "        options,\n",
              "        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_IS_IN') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} in [...]`,\n",
              "        `${condition.attribute} in [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `${condition.attribute} intersect [...]`,\n",
              "        `${condition.attribute} intersect [${condition.mask}]`, output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n",
              "    display_node_text_with_tooltip(\n",
              "        options, `Sparse oblique split...`,\n",
              "        `[${condition.attributes}]*[${condition.weights}]>=${\n",
              "            threshold_format(condition.threshold)}`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported condition ${condition.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds a value inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!value} value Value to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_value(options, value, output) {\n",
              "  if (value.type === 'PROBABILITY') {\n",
              "    const left_margin = 0;\n",
              "    const right_margin = 50;\n",
              "    const plot_width = options.node_x_size - options.node_padding * 2 -\n",
              "        left_margin - right_margin;\n",
              "\n",
              "    let cusum = Array.from(d3.cumsum(value.distribution));\n",
              "    cusum.unshift(0);\n",
              "    const distribution_plot = output.content.append('g').attr(\n",
              "        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n",
              "\n",
              "    distribution_plot.selectAll('rect')\n",
              "        .data(value.distribution)\n",
              "        .join('rect')\n",
              "        .attr('height', 10)\n",
              "        .attr(\n",
              "            'x',\n",
              "            (d, i) =>\n",
              "                (cusum[i] * plot_width + left_margin + options.node_padding))\n",
              "        .attr('width', (d, i) => d * plot_width)\n",
              "        .style('fill', (d, i) => d3.schemeSet1[i]);\n",
              "\n",
              "    const num_examples =\n",
              "        output.content.append('g')\n",
              "            .attr('transform', `translate(0,${output.vertical_offset})`)\n",
              "            .append('text')\n",
              "            .attr('x', options.node_x_size - options.node_padding)\n",
              "            .attr('alignment-baseline', 'hanging')\n",
              "            .attr('text-anchor', 'end')\n",
              "            .text(`(${value.num_examples})`);\n",
              "\n",
              "    const distribution_details = d3.create('ul');\n",
              "    distribution_details.selectAll('li')\n",
              "        .data(value.distribution)\n",
              "        .join('li')\n",
              "        .append('span')\n",
              "        .text(\n",
              "            (d, i) =>\n",
              "                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n",
              "\n",
              "    add_tooltip(options, distribution_plot, () => distribution_details.html());\n",
              "    add_tooltip(options, num_examples, () => 'Number of examples');\n",
              "\n",
              "    output.vertical_offset += 10;\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  if (value.type === 'REGRESSION') {\n",
              "    display_node_text(\n",
              "        options,\n",
              "        'value: ' + d3.format('r')(value.value) + ` (` +\n",
              "            d3.format('.6')(value.num_examples) + `)`,\n",
              "        output);\n",
              "    return;\n",
              "  }\n",
              "\n",
              "  display_node_text(options, `Non supported value ${value.type}`, output);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Adds an explanation inside of a node.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!explanation} explanation Explanation to display.\n",
              " * @param {!output} output Output display accumulator.\n",
              " */\n",
              "function display_explanation(options, explanation, output) {\n",
              "  // Margin before the explanation.\n",
              "  output.vertical_offset += 10;\n",
              "\n",
              "  display_node_text(\n",
              "      options, `Non supported explanation ${explanation.type}`, output);\n",
              "}\n",
              "\n",
              "\n",
              "/**\n",
              " * Draw the edges of the tree.\n",
              " * @param {!options} options Dictionary of configurations.\n",
              " * @param {!graph} graph D3 search handle containing the graph.\n",
              " * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n",
              " *     data, etc.).\n",
              " */\n",
              "function display_edges(options, graph, tree_struct) {\n",
              "  // Draw an edge between a parent and a child node with a bezier.\n",
              "  function draw_single_edge(d) {\n",
              "    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n",
              "        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n",
              "        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n",
              "        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n",
              "  }\n",
              "\n",
              "  graph.append('g')\n",
              "      .attr('fill', 'none')\n",
              "      .attr('stroke-width', 1.2)\n",
              "      .selectAll('path')\n",
              "      .data(tree_struct.links())\n",
              "      .join('path')\n",
              "      .attr('d', draw_single_edge)\n",
              "      .attr(\n",
              "          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n",
              "}\n",
              "\n",
              "display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.014084507042253521, 0.0, 0.04225352112676056, 0.0, 0.0, 0.028169014084507043, 0.18309859154929578, 0.056338028169014086, 0.0, 0.0, 0.0, 0.014084507042253521, 0.0, 0.014084507042253521, 0.028169014084507043, 0.014084507042253521, 0.04225352112676056, 0.028169014084507043, 0.04225352112676056, 0.0, 0.04225352112676056, 0.0, 0.014084507042253521, 0.0, 0.0, 0.014084507042253521, 0.014084507042253521, 0.014084507042253521, 0.0, 0.0, 0.014084507042253521, 0.014084507042253521, 0.014084507042253521, 0.0, 0.014084507042253521, 0.0, 0.0, 0.0, 0.014084507042253521, 0.0, 0.0, 0.028169014084507043, 0.0, 0.028169014084507043, 0.0, 0.0, 0.0, 0.04225352112676056, 0.014084507042253521, 0.014084507042253521, 0.0, 0.0, 0.0, 0.0, 0.028169014084507043, 0.04225352112676056, 0.0, 0.0, 0.014084507042253521, 0.014084507042253521, 0.0, 0.0, 0.014084507042253521, 0.0, 0.0, 0.028169014084507043, 0.04225352112676056, 0.014084507042253521], \"num_examples\": 71.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Past3\", \"mask\": [\"<OOD>\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20588235294117646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029411764705882353, 0.0, 0.0, 0.08823529411764706, 0.058823529411764705, 0.08823529411764706, 0.0, 0.08823529411764706, 0.0, 0.029411764705882353, 0.0, 0.0, 0.029411764705882353, 0.0, 0.029411764705882353, 0.0, 0.0, 0.029411764705882353, 0.0, 0.029411764705882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058823529411764705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029411764705882353, 0.029411764705882353, 0.029411764705882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029411764705882353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08823529411764706, 0.029411764705882353], \"num_examples\": 34.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.02702702702702703, 0.0, 0.08108108108108109, 0.0, 0.0, 0.05405405405405406, 0.16216216216216217, 0.10810810810810811, 0.0, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.05405405405405406, 0.02702702702702703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.0, 0.0, 0.05405405405405406, 0.0, 0.0, 0.0, 0.05405405405405406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05405405405405406, 0.08108108108108109, 0.0, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.05405405405405406, 0.0, 0.0], \"num_examples\": 37.0}, \"condition\": {\"type\": \"CATEGORICAL_IS_IN\", \"attribute\": \"Past2\", \"mask\": [\"NIL\"]}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.05555555555555555, 0.0, 0.16666666666666666, 0.0, 0.0, 0.1111111111111111, 0.1111111111111111, 0.2222222222222222, 0.0, 0.0, 0.0, 0.05555555555555555, 0.0, 0.0, 0.0, 0.05555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 18.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21052631578947367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05263157894736842, 0.0, 0.0, 0.05263157894736842, 0.0, 0.0, 0.0, 0.05263157894736842, 0.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.05263157894736842, 0.0, 0.0, 0.0, 0.05263157894736842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.0], \"num_examples\": 19.0}}]}]}, \"#tree_plot_4d4799ad89f94ea7b152b22d55a272e2\")\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPcL_hDnY7Zy"
      },
      "source": [
        "The root node on the left contains the first condition, number of examples (e.g. 74) and label distribution (the coloured bars).\n",
        "\n",
        "Examples that evaluates true to the condition are branched to the one (e.g. green) path. The other ones are branched to the another path (e.g. red).\n",
        "\n",
        "The deeper the node, the more `pure` they become i.e. the label distribution is biased toward a subset of classes. \n",
        "\n",
        "**Note:** Hover the mouse on top of the plot for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ob3ovQ2seVY"
      },
      "source": [
        "## Model structure and feature importance\n",
        "\n",
        "The overall structure of the model is show with `.summary()`. You will see:\n",
        "\n",
        "-   **Type**: The learning algorithm used to train the model (`Random Forest` in\n",
        "    our case).\n",
        "-   **Task**: The problem solved by the model (`Classification` in our case).\n",
        "-   **Input Features**: The input features of the model.\n",
        "-   **Variable Importance**: Different measures of the importance of each\n",
        "    feature for the model.\n",
        "-   **Out-of-bag evaluation**: The out-of-bag evaluation of the model. This is a\n",
        "    cheap and efficient alternative to cross-validation.\n",
        "-   **Number of {trees, nodes} and other metrics**: Statistics about the\n",
        "    structure of the decisions forests.\n",
        "\n",
        "**Remark:** The summary's content depends on the learning algorithm (e.g.\n",
        "Out-of-bag is only available for Random Forest) and the hyper-parameters (e.g.\n",
        "the *mean-decrease-in-accuracy* variable importance can be disabled in the\n",
        "hyper-parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzXME28Lq7Il",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "a6b9897a-4184-4801-9877-aeb4c500548c"
      },
      "source": [
        "%set_cell_height 300\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"random_forest_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1\n",
            "_________________________________________________________________\n",
            "Type: \"RANDOM_FOREST\"\n",
            "Task: CLASSIFICATION\n",
            "Label: \"__LABEL\"\n",
            "\n",
            "Input Features (3):\n",
            "\tPast1\n",
            "\tPast2\n",
            "\tPast3\n",
            "\n",
            "No weights\n",
            "\n",
            "Variable Importance: NUM_NODES:\n",
            "    1. \"Past2\" 300.000000 \n",
            "    2. \"Past3\" 300.000000 \n",
            "\n",
            "Variable Importance: NUM_AS_ROOT:\n",
            "    1. \"Past3\" 281.000000 ################\n",
            "    2. \"Past2\" 19.000000 \n",
            "\n",
            "Variable Importance: SUM_SCORE:\n",
            "    1. \"Past3\" 11160.197721 ################\n",
            "    2. \"Past2\" 6076.819692 \n",
            "\n",
            "Variable Importance: MEAN_MIN_DEPTH:\n",
            "    1.   \"Past1\"  1.666667 ################\n",
            "    2. \"__LABEL\"  1.666667 ################\n",
            "    3.   \"Past2\"  0.936667 ########\n",
            "    4.   \"Past3\"  0.063333 \n",
            "\n",
            "\n",
            "\n",
            "Winner take all: true\n",
            "Out-of-bag evaluation: accuracy:0.162162 logloss:27.712\n",
            "Number of trees: 300\n",
            "Total number of nodes: 1500\n",
            "\n",
            "Number of nodes by tree:\n",
            "Count: 300 Average: 5 StdDev: 0\n",
            "Min: 5 Max: 5 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 5, 5] 300 100.00% 100.00% ##########\n",
            "\n",
            "Depth by leafs:\n",
            "Count: 900 Average: 1.66667 StdDev: 0.471405\n",
            "Min: 1 Max: 2 Ignored: 0\n",
            "----------------------------------------------\n",
            "[ 1, 2) 300  33.33%  33.33% #####\n",
            "[ 2, 2] 600  66.67% 100.00% ##########\n",
            "\n",
            "Number of training obs by leaf:\n",
            "Count: 900 Average: 24.6667 StdDev: 10.2938\n",
            "Min: 8 Max: 50 Ignored: 0\n",
            "----------------------------------------------\n",
            "[  8, 10)   4   0.44%   0.44%\n",
            "[ 10, 12)  14   1.56%   2.00% #\n",
            "[ 12, 14)  56   6.22%   8.22% ####\n",
            "[ 14, 16)  91  10.11%  18.33% #######\n",
            "[ 16, 18) 119  13.22%  31.56% #########\n",
            "[ 18, 20) 104  11.56%  43.11% ########\n",
            "[ 20, 23) 136  15.11%  58.22% ##########\n",
            "[ 23, 25)  44   4.89%  63.11% ###\n",
            "[ 25, 27)  20   2.22%  65.33% #\n",
            "[ 27, 29)  10   1.11%  66.44% #\n",
            "[ 29, 31)   8   0.89%  67.33% #\n",
            "[ 31, 33)  18   2.00%  69.33% #\n",
            "[ 33, 35)  39   4.33%  73.67% ###\n",
            "[ 35, 38)  79   8.78%  82.44% ######\n",
            "[ 38, 40)  51   5.67%  88.11% ####\n",
            "[ 40, 42)  45   5.00%  93.11% ###\n",
            "[ 42, 44)  33   3.67%  96.78% ##\n",
            "[ 44, 46)  14   1.56%  98.33% #\n",
            "[ 46, 48)   9   1.00%  99.33% #\n",
            "[ 48, 50]   6   0.67% 100.00%\n",
            "\n",
            "Attribute in nodes:\n",
            "\t300 : Past3 [CATEGORICAL]\n",
            "\t300 : Past2 [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 0:\n",
            "\t281 : Past3 [CATEGORICAL]\n",
            "\t19 : Past2 [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 1:\n",
            "\t300 : Past3 [CATEGORICAL]\n",
            "\t300 : Past2 [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 2:\n",
            "\t300 : Past3 [CATEGORICAL]\n",
            "\t300 : Past2 [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 3:\n",
            "\t300 : Past3 [CATEGORICAL]\n",
            "\t300 : Past2 [CATEGORICAL]\n",
            "\n",
            "Attribute in nodes with depth <= 5:\n",
            "\t300 : Past3 [CATEGORICAL]\n",
            "\t300 : Past2 [CATEGORICAL]\n",
            "\n",
            "Condition type in nodes:\n",
            "\t600 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 0:\n",
            "\t300 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 1:\n",
            "\t600 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 2:\n",
            "\t600 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 3:\n",
            "\t600 : ContainsBitmapCondition\n",
            "Condition type in nodes with depth <= 5:\n",
            "\t600 : ContainsBitmapCondition\n",
            "\n",
            "Training OOB:\n",
            "\ttrees: 1, Out-of-bag evaluation: accuracy:0.130435 logloss:31.3423\n",
            "\ttrees: 11, Out-of-bag evaluation: accuracy:0.0945946 logloss:31.7676\n",
            "\ttrees: 21, Out-of-bag evaluation: accuracy:0.121622 logloss:30.3699\n",
            "\ttrees: 31, Out-of-bag evaluation: accuracy:0.135135 logloss:29.8907\n",
            "\ttrees: 41, Out-of-bag evaluation: accuracy:0.135135 logloss:29.4135\n",
            "\ttrees: 51, Out-of-bag evaluation: accuracy:0.121622 logloss:28.5297\n",
            "\ttrees: 61, Out-of-bag evaluation: accuracy:0.135135 logloss:28.5299\n",
            "\ttrees: 71, Out-of-bag evaluation: accuracy:0.148649 logloss:28.5288\n",
            "\ttrees: 81, Out-of-bag evaluation: accuracy:0.162162 logloss:28.5319\n",
            "\ttrees: 91, Out-of-bag evaluation: accuracy:0.162162 logloss:28.0877\n",
            "\ttrees: 101, Out-of-bag evaluation: accuracy:0.162162 logloss:28.0916\n",
            "\ttrees: 111, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1039\n",
            "\ttrees: 121, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1003\n",
            "\ttrees: 131, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1056\n",
            "\ttrees: 141, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1101\n",
            "\ttrees: 151, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1138\n",
            "\ttrees: 161, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1182\n",
            "\ttrees: 171, Out-of-bag evaluation: accuracy:0.162162 logloss:28.121\n",
            "\ttrees: 181, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1274\n",
            "\ttrees: 191, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1202\n",
            "\ttrees: 201, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1237\n",
            "\ttrees: 211, Out-of-bag evaluation: accuracy:0.162162 logloss:28.1273\n",
            "\ttrees: 221, Out-of-bag evaluation: accuracy:0.162162 logloss:27.6998\n",
            "\ttrees: 231, Out-of-bag evaluation: accuracy:0.162162 logloss:27.6997\n",
            "\ttrees: 241, Out-of-bag evaluation: accuracy:0.162162 logloss:27.7032\n",
            "\ttrees: 251, Out-of-bag evaluation: accuracy:0.162162 logloss:27.706\n",
            "\ttrees: 261, Out-of-bag evaluation: accuracy:0.162162 logloss:27.709\n",
            "\ttrees: 271, Out-of-bag evaluation: accuracy:0.162162 logloss:27.7107\n",
            "\ttrees: 281, Out-of-bag evaluation: accuracy:0.162162 logloss:27.7139\n",
            "\ttrees: 291, Out-of-bag evaluation: accuracy:0.162162 logloss:27.7162\n",
            "\ttrees: 300, Out-of-bag evaluation: accuracy:0.162162 logloss:27.712\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ApRpUm02zU"
      },
      "source": [
        "The information in ``summary`` are all available programatically using the model inspector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3xuB3jN1Cww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b69e65-d9a8-4f79-b75a-0f4ab36ddd5f"
      },
      "source": [
        "# The input features\n",
        "model_1.make_inspector().features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Past1\" (4; #0), \"Past2\" (4; #1), \"Past3\" (4; #2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2RBbU51L6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b20f66-8985-45cd-ff21-e0b5188feaf0"
      },
      "source": [
        "# The feature importances\n",
        "model_1.make_inspector().variable_importances()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NUM_AS_ROOT': [(\"Past3\" (4; #2), 281.0), (\"Past2\" (4; #1), 19.0)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvyRJVk1aEk"
      },
      "source": [
        "The content of the summary and the inspector depends on the learning algorithm (`tfdf.keras.RandomForestModel` in this case) and its hyper-parameters (e.g. `compute_oob_variable_importances=True` will trigger the computation of Out-of-bag variable importances for the Random Forest learner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFVmrHtWXYKY"
      },
      "source": [
        "## Model Self Evaluation\n",
        "\n",
        "During training TFDF models can self evaluate **even if no validation dataset** is provided to the `fit()` method. The exact logic depends on the model. For example, Random Forest will use Out-of-bag evaluation while Gradient Boosted Trees will use internal train-validation.\n",
        "\n",
        "**Note:** While this evaluation is  computed during training, it is NOT computed on the training dataset and can be used as a low quality evaluation.\n",
        "\n",
        "The model self evaluation is available with the inspector's `evaluation()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZPzyIMmYmsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d4cd23-29fb-4a93-87ff-bf2daa5bbf6a"
      },
      "source": [
        "model_1.make_inspector().evaluation()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.71200896839838, rmse=None, ndcg=None, aucs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSz-jE0Qss_"
      },
      "source": [
        "## Plotting the training logs\n",
        "\n",
        "The training logs show the quality of the model (e.g. accuracy evaluated on the out-of-bag or validation dataset) according to the number of trees in the model. These logs are helpful to study the balance between model size and model quality.\n",
        "\n",
        "The logs are available in multiple ways:\n",
        "\n",
        "1. Displayed in during training if `fit()` is wrapped in `with sys_pipes():` (see example above).\n",
        "1. At the end of the model summary i.e. `model.summary()` (see example above).\n",
        "1. Programmatically, using the model inspector i.e. `model.make_inspector().training_logs()`.\n",
        "1. Using [TensorBoard](https://www.tensorflow.org/tensorboard)\n",
        "\n",
        "Let's try the options 2 and 3:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbRk7xvpTKQG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "02802e2b-661b-46e9-8b3f-f46a876832eb"
      },
      "source": [
        "%set_cell_height 150\n",
        "model_1.make_inspector().training_logs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 150})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TrainLog(num_trees=1, evaluation=Evaluation(num_examples=23, accuracy=0.13043478260869565, loss=31.342305722443953, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=11, evaluation=Evaluation(num_examples=74, accuracy=0.0945945945945946, loss=31.767606734826757, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=21, evaluation=Evaluation(num_examples=74, accuracy=0.12162162162162163, loss=30.36989762180963, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=31, evaluation=Evaluation(num_examples=74, accuracy=0.13513513513513514, loss=29.890677955303644, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=41, evaluation=Evaluation(num_examples=74, accuracy=0.13513513513513514, loss=29.413478214797134, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=51, evaluation=Evaluation(num_examples=74, accuracy=0.12162162162162163, loss=28.529720818472875, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=61, evaluation=Evaluation(num_examples=74, accuracy=0.13513513513513514, loss=28.5298566844415, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=71, evaluation=Evaluation(num_examples=74, accuracy=0.14864864864864866, loss=28.52884764163881, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=81, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.53192450589425, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=91, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.0877074917426, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=101, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.091553450033473, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=111, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.103926407324302, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=121, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.100283957413726, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=131, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.10555669020962, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=141, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.11009298305254, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=151, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.11375766227374, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=161, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.118202200209772, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=171, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.12097171714177, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=181, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.127413860043966, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=191, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.120246744236432, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=201, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.12367114464979, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=211, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=28.127307183436447, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=221, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.69983497060634, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=231, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.699687600135803, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=241, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.703183082712663, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=251, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.705951100265658, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=261, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.709042642970342, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=271, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.710694928829735, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=281, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.713904189499647, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=291, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.71623375891028, rmse=None, ndcg=None, aucs=None)),\n",
              " TrainLog(num_trees=300, evaluation=Evaluation(num_examples=74, accuracy=0.16216216216216217, loss=27.71200896839838, rmse=None, ndcg=None, aucs=None))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WynFJCEbhuF_"
      },
      "source": [
        "Let's plot it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzPH7Gggh0g1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "1490c6b2-8c48-41d5-c342-51d988ecad7b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = model_1.make_inspector().training_logs()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Logloss (out-of-bag)\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1xzugBRhwuN"
      },
      "source": [
        "This dataset is small. You can see the model converging almost immediately.\n",
        "\n",
        "Let's use TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R_m-JmvU9tu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03ccf1f-8070-43a6-d8ca-33c0912206d4"
      },
      "source": [
        "# This cell start TensorBoard that can be slow. Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Google internal version\n",
        "# %load_ext google3.learning.brain.tensorboard.notebook.extension"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6mp7K6HWwqQ"
      },
      "source": [
        "# Clear existing results (if any)\n",
        "!rm -fr \"/tmp/tensorboard_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16NbLILYo124"
      },
      "source": [
        "# Export the meta-data to tensorboard.\n",
        "model_1.make_inspector().export_to_tensorboard(\"/tmp/tensorboard_logs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSsN6aTXW0LJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "f4e82fe5-3cd0-4bca-b580-82001f49eba8"
      },
      "source": [
        "# docs_infra: no_execute\n",
        "# Start a tensorboard instance.\n",
        "%tensorboard --logdir \"/tmp/tensorboard_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_tlSccjZ8kE"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/beginner_tensorboard.png\"/> -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phTUr6F1t-_E"
      },
      "source": [
        "## Re-train the model with a different learning algorithm\n",
        "\n",
        "The learning algorithm is defined by the model class. For\n",
        "example, `tfdf.keras.RandomForestModel()` trains a Random Forest, while\n",
        "`tfdf.keras.GradientBoostedTreesModel()` trains a Gradient Boosted Decision\n",
        "Trees.\n",
        "\n",
        "The learning algorithms are listed by calling `tfdf.keras.get_all_models()` or in the\n",
        "[learner list](https://github.com/google/yggdrasil-decision-forests/manual/learners)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwEAAzUZq2m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b3dadf-0ad1-45dd-c249-a93b372830ca"
      },
      "source": [
        "tfdf.keras.get_all_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensorflow_decision_forests.keras.RandomForestModel,\n",
              " tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n",
              " tensorflow_decision_forests.keras.CartModel]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmzvuI78voD4"
      },
      "source": [
        "The description of the learning algorithms and their hyper-parameters are also available in the [API reference](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf) and builtin help:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hONToBav4DE"
      },
      "source": [
        "# help works anywhere.\n",
        "help(tfdf.keras.RandomForestModel)\n",
        "\n",
        "# ? only works in ipython or notebooks, it usually opens on a separate panel.\n",
        "tfdf.keras.RandomForestModel?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuWEYvXaiwhk"
      },
      "source": [
        "## Using a subset of features\n",
        "\n",
        "The previous example did not specify the features, so all the columns were used\n",
        "as input feature (except for the label). The following example shows how to\n",
        "specify input features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgn_LnRz3M7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371013a0-d480-4c49-c002-bd5a01841d73"
      },
      "source": [
        "feature_1 = tfdf.keras.FeatureUsage(name=\"Past1\")\n",
        "feature_2 = tfdf.keras.FeatureUsage(name=\"Past2\")\n",
        "\n",
        "all_features = [feature_1, feature_2]\n",
        "\n",
        "# Note: This model is only trained with two features. It will not be as good as\n",
        "# the one trained on all features.\n",
        "\n",
        "model_2 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    features=all_features, exclude_non_specified_features=True)\n",
        "\n",
        "model_2.compile(metrics=[\"accuracy\"])\n",
        "model_2.fit(x=train_ds, validation_data=test_ds)\n",
        "\n",
        "print(model_2.evaluate(test_ds, return_dict=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 204ms/step - val_loss: 0.0000e+00 - val_accuracy: 0.0400\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - accuracy: 0.0400\n",
            "{'loss': 0.0, 'accuracy': 0.03999999910593033}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvM84cgCmbUR"
      },
      "source": [
        "**Note:** As expected, the accuracy is lower than previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFmqpivc7x7p"
      },
      "source": [
        "**TF-DF** attaches a **semantics** to each feature. This semantics controls how\n",
        "the feature is used by the model. The following semantics are currently supported:\n",
        "\n",
        "-   **Numerical**: Generally for quantities or counts with full ordering. For\n",
        "    example, the age of a person, or the number of items in a bag. Can be a\n",
        "    float or an integer. Missing values are represented with float(Nan) or with\n",
        "    an empty sparse tensor.\n",
        "-   **Categorical**: Generally for a type/class in finite set of possible values\n",
        "    without ordering. For example, the color RED in the set {RED, BLUE, GREEN}.\n",
        "    Can be a string or an integer. Missing values are represented as \"\" (empty\n",
        "    sting), value -2 or with an empty sparse tensor.\n",
        "-   **Categorical-Set**: A set of categorical values. Great to represent\n",
        "    tokenized text. Can be a string or an integer in a sparse tensor or a\n",
        "    ragged tensor (recommended). The order/index of each item doesn't matter.\n",
        "\n",
        "If not specified, the semantics is inferred from the representation type and shown in the training logs:\n",
        "\n",
        "- int, float (dense or sparse) → Numerical semantics.\n",
        "- str (dense or sparse) → Categorical semantics\n",
        "- int, str (ragged) → Categorical-Set semantics\n",
        "\n",
        "In some cases, the inferred semantics is incorrect. For example: An Enum stored as an integer is semantically categorical, but it will be detected as numerical. In this case, you should specify the semantic argument in the input. The `education_num` field of the Adult dataset is classical example.\n",
        "\n",
        "This dataset doesn't contain such a feature. However, for the demonstration, we will make the model treat the `year` as a categorical feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNRIwLYC8zrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "15844f63-f6ed-4eca-845c-5b6bad087bd6"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "feature_1 = tfdf.keras.FeatureUsage(name=\"Past1\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL)\n",
        "feature_2 = tfdf.keras.FeatureUsage(name=\"Past2\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL)\n",
        "feature_3 = tfdf.keras.FeatureUsage(name=\"Past3\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL)\n",
        "all_features = [feature_1, feature_2, feature_3]\n",
        "\n",
        "model_3 = tfdf.keras.GradientBoostedTreesModel(features=all_features, exclude_non_specified_features=True)\n",
        "model_3.compile( metrics=[\"accuracy\"])\n",
        "\n",
        "with sys_pipes():\n",
        "  model_3.fit(x=train_ds, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r1/2 [==============>...............] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 2\n",
            "[INFO kernel.cc:393] Number of examples: 74\n",
            "[INFO data_spec_inference.cc:289] 72 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Past1 (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 56 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Past2 (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Past3 (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 74\n",
            "Number of columns: 4\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 4 (100%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 4 (100%)\n",
            "\t0: \"Past1\" CATEGORICAL has-dict vocab-size:1 num-oods:72 (97.2973%)\n",
            "\t1: \"Past2\" CATEGORICAL has-dict vocab-size:2 num-oods:56 (75.6757%) most-frequent:\"<OOD>\" 56 (75.6757%)\n",
            "\t2: \"Past3\" CATEGORICAL has-dict vocab-size:2 num-oods:38 (51.3514%) most-frequent:\"<OOD>\" 38 (51.3514%)\n",
            "\t3: \"__LABEL\" CATEGORICAL integerized vocab-size:54 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1532] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1545] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1554] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1566] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"Past1\"\n",
            "features: \"Past2\"\n",
            "features: \"Past3\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:480] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1358] \tnum-trees:1 train-loss:3.711767 train-accuracy:0.161765 valid-loss:3.917980 valid-accuracy:0.166667\n",
            "[INFO gradient_boosted_trees.cc:2506] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 3.91798\n",
            "[INFO gradient_boosted_trees.cc:319] Truncates the model to 53 tree(s) i.e. 1  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:348] Final model valid-loss:3.917980 valid-accuracy:0.166667\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpts1usw4c\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:929] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 53 root(s), 179 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:876] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:797] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 249ms/step - val_loss: 0.0000e+00 - val_accuracy: 0.0400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYrw7nKN40Vm"
      },
      "source": [
        "## Hyper-parameters\n",
        "\n",
        "**Hyper-parameters** are parameters of the training algorithm that impact\n",
        "the quality of the final model. They are specified in the model class\n",
        "constructor. The list of hyper-parameters is visible with the *question mark* colab command (e.g. `?tfdf.keras.GradientBoostedTreesModel`).\n",
        "\n",
        "Alternatively, you can find them on the [TensorFlow Decision Forest Github](https://github.com/tensorflow/decision-forests/keras/wrappers_pre_generated.py) or the [Yggdrasil Decision Forest documentation](https://github.com/google/yggdrasil_decision_forests/documentation/learners).\n",
        "\n",
        "The default hyper-parameters of each algorithm matches approximatively the initial publication paper. To ensure consistancy, new features and their matching hyper-parameters are always disable by default. That's why it is a good idea to tune your hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHgPr4Pt43hv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1ea216-f129-4198-ede3-a676092347e5"
      },
      "source": [
        "# A classical but slighly more complex model.\n",
        "model_6 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500, growing_strategy=\"BEST_FIRST_GLOBAL\", max_depth=8)\n",
        "model_6.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3cab83210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uECgPGDc2P4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f5f678-4618-4ca1-83fd-18c13e7e94ec"
      },
      "source": [
        "# A more complex, but possibly, more accurate model.\n",
        "model_7 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    num_trees=500,\n",
        "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
        "    max_depth=8,\n",
        "    split_axis=\"SPARSE_OBLIQUE\",\n",
        "    categorical_algorithm=\"RANDOM\",\n",
        "    )\n",
        "model_7.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7fc3cc711c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7fc3cc711c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fc3cc3d39e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fc3cc3d39e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3cc611e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk7wEmUZu3V0"
      },
      "source": [
        "As new training methods are published and implemented, combinaisons of hyper-parameters can emerge as good or almost-always-better than the default parameters. To avoid changing the default hyper-parameter values these good combinaisons are indexed and available as hyper-parameter templates.\n",
        "\n",
        "For example, the `benchmark_rank1` template is the best combinaison on our internal benchmarks. Those templates are versioned to allow training configuration stability e.g. `benchmark_rank1@v1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtrRhMhj3hSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e38d302-8758-4e14-af17-47be611fbc7e"
      },
      "source": [
        "# A good template of hyper-parameters.\n",
        "model_8 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n",
        "model_8.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fc3ccbafdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fc3ccbafdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fc3cc882f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fc3cc882f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3cc977390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSDXcKXB3u6M"
      },
      "source": [
        "The available tempaltes are available with `predefined_hyperparameters`. Note that different learning algorithms have different templates, even if the name is similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQrWI2iv37Bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7a4d3a-21bf-4e97-946d-75f79a3588de"
      },
      "source": [
        "# The hyper-parameter templates of the Gradient Boosted Tree model.\n",
        "print(tfdf.keras.GradientBoostedTreesModel.predefined_hyperparameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[HyperParameterTemplate(name='better_default', version=1, parameters={'growing_strategy': 'BEST_FIRST_GLOBAL'}, description='A configuration that is generally better than the default parameters without being more expensive.'), HyperParameterTemplate(name='benchmark_rank1', version=1, parameters={'growing_strategy': 'BEST_FIRST_GLOBAL', 'categorical_algorithm': 'RANDOM', 'split_axis': 'SPARSE_OBLIQUE', 'sparse_oblique_normalization': 'MIN_MAX', 'sparse_oblique_num_projections_exponent': 1.0}, description='Top ranking hyper-parameters on our benchmark slightly modified to run in reasonable time.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S54mR6i9jkhp"
      },
      "source": [
        "## Training a ranking model (possibly relevant)\n",
        "\n",
        "Finaly, after having trained a classification and a regression models, train a [ranking](https://en.wikipedia.org/wiki/Learning_to_rank) model.\n",
        "\n",
        "The goal of a ranking is to **order** items by importance. The \"value\" of\n",
        "relevance does not matter directly. Ranking a set of *documents* with regard to\n",
        "a user *query* is an example of ranking problem: It is only important to get the right order, where the top documents matter more.\n",
        "\n",
        "TF-DF expects for ranking datasets to be presented in a \"flat\" format. A\n",
        "document+query dataset might look like that:\n",
        "\n",
        "query | document_id | feature_1 | feature_2 | relevance/label\n",
        "----- | ----------- | --------- | --------- | ---------------\n",
        "cat   | 1           | 0.1       | blue      | 4\n",
        "cat   | 2           | 0.5       | green     | 1\n",
        "cat   | 3           | 0.2       | red       | 2\n",
        "dog   | 4           | NA        | red       | 0\n",
        "dog   | 5           | 0.2       | red       | 1\n",
        "dog   | 6           | 0.6       | green     | 1\n",
        "\n",
        "The *relevance/label* is a floating point numerical value between 0 and 5\n",
        "(generally between 0 and 4) where 0 means \"completely unrelated\", 4 means \"very\n",
        "relevant\" and 5 means \"the same as the query\".\n",
        "\n",
        "Interestingly, decision forests are often good rankers, and many\n",
        "state-of-the-art ranking models are decision forests.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axD6x1ZivHCS"
      },
      "source": [
        "%set_cell_height 200\n",
        "\n",
        "archive_path = tf.keras.utils.get_file(\"letor.zip\",\n",
        "  \"https://download.microsoft.com/download/E/7/E/E7EABEF1-4C7B-4E31-ACE5-73927950ED5E/Letor.zip\",\n",
        "  extract=True)\n",
        "\n",
        "# Path to the train and test dataset using libsvm format.\n",
        "raw_dataset_path = os.path.join(os.path.dirname(archive_path),\"OHSUMED/Data/All/OHSUMED.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcManr98ZGID"
      },
      "source": [
        "The dataset is stored as a .txt file in a specific format, so first convert it into a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkiM9HJox-e8"
      },
      "source": [
        "def convert_libsvm_to_csv(src_path, dst_path):\n",
        "  \"\"\"Converts a libsvm ranking dataset into a flat csv file.\n",
        "  \n",
        "  Note: This code is specific to the LETOR3 dataset.\n",
        "  \"\"\"\n",
        "  dst_handle = open(dst_path, \"w\")\n",
        "  first_line = True\n",
        "  for src_line in open(src_path,\"r\"):\n",
        "    # Note: The last 3 items are comments.\n",
        "    items = src_line.split(\" \")[:-3]\n",
        "    relevance = items[0]\n",
        "    group = items[1].split(\":\")[1]\n",
        "    features = [ item.split(\":\") for item in items[2:]]\n",
        "\n",
        "    if first_line:\n",
        "      # Csv header\n",
        "      dst_handle.write(\"relevance,group,\" + \",\".join([\"f_\" + feature[0] for feature in features]) + \"\\n\")\n",
        "      first_line = False\n",
        "    dst_handle.write(relevance + \",g_\" + group + \",\" + (\",\".join([feature[1] for feature in features])) + \"\\n\")\n",
        "  dst_handle.close()\n",
        "\n",
        "# Convert the dataset.\n",
        "csv_dataset_path=\"/tmp/ohsumed.csv\"\n",
        "convert_libsvm_to_csv(raw_dataset_path, csv_dataset_path)\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(csv_dataset_path)\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB7bWAja1G-o"
      },
      "source": [
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Display the first 3 examples of the training dataset.\n",
        "train_ds_pd.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQKqN9zN4L00"
      },
      "source": [
        "In this dataset, the `relevance` defines the ground-truth rank among rows of the same `group`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QMbBkCEXxu_"
      },
      "source": [
        "# Name of the relevance and grouping columns.\n",
        "relevance = \"relevance\"\n",
        "\n",
        "ranking_train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)\n",
        "ranking_test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=relevance, task=tfdf.keras.Task.RANKING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba1gb75SX1rr"
      },
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8 = tfdf.keras.GradientBoostedTreesModel(\n",
        "    task=tfdf.keras.Task.RANKING,   # Note the task chosen\n",
        "    ranking_group=\"group\",\n",
        "    num_trees=50)\n",
        "\n",
        "with sys_pipes():\n",
        "  model_8.fit(x=ranking_train_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spZCfxfR3VK0"
      },
      "source": [
        "At this point, keras does not propose any ranking metrics. Instead, the training and validation (a GBDT uses a validation dataset) are shown in the training\n",
        "logs. In this case the loss is `LAMBDA_MART_NDCG5`, and the final (i.e. at\n",
        "the end of the training) NDCG (normalized discounted cumulative gain) is `0.510136` (see line `Final model valid-loss: -0.510136`).\n",
        "\n",
        "Note that the NDCG is a value between 0 and 1. The larget the NDCG, the better\n",
        "the model. For this reason, the loss to be -NDCG.\n",
        "\n",
        "As before, the model can be analysed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4N1R8fM4jFh"
      },
      "source": [
        "%set_cell_height 400\n",
        "\n",
        "model_8.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vif6gsAjfzv"
      },
      "source": [
        "## Training a regression model (not relevant)\n",
        "\n",
        "The previous example trains a classification model (TF-DF does not differentiate\n",
        "between binary classification and multi-class classification). In the next\n",
        "example, train a regression model on the\n",
        "[Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone). The\n",
        "objective of this dataset is to predict the number of shell's rings of an\n",
        "abalone.\n",
        "\n",
        "**Note:** The csv file is assembled by appending UCI's header and data files. No preprocessing was applied.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/LivingAbalone.JPG/800px-LivingAbalone.JPG\" width=\"200\"/></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uKI_Uy7RyWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04afc3f1-eca0-469c-e5ae-b179f93139ec"
      },
      "source": [
        "# Download the dataset.\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/abalone_raw.csv -O /tmp/abalone.csv\n",
        "\n",
        "dataset_df = pd.read_csv(\"/tmp/abalone.csv\")\n",
        "print(dataset_df.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Type  LongestShell  Diameter  ...  VisceraWeight  ShellWeight  Rings\n",
            "0    M         0.455     0.365  ...         0.1010         0.15     15\n",
            "1    M         0.350     0.265  ...         0.0485         0.07      7\n",
            "2    F         0.530     0.420  ...         0.1415         0.21      9\n",
            "\n",
            "[3 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gjrquQySU7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580659f8-68ba-4ee9-aca7-18ac92169fa6"
      },
      "source": [
        "# Split the dataset into a training and testing dataset.\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Name of the label column.\n",
        "label = \"Rings\"\n",
        "\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2984 examples in training, 1193 examples for testing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8fUhQKISqYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "c11d406d-96d7-45f5-9b2b-a7645d819c21"
      },
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "# Configure the model.\n",
        "model_7 = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "# Optional.\n",
        "model_7.compile(metrics=[\"mse\"])\n",
        "\n",
        "# Train the model.\n",
        "with sys_pipes():\n",
        "  model_7.fit(x=train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 47\n",
            "[INFO kernel.cc:393] Number of examples: 2984\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2984\n",
            "Number of columns: 9\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 8 (88.8889%)\n",
            "\tCATEGORICAL: 1 (11.1111%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 8 (88.8889%)\n",
            "\t0: \"Diameter\" NUMERICAL mean:0.407837 min:0.055 max:0.63 sd:0.0989397\n",
            "\t1: \"Height\" NUMERICAL mean:0.139564 min:0 max:1.13 sd:0.0430591\n",
            "\t2: \"LongestShell\" NUMERICAL mean:0.52378 min:0.075 max:0.8 sd:0.119413\n",
            "\t3: \"ShellWeight\" NUMERICAL mean:0.238117 min:0.0015 max:1.005 sd:0.137906\n",
            "\t4: \"ShuckedWeight\" NUMERICAL mean:0.358867 min:0.001 max:1.488 sd:0.221317\n",
            "\t6: \"VisceraWeight\" NUMERICAL mean:0.180245 min:0.0005 max:0.76 sd:0.10943\n",
            "\t7: \"WholeWeight\" NUMERICAL mean:0.826909 min:0.002 max:2.8255 sd:0.487693\n",
            "\t8: \"__LABEL\" NUMERICAL mean:9.88773 min:1 max:27 sd:3.1615\n",
            "\n",
            "CATEGORICAL: 1 (11.1111%)\n",
            "\t5: \"Type\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"M\" 1078 (36.126%)\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Diameter\"\n",
            "features: \"Height\"\n",
            "features: \"LongestShell\"\n",
            "features: \"ShellWeight\"\n",
            "features: \"ShuckedWeight\"\n",
            "features: \"Type\"\n",
            "features: \"VisceraWeight\"\n",
            "features: \"WholeWeight\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 2984 example(s) and 8 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/300 (tree index:1) done rmse:2.62257\n",
            "[INFO random_forest.cc:578] Training of tree  11/300 (tree index:11) done rmse:2.22535\n",
            "[INFO random_forest.cc:578] Training of tree  21/300 (tree index:19) done rmse:2.13653\n",
            "[INFO random_forest.cc:578] Training of tree  31/300 (tree index:31) done rmse:2.12654\n",
            "[INFO random_forest.cc:578] Training of tree  41/300 (tree index:38) done rmse:2.1044\n",
            "[INFO random_forest.cc:578] Training of tree  53/300 (tree index:53) done rmse:2.09602\n",
            "[INFO random_forest.cc:578] Training of tree  63/300 (tree index:63) done rmse:2.08935\n",
            "[INFO random_forest.cc:578] Training of tree  73/300 (tree index:71) done rmse:2.08702\n",
            "[INFO random_forest.cc:578] Training of tree  83/300 (tree index:84) done rmse:2.08261\n",
            "[INFO random_forest.cc:578] Training of tree  93/300 (tree index:94) done rmse:2.08131\n",
            "[INFO random_forest.cc:578] Training of tree  103/300 (tree index:103) done rmse:2.0812\n",
            "[INFO random_forest.cc:578] Training of tree  113/300 (tree index:116) done rmse:2.08131\n",
            "[INFO random_forest.cc:578] Training of tree  123/300 (tree index:120) done rmse:2.08052\n",
            "[INFO random_forest.cc:578] Training of tree  133/300 (tree index:135) done rmse:2.08053\n",
            "[INFO random_forest.cc:578] Training of tree  143/300 (tree index:145) done rmse:2.07986\n",
            "[INFO random_forest.cc:578] Training of tree  153/300 (tree index:152) done rmse:2.07913\n",
            "[INFO random_forest.cc:578] Training of tree  164/300 (tree index:161) done rmse:2.08063\n",
            "[INFO random_forest.cc:578] Training of tree  174/300 (tree index:175) done rmse:2.08117\n",
            "[INFO random_forest.cc:578] Training of tree  184/300 (tree index:182) done rmse:2.07928\n",
            "[INFO random_forest.cc:578] Training of tree  194/300 (tree index:193) done rmse:2.08142\n",
            "[INFO random_forest.cc:578] Training of tree  204/300 (tree index:205) done rmse:2.07972\n",
            "[INFO random_forest.cc:578] Training of tree  214/300 (tree index:212) done rmse:2.07804\n",
            "[INFO random_forest.cc:578] Training of tree  224/300 (tree index:222) done rmse:2.07778\n",
            "[INFO random_forest.cc:578] Training of tree  235/300 (tree index:233) done rmse:2.07776\n",
            "[INFO random_forest.cc:578] Training of tree  246/300 (tree index:245) done rmse:2.07818\n",
            "[INFO random_forest.cc:578] Training of tree  256/300 (tree index:257) done rmse:2.07774\n",
            "[INFO random_forest.cc:578] Training of tree  266/300 (tree index:265) done rmse:2.07635\n",
            "[INFO random_forest.cc:578] Training of tree  276/300 (tree index:274) done rmse:2.07614\n",
            "[INFO random_forest.cc:578] Training of tree  286/300 (tree index:282) done rmse:2.07627\n",
            "[INFO random_forest.cc:578] Training of tree  297/300 (tree index:296) done rmse:2.0767\n",
            "[INFO random_forest.cc:578] Training of tree  300/300 (tree index:298) done rmse:2.076\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:2.076\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpjfh3i00h\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:929] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 300 root(s), 265838 node(s), and 8 input feature(s).\n",
            "[INFO abstract_model.cc:876] Engine \"RandomForestOptPred\" built\n",
            "[INFO kernel.cc:797] Use fast generic engine\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSriIAaMSzwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad835abb-e03c-49d3-ff31-36e9cddd866f"
      },
      "source": [
        "# Evaluate the model on the test dataset.\n",
        "evaluation = model_7.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "print(evaluation)\n",
        "print()\n",
        "print(f\"MSE: {evaluation['mse']}\")\n",
        "print(f\"RMSE: {math.sqrt(evaluation['mse'])}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_test_function.<locals>.test_function_trained at 0x7fc3c85549e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_test_function.<locals>.test_function_trained at 0x7fc3c85549e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - mse: 1.8002\n",
            "{'loss': 0.0, 'mse': 1.800211787223816}\n",
            "\n",
            "MSE: 1.800211787223816\n",
            "RMSE: 1.3417197126165419\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}